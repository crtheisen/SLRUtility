
@article{ ISI:000354884000017,
Author = {Lee, Young-Jin},
Title = {{Analyzing Log Files to Predict Students' Problem Solving Performance in
   a Computer-Based Physics Tutor}},
Journal = {{EDUCATIONAL TECHNOLOGY \& SOCIETY}},
Year = {{2015}},
Volume = {{18}},
Number = {{2, SI}},
Pages = {{225-236}},
Month = {{APR}},
Abstract = {{This study investigates whether information saved in the log files of a
   computer-based tutor can be used to predict the problem solving
   performance of students. The log files of a computer-based physics
   tutoring environment called Andes Physics Tutor was analyzed to build a
   logistic regression model that predicted success and failure of
   students' problem solving from their past interactions with the
   computer-based tutor. The logistic regression model developed in this
   study was able to correctly identify about 70\% of the observed problem
   solving performance. The 10-fold cross-validation and the Receiver
   Operating Characteristic (ROC) curve analyses suggest that the developed
   logistic regression model can predict students' problem solving
   performance on unseen new problems with a similar accuracy in the
   future.}},
Publisher = {{IEEE COMPUTER SOC, LEARNING  TECHNOLOGY TASK FORCE}},
Address = {{BAG 11-222, MASSEY UNIVERSITY, PALMERSTON NORTH, NEW ZEALAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lee, YJ (Reprint Author), Univ Kansas, Educ Technol Program, 1122 West Campus Rd,Room 413, Lawrence, KS 66045 USA.
   Univ Kansas, Educ Technol Program, Lawrence, KS 66045 USA.}},
ISSN = {{1436-4522}},
Keywords = {{Log file analysis; Computer-based learning environment; Problem solving;
   Statistical modeling}},
Keywords-Plus = {{LEARNING ENVIRONMENTS}},
Research-Areas = {{Education \& Educational Research}},
Web-of-Science-Categories  = {{Education \& Educational Research}},
Author-Email = {{yjlee@ku.edu}},
Number-of-Cited-References = {{30}},
Times-Cited = {{0}},
Journal-ISO = {{Educ. Technol. Soc.}},
Doc-Delivery-Number = {{CI6PX}},
Unique-ID = {{ISI:000354884000017}},
}

@article{ ISI:000351280600007,
Author = {Ben-Assuli, Ofir and Shabtai, Itamar and Leshno, Moshe},
Title = {{Using electronic health record systems to optimize admission decisions:
   The Creatinine case study}},
Journal = {{HEALTH INFORMATICS JOURNAL}},
Year = {{2015}},
Volume = {{21}},
Number = {{1}},
Pages = {{73-88}},
Month = {{MAR}},
Abstract = {{Many medical organizations have implemented electronic health record
   (EHR) and health information exchange (HIE) networks to improve medical
   decision-making. This study evaluated the contribution of EHR and HIE
   networks to physicians by investigating whether health information
   technology can lead to more efficient admission decisions by reducing
   redundant admissions in the stressful environment of emergency.
   Log-files were retrieved from an integrative and interoperable EHR that
   serves seven main Israeli hospitals. The analysis was restricted to a
   group of patients seen in the emergency departments who were
   administered a Creatinine test. The assessment of the contribution of
   EHR to admission decisions used various statistical analyses and track
   log-file analysis. We showed that using the EHR contributes to more
   efficient admission decisions and reduces the number of avoidable
   admissions. In particular, there was a reduction in readmissions when
   patient history was viewed. Using EHR can help respond to the
   international problem of avoidable hospital readmissions.}},
Publisher = {{SAGE PUBLICATIONS INC}},
Address = {{2455 TELLER RD, THOUSAND OAKS, CA 91320 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ben-Assuli, O (Reprint Author), Ono Acad Coll, Fac Business Adm, Management Informat Syst, IL-55000 Kiryat Ono, Israel.
   Ben-Assuli, Ofir, Ono Acad Coll, IL-55000 Kiryat Ono, Israel.
   Ben-Assuli, Ofir; Leshno, Moshe, Tel Aviv Univ, IL-69978 Tel Aviv, Israel.
   Shabtai, Itamar, Coll Management Acad Studies, Rishon LeTsiyon, Israel.}},
DOI = {{10.1177/1460458213503646}},
ISSN = {{1460-4582}},
EISSN = {{1741-2811}},
Keywords = {{clinical decision-making; databases and data mining; e-health;
   electronic health record; information technology health-care evaluation}},
Keywords-Plus = {{INFORMATION-RETRIEVAL SYSTEMS; ANSWER CLINICAL QUESTIONS;
   EMERGENCY-DEPARTMENT; HOSPITAL ADMISSIONS; TECHNOLOGY; IMPACT; CARE;
   READMISSION; QUALITY; MANAGEMENT}},
Research-Areas = {{Health Care Sciences \& Services; Medical Informatics}},
Web-of-Science-Categories  = {{Health Care Sciences \& Services; Medical Informatics}},
Author-Email = {{ofir.benassuli@gmail.com}},
Funding-Acknowledgement = {{Research Center of Ono Academic College}},
Funding-Text = {{This work was partially supported by the Research Center of Ono Academic
   College.}},
Number-of-Cited-References = {{39}},
Times-Cited = {{0}},
Journal-ISO = {{Health Inform. J.}},
Doc-Delivery-Number = {{CD7OR}},
Unique-ID = {{ISI:000351280600007}},
}

@article{ ISI:000347763300003,
Author = {Friedberg, Ivo and Skopik, Florian and Settanni, Giuseppe and Fiedler,
   Roman},
Title = {{Combating advanced persistent threats: From network event correlation to
   incident detection}},
Journal = {{COMPUTERS \& SECURITY}},
Year = {{2015}},
Volume = {{48}},
Pages = {{35-57}},
Month = {{FEB}},
Abstract = {{An advanced persistent threat (also known as APT) is a deliberately
   slow-moving cyber-attack that is applied to quietly compromise
   interconnected information systems without revealing itself. APTs often
   use a variety of attack methods to get unauthorized system access
   initially and then gradually spread throughout the network. In contrast
   to traditional attacks, they are not used to interrupt services but
   primarily to steal intellectual property, sensitive internal business
   and legal documents and other data. If an attack on a system is
   successful, timely detection is of paramount importance to mitigate its
   impact and prohibit APTs from further spreading. However, recent
   security incidents, such as Operation Shady Rat, Operation Red October
   or the discovery of Mini Duke just to name a few have impressively
   demonstrated that current security mechanisms are mostly insufficient to
   prohibit targeted and customized attacks. This paper therefore proposes
   a novel anomaly detection approach which is a promising basis for modern
   intrusion detection systems. In contrast to other common approaches,
   which apply a kind of blacklist approach and consider only actions and
   behaviour that match to well-known attack patterns and signatures of
   malware traces, our system works with a white-list approach. Our anomaly
   detection technique keeps track of system events, their dependencies and
   occurrences, and thus learns the normal system behaviour over time and
   reports all actions that differ from the created system model. In this
   work, we describe this system in theory and show evaluation results from
   a pilot study under real-world conditions. (C) 2014 Elsevier Ltd. All
   rights reserved.}},
Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Skopik, F (Reprint Author), Austrian Inst Technol, Safety \& Secur Dept, Donau City Str 1, A-1220 Vienna, Austria.
   Friedberg, Ivo; Skopik, Florian; Settanni, Giuseppe; Fiedler, Roman, Austrian Inst Technol, Safety \& Secur Dept, A-1220 Vienna, Austria.}},
DOI = {{10.1016/j.cose.2014.09.006}},
ISSN = {{0167-4048}},
EISSN = {{1872-6208}},
Keywords = {{Advanced persistent threat; Anomaly detection; Log file analysis;
   Intrusion detection; Event correlation; Self-learning system model}},
Keywords-Plus = {{ANOMALY DETECTION; INTRUSION DETECTION; SECURITY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{florian.skopik@ait.ac.at}},
Funding-Acknowledgement = {{Austrian FFG research program KIRAS CIIS {[}840842]; European Union
   {[}607577]}},
Funding-Text = {{This work was partly funded by the Austrian FFG research program KIRAS
   in course of the project CIIS (840842) and the European Union FP7
   project ECOSSIAN (607577).}},
Number-of-Cited-References = {{35}},
Times-Cited = {{0}},
Journal-ISO = {{Comput. Secur.}},
Doc-Delivery-Number = {{AY7UD}},
Unique-ID = {{ISI:000347763300003}},
}

@article{ ISI:000344442300010,
Author = {Erra, Ugo and Senatore, Sabrina and Minnella, Fernando and Caggianese,
   Giuseppe},
Title = {{Approximate TF-IDF based on topic extraction from massive message stream
   using the GPU}},
Journal = {{INFORMATION SCIENCES}},
Year = {{2015}},
Volume = {{292}},
Pages = {{143-161}},
Month = {{JAN 20}},
Abstract = {{The Web is a constantly expanding global information space that includes
   disparate types of data and resources. Recent trends demonstrate the
   urgent need to manage the large amounts of data stream, especially in
   specific domains of application such as critical infrastructure systems,
   sensor networks, log file analysis, search engines and more recently,
   social networks. All of these applications involve large-scale
   data-intensive tasks, often subject to time constraints and space
   complexity. Algorithms, data management and data retrieval techniques
   must be able to process data stream, i.e., process data as it becomes
   available and provide an accurate response, based solely on the data
   stream that has already been provided. Data retrieval techniques often
   require traditional data storage and processing approach, i.e., all data
   must be available in the storage space in order to be processed. For
   instance, a widely used relevance measure is Term Frequency-Inverse
   Document Frequency (TF-IDF), which can evaluate how important a word is
   in a collection of documents and requires to a priori know the whole
   dataset.
   To address this problem, we propose an approximate version of the TF-IDF
   measure suitable to work on continuous data stream (such as the exchange
   of messages, tweets and sensor-based log files). The algorithm for the
   calculation of this measure makes two assumptions: a fast response is
   required, and memory is both limited and infinitely smaller than the
   size of the data stream. In addition, to face the great computational
   power required to process massive data stream, we present also a
   parallel implementation of the approximate TF-IDF calculation using
   Graphical Processing Units (GPUs).
   This implementation of the algorithm was tested on generated and real
   data stream and was able to capture the most frequent terms. Our results
   demonstrate that the approximate version of the TF-IDF measure performs
   at a level that is comparable to the solution of the precise TF-IDF
   measure. (C) 2014 Elsevier Inc. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE INC}},
Address = {{360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Senatore, S (Reprint Author), Univ Salerno, Dipartimento Informat, I-84084 Fisciano, SA, Italy.
   Erra, Ugo; Minnella, Fernando, Univ Basilicata, Dipartimento Matemat Informat \& Econ, I-85100 Potenza, Italy.
   Senatore, Sabrina, Univ Salerno, Dipartimento Informat, I-84084 Fisciano, SA, Italy.
   Caggianese, Giuseppe, Univ Basilicata, Scuola Ingn, I-85100 Potenza, Italy.}},
DOI = {{10.1016/j.ins.2014.08.062}},
ISSN = {{0020-0255}},
EISSN = {{1872-6291}},
Keywords = {{Twitter; TF-IDF; GPU; Topic extraction; Frequent items; Massive data
   stream}},
Keywords-Plus = {{ACCELERATION; FREQUENT; LAW}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{ugo.erra@unibas.it
   ssenatore@unisa.it
   femando.minnella@unibas.it
   giuseppe.caggianese@uni-bas.it}},
Number-of-Cited-References = {{36}},
Times-Cited = {{0}},
Journal-ISO = {{Inf. Sci.}},
Doc-Delivery-Number = {{AS7NJ}},
Unique-ID = {{ISI:000344442300010}},
}

@article{ ISI:000354646600007,
Author = {Leduc, Claire and Schopfel, Joachim},
Title = {{Usage of e-journals in French business schools}},
Journal = {{ELECTRONIC LIBRARY}},
Year = {{2015}},
Volume = {{33}},
Number = {{2}},
Pages = {{258-272}},
Abstract = {{Purpose - The paper of this paper is to explore the usage patterns of
   e-journals in French business schools.
   Design/methodology/approach - The paper exploits COUNTER-compliant usage
   statistics from a nationwide usage study with data from journal
   collections of an international academic publisher.
   Findings - With regard to online collections, the usage appears to be
   relatively intensive, especially when compared to usage statistics from
   universities in the same fields. This result may reflect an emerging
   research activity in business schools and a projected and required
   international orientation. However, the study also reveals important
   differences between schools, a fact that should not be overestimated
   because of the small sample size, even if the sample is a representative
   of French business schools.
   Research limitations/implications - The paper uses empirical data from a
   national usage study to identify specific patterns in business schools.
   It does not integrate qualitative survey data or deep log file analysis.
   Originality/value - Very few studies provide empirical evidence of
   e-journal usage in business schools. The paper enhances the knowledge on
   usage in specific environments in higher education. This is the first
   usage study with French business schools.}},
Publisher = {{EMERALD GROUP PUBLISHING LIMITED}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Schopfel, J (Reprint Author), Univ Lille 3, Informat \& Document Sci, Villeneuve Dascq, France.
   Leduc, Claire, Univ Littoral \& Cote dOpale, Int Business Inst ISCID CO, Dunkerque, France.
   Schopfel, Joachim, Univ Lille 3, Informat \& Document Sci, Villeneuve Dascq, France.}},
DOI = {{10.1108/EL-03-2013-0046}},
ISSN = {{0264-0473}},
EISSN = {{1758-616X}},
Keywords = {{Business schools; Academic publishing; Electronic journals; Usage
   statistics}},
Keywords-Plus = {{INFORMATION-SEEKING BEHAVIOR; RESEARCHERS; RESOURCES}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Author-Email = {{joachim.schopfel@univ-lille3.fr}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Journal-ISO = {{Electron. Libr.}},
Doc-Delivery-Number = {{CI3KM}},
Unique-ID = {{ISI:000354646600007}},
}

@article{ ISI:000353062400012,
Author = {Saneifar, Hassan and Bonniol, Stephane and Poncelet, Pascal and Roche,
   Mathieu},
Title = {{Recognition of logical units in log files}},
Journal = {{INTELLIGENT DATA ANALYSIS}},
Year = {{2015}},
Volume = {{19}},
Number = {{2}},
Pages = {{431-448}},
Abstract = {{With the development of new technologies more and more information is
   stored in log files. Analyzing such logs can be very useful for the
   decision maker. One of the probably best known example is the Web log
   file analysis where lots of efficient tools have been proposed to
   extract the top-k accessed pages, the best users or even the patterns
   describing the behaviors of users on a Web site. These tools take
   advantages of the well-formed structures of the data. Unfortunately,
   logs files from the industrial world have very heterogeneous complex
   structures (e.g., tables, lists, data blocks). For experts, analyzing
   logs to find messages helping to better understand causes of a failure,
   if a problem have already occurred in the past or even knowing the main
   consequences of a failure is a hard, tedious, time-consuming and
   error-prone task. There is thus a need for new tools helping the experts
   to easily recognize the appropriate part in logs.
   Passage retrieval methods have proved to be very useful for extracting
   relevant parts in documents. In this paper we propose a new approach for
   automatically split logs files into relevant segments based on their
   logical units. We characterize the complex logical units found in logs
   according to their syntactic characteristics. We also introduce the
   notion of generalized vs-grams which is used to automatically extract
   the syntactic characteristics of special structures found in log files.
   Conducted experiments are performed on real datasets from the industrial
   world to demonstrate the efficiency of our proposal on the recognition
   of complex logical units.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Saneifar, H (Reprint Author), Raja Univ, Comp Fac, Tehran, Iran.
   Saneifar, Hassan, Raja Univ, Comp Fac, Tehran, Iran.
   Poncelet, Pascal; Roche, Mathieu, Univ Montpellier 2, CNRS, LIRMM, Montpellier, France.
   Roche, Mathieu, Irstea, Cirad, UMR TETIS, Montpellier, France.
   Bonniol, Stephane, Satin Technol, MIBI, Montpellier, France.}},
DOI = {{10.3233/IDA-150724}},
ISSN = {{1088-467X}},
EISSN = {{1571-4128}},
Keywords = {{Log files; text segmentation; logical units; generalized vs-grams}},
Keywords-Plus = {{TEXT SEGMENTATION; PASSAGES}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{Hassan.Saneifar@lirmm.fr}},
Number-of-Cited-References = {{28}},
Times-Cited = {{0}},
Journal-ISO = {{Intell. Data Anal.}},
Doc-Delivery-Number = {{CG1VE}},
Unique-ID = {{ISI:000353062400012}},
}

@article{ ISI:000347277000023,
Author = {Politi, Liran and Codish, Shlomi and Sagy, Iftach and Fink, Lior},
Title = {{Use patterns of health information exchange through a multidimensional
   lens: Conceptual framework and empirical validation}},
Journal = {{JOURNAL OF BIOMEDICAL INFORMATICS}},
Year = {{2014}},
Volume = {{52}},
Pages = {{212-221}},
Month = {{DEC}},
Abstract = {{Insights about patterns of system use are often gained through the
   analysis of system log files, which record the actual behavior of users.
   In a clinical context, however, few attempts have been made to typify
   system use through log file analysis. The present study offers a
   framework for identifying, describing, and discerning among patterns of
   use of a clinical information retrieval system. We use the session
   attributes of volume, diversity, granularity, duration, and content to
   define a multidimensional space in which each specific session can be
   positioned. We also describe an analytical method for identifying the
   common archetypes of system use in this multidimensional space. We
   demonstrate the value of the proposed framework with a log file of the
   use of a health information exchange (HIE) system by physicians in an
   emergency department (ED) of a large Israeli hospital. The analysis
   reveals five distinct patterns of system use, which have yet to be
   described in the relevant literature. The results of this study have the
   potential to inform the design of HIE systems for efficient and
   effective use, thus increasing their contribution to the clinical
   decision-making process. (C) 2014 Elsevier Inc. All rights reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Politi, L (Reprint Author), 1 Ben Gurion Ave, IL-84105 Beer Sheva, Israel.
   Politi, Liran; Fink, Lior, Ben Gurion Univ Negev, Dept Ind Engn \& Management, IL-84105 Beer Sheva, Israel.
   Codish, Shlomi; Sagy, Iftach, Soroka Univ, Med Ctr, Clin Res Ctr, Beer Sheva, Israel.}},
DOI = {{10.1016/j.jbi.2014.07.003}},
ISSN = {{1532-0464}},
EISSN = {{1532-0480}},
Keywords = {{Use pattern; Health information exchange; Log file; Multidimensional
   analysis}},
Keywords-Plus = {{ORGANIZATIONAL CONFIGURATIONS; EMERGENCY-DEPARTMENT; USAGE; CARE;
   TECHNOLOGY; SYSTEM; PERSONALIZATION; PERCEPTIONS; PERFORMANCE; BEHAVIOR}},
Research-Areas = {{Computer Science; Medical Informatics}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Medical Informatics}},
Author-Email = {{liranpo@post.bgu.ac.il}},
ResearcherID-Numbers = {{Codish, Shlomi/F-1286-2012
   FINK, LIOR/F-1633-2012}},
Number-of-Cited-References = {{56}},
Times-Cited = {{0}},
Journal-ISO = {{J. Biomed. Inform.}},
Doc-Delivery-Number = {{AY0HC}},
Unique-ID = {{ISI:000347277000023}},
}

@article{ ISI:000345948100007,
Author = {Zawoad, Shams and Mernik, Marjan and Hasan, Ragib},
Title = {{Towards Building a Forensics Aware Language for Secure Logging}},
Journal = {{COMPUTER SCIENCE AND INFORMATION SYSTEMS}},
Year = {{2014}},
Volume = {{11}},
Number = {{4, SI}},
Pages = {{1291-1314}},
Month = {{OCT}},
Abstract = {{Trustworthy system logs and application logs are crucial for digital
   forensics. Researchers have proposed different security mechanisms to
   ensure the integrity and confidentiality of logs. However, applying
   current secure logging schemes on heterogeneous formats of logs is
   tedious. Here, we propose Forensics Aware Language (FAL), a
   domain-specific language (DSL) through which we can apply a secure
   logging mechanism on any format of logs. Using FAL, we can define log
   structure, which represents the format of logs and ensures the security
   properties of a chosen secure logging scheme. This log structure can
   later be used by FAL to serve two purposes: it can be used to store
   system logs securely and it will help application developers for secure
   application logging by generating the required source code.}},
Publisher = {{COMSIS CONSORTIUM}},
Address = {{UNIV NOVI SAD, FAC TECH SCI, TRG DOSITEJA OBRADOVICA 6, NOVI SAD, 21000,
   SERBIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zawoad, S (Reprint Author), Univ Alabama Birmingham, Birmingham, AL 35233 USA.
   Zawoad, Shams; Hasan, Ragib, Univ Alabama Birmingham, Birmingham, AL 35233 USA.
   Mernik, Marjan, Univ Maribor, SLO-2000 Maribor, Slovenia.}},
DOI = {{10.2298/CSIS131201051Z}},
ISSN = {{1820-0214}},
Keywords = {{DSL; Secure Logging; Audit Trail; Digital Forensics}},
Keywords-Plus = {{DOMAIN-SPECIFIC LANGUAGES; FEATURE DIAGRAMS; IMPLEMENTATION; SYSTEM;
   SEMANTICS; EASYTIME; DESIGN; LISA}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Author-Email = {{zawoad@cis.uab.edu
   marjan.mernik@um.si
   ragib@cis.uab.edu}},
ResearcherID-Numbers = {{Hasan, Ragib/F-4976-2013}},
ORCID-Numbers = {{Hasan, Ragib/0000-0001-5248-8341}},
Number-of-Cited-References = {{41}},
Times-Cited = {{0}},
Journal-ISO = {{Comput. Sci. Inf. Syst.}},
Doc-Delivery-Number = {{AU9YO}},
Unique-ID = {{ISI:000345948100007}},
}

@article{ ISI:000340488500002,
Author = {Inoue, Mitsuhiro and Shiomi, Hiroya and Sato, Kengo and Taguchi, Junichi
   and Okawa, Kohei and Inada, Kosaku and Murai, Taro and Koike, Izumi and
   Tatewaki, Koshi and Ota, Seiji and Inoue, Tomio},
Title = {{Effect of residual patient motion on dose distribution during
   image-guided robotic radiosurgery for skull tracking based on log file
   analysis}},
Journal = {{JAPANESE JOURNAL OF RADIOLOGY}},
Year = {{2014}},
Volume = {{32}},
Number = {{8}},
Pages = {{461-466}},
Month = {{AUG}},
Abstract = {{The present study aimed to assess the effect of residual patient motion
   on dose distribution during intracranial image-guided robotic
   radiosurgery by analyzing the system log files.
   The dosimetric effect was analyzed according to the difference between
   the original and estimated dose distributions, including targeting
   error, caused by residual patient motion between two successive image
   acquisitions. One hundred twenty-eight treatments were analyzed.
   Forty-two patients were treated using the isocentric plan, and 86
   patients were treated using the conformal (non-isocentric) plan.
   The median distance from the imaging center to the target was 55 mm, and
   the median interval between the acquisitions of sequential images was 79
   s. The median translational residual patient motion was 0.1 mm for each
   axis, and the rotational residual patient motion was 0.1A degrees for
   Delta pitch and Delta roll and 0.2A degrees for Delta yaw. The dose
   error for D (95) was within 1 \% in more than 95 \% of cases. The
   maximum dose error for D (10) to D (90) was within 2 \%. None of the
   studied parameters, including the interval between the acquisitions of
   sequential images, was significantly related to the dosimetric effect.
   The effect of residual patient motion on dose distribution was minimal.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Inoue, M (Reprint Author), Yokohama CyberKnife Ctr, Dept Qual Management Radiotherapy, Shinryoku Neurosurg Clin, Asahi Ku, 574-1 Ichisawa Cho, Yokohama, Kanagawa 2410014, Japan.
   Inoue, Mitsuhiro; Taguchi, Junichi; Okawa, Kohei; Inada, Kosaku, Yokohama CyberKnife Ctr, Dept Qual Management Radiotherapy, Shinryoku Neurosurg Clin, Asahi Ku, Yokohama, Kanagawa 2410014, Japan.
   Inoue, Mitsuhiro; Okawa, Kohei; Koike, Izumi; Inoue, Tomio, Yokohama City Univ, Grad Sch Med, Dept Radiol, Yokohama, Kanagawa 232, Japan.
   Shiomi, Hiroya, Osaka Univ, Grad Sch Med, Dept Radiat Oncol, Osaka, Japan.
   Sato, Kengo, Japanese Red Cross Med Ctr, CyberKnife Ctr, Dept Neurosurg, Shibuya, Japan.
   Murai, Taro, Yokohama CyberKnife Ctr, Dept Radiat Oncol, Shinryoku Neurosurg Clin, Yokohama, Kanagawa, Japan.
   Tatewaki, Koshi; Ota, Seiji, Yokohama CyberKnife Ctr, Dept Neurosurg, Shinryoku Neurosurg Clin, Yokohama, Kanagawa, Japan.}},
DOI = {{10.1007/s11604-014-0330-0}},
ISSN = {{1867-1071}},
EISSN = {{1867-108X}},
Keywords = {{Image-guided radiotherapy; Robotic radiosurgery; Skull tracking;
   Residual patient motion}},
Keywords-Plus = {{SPINAL RADIOSURGERY; ACCURACY; SYSTEM}},
Research-Areas = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Web-of-Science-Categories  = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Author-Email = {{m-inoue@syck.jp}},
Funding-Acknowledgement = {{Institute of Yokohama Advanced Radiosurgery; Chiyoda Technol Corp.;
   Climb Medical Systems, Inc.}},
Funding-Text = {{Hiroya Shiomi is a paid advisor for the Institute of Yokohama Advanced
   Radiosurgery, Chiyoda Technol Corp., Climb Medical Systems, Inc. None of
   the other authors has any conflict of interest to declare.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{0}},
Journal-ISO = {{Jpn. J. Radiol.}},
Doc-Delivery-Number = {{AN3LC}},
Unique-ID = {{ISI:000340488500002}},
}

@article{ ISI:000345122000018,
Author = {Agnew, Christina E. and Irvine, Denise M. and McGarry, Conor K.},
Title = {{Correlation of phantom-based and log file patient-specific QA with
   complexity scores for VMAT}},
Journal = {{JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS}},
Year = {{2014}},
Volume = {{15}},
Number = {{6}},
Pages = {{204-216}},
Abstract = {{The motivation for this study was to reduce physics workload relating to
   patient-specific quality assurance (QA). VMAT plan delivery accuracy was
   determined from analysis of pre- and on-treatment trajectory log files
   and phantom-based ionization chamber array measurements. The correlation
   in this combination of measurements for patient-specific QA was
   investigated. The relationship between delivery errors and plan
   complexity was investigated as a potential method to further reduce
   patient-specific QA workload. Thirty VMAT plans from three treatment
   sites - prostate only, prostate and pelvic node (PPN), and head and neck
   (H\&N) - were retrospectively analyzed in this work. The 2D fluence
   delivery reconstructed from pretreatment and on-treatment trajectory log
   files was compared with the planned fluence using gamma analysis.
   Pretreatment dose delivery verification was also carried out using gamma
   analysis of ionization chamber array measurements compared with
   calculated doses. Pearson correlations were used to explore any
   relationship between trajectory log file (pretreatment and on-treatment)
   and ionization chamber array gamma results (pretreatment). Plan
   complexity was assessed using the MU/arc and the modulation complexity
   score (MCS), with Pearson correlations used to examine any relationships
   between complexity metrics and plan delivery accuracy. Trajectory log
   files were also used to further explore the accuracy of MLC and gantry
   positions. Pretreatment 1\%/1 mm gamma passing rates for trajectory log
   file analysis were 99.1\% (98.7\%-99.2\%), 99.3\% (99.1\%-99.5\%), and
   98.4\% (97.3\%-98.8\%) (median (IQR)) for prostate, PPN, and H\&N,
   respectively, and were significantly correlated to on-treatment
   trajectory log file gamma results (R= 0.989, p < 0.001). Pretreatment
   ionization chamber array (2\%/2 mm) gamma results were also
   significantly correlated with on-treatment trajectory log file gamma
   results (R = 0.623, p < 0.001). Furthermore, all gamma results displayed
   a significant correlation with MCS (R > 0.57, p < 0.001), but not with
   MU/arc. Average MLC position and gantry angle errors were 0.001 +/-
   0.002mm and 0.025 degrees +/- 0.008 degrees over all treatment sites and
   were not found to affect delivery accuracy. However, variability in MLC
   speed was found to be directly related to MLC position accuracy. The
   accuracy of VMAT plan delivery assessed using pretreatment trajectory
   log file fluence delivery and ionization chamber array measurements were
   strongly correlated with on-treatment trajectory log file fluence
   delivery. The strong correlation between trajectory log file and
   phantom-based gamma results demonstrates potential to reduce our current
   patient-specific QA. Additionally, insight into MLC and gantry position
   accuracy through trajectory log file analysis and the strong correlation
   between gamma analysis results and the MCS could also provide further
   methodologies to both optimize the VMAT planning and QA process.}},
Publisher = {{MULTIMED INC}},
Address = {{66 MARTIN ST, TORONTO, ON L9T 2R2, CANADA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{McGarry, CK (Reprint Author), Northern Ireland Canc Ctr, Belfast BT9 7AB, Antrim, North Ireland.
   Agnew, Christina E.; Irvine, Denise M.; McGarry, Conor K., Northern Ireland Canc Ctr, Belfast Hlth \& Social Care Trust, Belfast BT9 7AB, Antrim, North Ireland.
   McGarry, Conor K., Queens Univ, Ctr Canc Res, Belfast, Antrim, North Ireland.}},
ISSN = {{1526-9914}},
Keywords = {{VMAT; complexity; trajectory log files; MLC leaf speed; gantry speed}},
Keywords-Plus = {{MODULATED ARC THERAPY; DOSE-VOLUME HISTOGRAM; QUALITY-ASSURANCE; IMRT
   QA; RADIATION-THERAPY; PASSING RATES; DELIVERY; RADIOTHERAPY; RAPIDARC;
   ACCURACY}},
Research-Areas = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Web-of-Science-Categories  = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Author-Email = {{conor.mcgarry@belfasttrust.hscni.net}},
Number-of-Cited-References = {{40}},
Times-Cited = {{0}},
Journal-ISO = {{J. Appl. Clin. Med. Phys}},
Doc-Delivery-Number = {{AT7MR}},
Unique-ID = {{ISI:000345122000018}},
}

@incollection{ ISI:000341380800010,
Author = {Koplenig, Alexander and Meyer, Peter and Mueller-Spitzer, Carolin},
Editor = {{MullerSpitzer, C}},
Title = {{Dictionary users do look up frequent words. A log file analysis}},
Booktitle = {{USING ONLINE DICTIONARIES}},
Series = {{Lexicographica Series Maior}},
Year = {{2014}},
Volume = {{145}},
Pages = {{229-249}},
Abstract = {{In this paper, we use the 2012 log files of two German online
   dictionaries (Digital Dictionary of the German Language(1) and the
   German version of Wiktionary) and the 100,000 most frequent words in the
   Mannheim German Reference Corpus from 2009 to answer the question of
   whether dictionary users really do look up frequent words, first asked
   by de Schryver et al. (2006). By using an approach to the comparison of
   log files and corpus data which is completely different from that of the
   aforementioned authors, we provide empirical evidence that indicates -
   contrary to the results of de Schryver et al. and Verlinde/Binon (2010)
   - that the corpus frequency of a word can indeed be an important factor
   in determining what online dictionary users look up. Finally, we
   incorporate word class information readily available in Wiktionary into
   our analysis to improve our results considerably.}},
Publisher = {{WALTER DE GRUYTER GMBH}},
Address = {{GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY}},
Type = {{Article; Book Chapter}},
Language = {{English}},
Affiliation = {{Koplenig, A (Reprint Author), Inst Deutsch Sprache, R 5,6-13, D-68161 Mannheim, Germany.
   Koplenig, Alexander; Meyer, Peter; Mueller-Spitzer, Carolin, Inst Deutsch Sprache, D-68161 Mannheim, Germany.}},
ISSN = {{0175-9264}},
ISBN = {{978-3-11-034128-7; 978-3-11-034116-4}},
Keywords = {{log file; frequency; corpus; headword list; monolingual dictionary;
   multilingual dictionary}},
Research-Areas = {{Linguistics}},
Web-of-Science-Categories  = {{Language \& Linguistics}},
Author-Email = {{koplenig@ids-mannheim.de
   meyer@ids-mannheim.de
   mueller-spitzer@ids-mannheim.de}},
Number-of-Cited-References = {{13}},
Times-Cited = {{1}},
Doc-Delivery-Number = {{BB1UW}},
Unique-ID = {{ISI:000341380800010}},
}

@article{ ISI:000327262900009,
Author = {Ein-Dor, L. and Goldschmidt, Y. and Lavi, O. and Miller, G. E. and
   Ninio, M. and Dillenberger, D.},
Title = {{Analytics for resiliency in the mainframe}},
Journal = {{IBM JOURNAL OF RESEARCH AND DEVELOPMENT}},
Year = {{2013}},
Volume = {{57}},
Number = {{5}},
Month = {{SEP-OCT}},
Abstract = {{The IBM System z(R) mainframe computer is a direct descendant of the IBM
   System/360 family of computing systems initially made available in 1965.
   With each release of an IBM mainframe, its developers include new
   reliability, availability, and serviceability (RAS) functions. This
   paper describes recent technology added to the System z and z/OS(R)
   operating system to enhance the ability to provide high levels of
   availability. Specifically, we discuss the use of machine-learning
   algorithms to analyze log messages. We also describe combining temporal
   and textual information for system log-file analysis. Finally, we
   discuss the results of this analysis and the assistance it provides to
   mainframe users.}},
Publisher = {{IBM CORP}},
Address = {{1 NEW ORCHARD ROAD, ARMONK, NY 10504 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ein-Dor, L (Reprint Author), IBM Corp, Div Res, Haifa Res Lab, Haifa Univ Campus, IL-31905 Haifa, Israel.
   Ein-Dor, L.; Goldschmidt, Y.; Lavi, O.; Ninio, M., IBM Corp, Div Res, Haifa Res Lab, IL-31905 Haifa, Israel.
   Miller, G. E., IBM Corp, Syst \& Technol Grp, Poughkeepsie Dev Lab, Poughkeepsie, NY 12601 USA.
   Dillenberger, D., IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.}},
DOI = {{10.1147/JRD.2013.2263891}},
Article-Number = {{8}},
ISSN = {{0018-8646}},
EISSN = {{2151-8556}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Software Engineering; Computer
   Science, Theory \& Methods}},
Author-Email = {{liate@il.ibm.com
   yaarag@il.ibm.com
   oferl@il.ibm.com
   geoffm@us.ibm.com
   matann@il.ibm.com
   engd@us.ibm.com}},
Number-of-Cited-References = {{10}},
Times-Cited = {{0}},
Journal-ISO = {{IBM J. Res. Dev.}},
Doc-Delivery-Number = {{255TL}},
Unique-ID = {{ISI:000327262900009}},
}

@article{ ISI:000325194700007,
Author = {Dixon, Brian E. and Simonaitis, Linas and Goldberg, Howard S. and
   Paterno, Marilyn D. and Schaeffer, Molly and Hongsermeier, Tonya and
   Wright, Adam and Middleton, Blackford},
Title = {{A pilot study of distributed knowledge management and clinical decision
   support in the cloud}},
Journal = {{ARTIFICIAL INTELLIGENCE IN MEDICINE}},
Year = {{2013}},
Volume = {{59}},
Number = {{1, SI}},
Pages = {{45-53}},
Month = {{SEP}},
Abstract = {{Objective: Implement and perform pilot testing of web-based clinical
   decision support services using a novel framework for creating and
   managing clinical knowledge in a distributed fashion using the cloud.
   The pilot sought to (1) develop and test connectivity to an external
   clinical decision support (CDS) service, (2) assess the exchange of data
   to and knowledge from the external CDS service, and (3) capture lessons
   to guide expansion to more practice sites and users.
   Materials and methods: The Clinical Decision Support Consortium created
   a repository of shared CDS knowledge for managing hypertension,
   diabetes, and coronary artery disease in a community cloud hosted by
   Partners HealthCare. A limited data set for primary care patients at a
   separate health system was securely transmitted to a CDS rules engine
   hosted in the cloud. Preventive care reminders triggered by the limited
   data set were returned for display to clinician end users for review and
   display. During a pilot study, we (1) monitored connectivity and system
   performance, (2) studied the exchange of data and decision support
   reminders between the two health systems, and (3) captured lessons.
   Results: During the six month pilot study, there were 1339 patient
   encounters in which information was successfully exchanged. Preventive
   care reminders were displayed during 57\% of patient visits, most often
   reminding physicians to monitor blood pressure for hypertensive patients
   (29\%) and order eye exams for patients with diabetes (28\%). Lessons
   learned were grouped into five themes: performance, governance, semantic
   interoperability, ongoing adjustments, and usability.
   Discussion: Remote, asynchronous cloud-based decision support performed
   reasonably well, although issues concerning governance, semantic
   interoperability, and usability remain key challenges for successful
   adoption and use of cloud-based CDS that will require collaboration
   between biomedical informatics and computer science disciplines.
   Conclusion: Decision support in the cloud is feasible and may be a
   reasonable path toward achieving better support of clinical
   decision-making across the widest range of health care providers.
   Published by Elsevier B.V.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dixon, BE (Reprint Author), 410W 10th St,Suite 2000, Indianapolis, IN 46202 USA.
   Dixon, Brian E., Indiana Univ Purdue Univ, Sch Informat \& Comp, Indianapolis, IN 46202 USA.
   Dixon, Brian E.; Simonaitis, Linas, Regenstrief Inst Hlth Care, Ctr Biomed Informat, Indianapolis, IN 46202 USA.
   Dixon, Brian E., Hlth Serv Res \& Dev Serv, Vet Hlth Adm, Dept Vet Affairs, Ctr Excellence Implementing Evidence Based Practi, Indianapolis, IN 46202 USA.
   Simonaitis, Linas, Indiana Univ, Sch Med, Indianapolis, IN 46202 USA.
   Goldberg, Howard S.; Wright, Adam; Middleton, Blackford, Harvard Univ, Sch Med, Boston, MA 02115 USA.
   Goldberg, Howard S.; Paterno, Marilyn D.; Schaeffer, Molly; Hongsermeier, Tonya; Middleton, Blackford, Partners HealthCare Syst, Clin Informat Res \& Dev, Wellesley, MA 02481 USA.
   Wright, Adam, Brigham \& Womens Hosp, Dept Med, Boston, MA 02115 USA.}},
DOI = {{10.1016/j.artmed.2013.03.004}},
ISSN = {{0933-3657}},
Keywords = {{Log file analysis; Qualitative analysis; Computer-Assisted Decision
   Making; Clinical decision support systems; Medical informatics;
   Preventive health services; Knowledge management; Information
   dissemination}},
Keywords-Plus = {{ELECTRONIC HEALTH RECORDS; INFORMATION-TECHNOLOGY; CONTROLLED-TRIAL;
   PRIMARY-CARE; RANDOMIZED-TRIAL; MEDICAL-RECORD; SYSTEMS; REMINDERS;
   ALERTS; GUIDELINES}},
Research-Areas = {{Computer Science; Engineering; Medical Informatics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics}},
Author-Email = {{bedixon@regenstrief.org}},
Funding-Acknowledgement = {{Agency for Healthcare Research and Quality (AHRQ) {[}HHSA290200810010]}},
Funding-Text = {{This publication is derived from work supported under a contract with
   the Agency for Healthcare Research and Quality (AHRQ): Contract \#
   HHSA290200810010. The study sponsor played no role in the design,
   collection, or analysis of the data presented in the manuscript.
   Furthermore, the study sponsor did not play a role in writing or editing
   the manuscript. The views expressed in this article are those of the
   authors and do not necessarily reflect the position or policy of the
   Agency for Healthcare Research and Quality, Department of Veterans
   Affairs, or the United States government.}},
Number-of-Cited-References = {{54}},
Times-Cited = {{11}},
Journal-ISO = {{Artif. Intell. Med.}},
Doc-Delivery-Number = {{228NY}},
Unique-ID = {{ISI:000325194700007}},
}

@article{ ISI:000324620700003,
Author = {van den Berg, Sanne W. and Peters, Esmee J. and Kraaijeveld, J. Frank
   and Gielissen, Marieke F. M. and Prins, Judith B.},
Title = {{Usage of a Generic Web-Based Self-Management Intervention for Breast
   Cancer Survivors: Substudy Analysis of the BREATH Trial}},
Journal = {{JOURNAL OF MEDICAL INTERNET RESEARCH}},
Year = {{2013}},
Volume = {{15}},
Number = {{8}},
Month = {{AUG}},
Abstract = {{Background: Generic fully automated Web-based self-management
   interventions are upcoming, for example, for the growing number of
   breast cancer survivors. It is hypothesized that the use of these
   interventions is more individualized and that users apply a large amount
   of self-tailoring. However, technical usage evaluations of these types
   of interventions are scarce and practical guidelines are lacking.
   Objective: To gain insight into meaningful usage parameters to evaluate
   the use of generic fully automated Web-based interventions by assessing
   how breast cancer survivors use a generic self-management website. Final
   aim is to propose practical recommendations for researchers and
   information and communication technology (ICT) professionals who aim to
   design and evaluate the use of similar Web-based interventions.
   Methods: The BREAst cancer ehealTH (BREATH) intervention is a generic
   unguided fully automated website with stepwise weekly access and a fixed
   4-month structure containing 104 intervention ingredients (ie, texts,
   tasks, tests, videos). By monitoring https-server requests, technical
   usage statistics were recorded for the intervention group of the
   randomized controlled trial. Observed usage was analyzed by measures of
   frequency, duration, and activity. Intervention adherence was defined as
   continuous usage, or the proportion of participants who started using
   the intervention and continued to log in during all four phases. By
   comparing observed to minimal intended usage (frequency and activity),
   different user groups were defined.
   Results: Usage statistics for 4 months were collected from 70 breast
   cancer survivors (mean age 50.9 years). Frequency of logins/person
   ranged from 0 to 45, total duration/person from 0 to 2324 minutes (38.7
   hours), and activity from opening none to all intervention ingredients.
   31 participants continued logging in to all four phases resulting in an
   intervention adherence rate of 44.3\% (95\% CI 33.2-55.9). Nine nonusers
   (13\%), 30 low users (43\%), and 31 high users (44\%) were defined. Low
   and high users differed significantly on frequency (P<.001), total
   duration (P<.001), session duration (P=.009), and activity (P<.001).
   High users logged in an average of 21 times, had a mean session duration
   of 33 minutes, and opened on average 91\% of all ingredients. Signing
   the self-help contract (P<.001), reporting usefulness of ingredients
   (P=.003), overall satisfaction (P=.028), and user friendliness
   evaluation (P=.003) were higher in high users. User groups did not
   differ on age, education, and baseline distress.
   Conclusions: By reporting the usage of a self-management website for
   breast cancer survivors, the present study gained first insight into the
   design of usage evaluations of generic fully automated Web-based
   interventions. It is recommended to (1) incorporate usage statistics
   that reflect the amount of self-tailoring applied by users, (2) combine
   technical usage statistics with self-reported usefulness, and (3) use
   qualitative measures. Also, (4) a pilot usage evaluation should be a
   fixed step in the development process of novel Web-based interventions,
   and (5) it is essential for researchers to gain insight into the
   rationale of recorded and nonrecorded usage statistics.}},
Publisher = {{JMIR PUBLICATIONS, INC}},
Address = {{59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{van den Berg, SW (Reprint Author), Radboud Univ Nijmegen, Med Ctr, Dept Med Psychol, POB 9101, NL-6500 HB Nijmegen, Netherlands.
   van den Berg, Sanne W.; Gielissen, Marieke F. M.; Prins, Judith B., Radboud Univ Nijmegen, Med Ctr, Dept Med Psychol, NL-6500 HB Nijmegen, Netherlands.
   Peters, Esmee J., Radboud Univ Nijmegen, Med Ctr, Dept Med Oncol, NL-6500 HB Nijmegen, Netherlands.
   Kraaijeveld, J. Frank, IPPZ, ICT \& Consultancy Healthcare, Utrecht, Netherlands.}},
DOI = {{10.2196/jmir.2566}},
Article-Number = {{UNSP e170}},
ISSN = {{1438-8871}},
Keywords = {{usage evaluation; usage statistics; intervention adherence; user groups;
   exposure; Internet; Web-based intervention; breast cancer; log file
   analysis; website use}},
Keywords-Plus = {{CONFIRMATORY FACTOR-ANALYSIS; DEPRESSION SCALE; HOSPITAL ANXIETY;
   INTERNET; ADHERENCE; DISTRESS; TRAJECTORIES; ADJUSTMENT; EXPOSURE;
   SYSTEM}},
Research-Areas = {{Health Care Sciences \& Services; Medical Informatics}},
Web-of-Science-Categories  = {{Health Care Sciences \& Services; Medical Informatics}},
Author-Email = {{s.vandenberg@mps.umcn.nl}},
ResearcherID-Numbers = {{Prins, Judith/C-8522-2013}},
Funding-Acknowledgement = {{Pink Ribbon, the Netherlands}},
Funding-Text = {{The BREATH study is funded by Pink Ribbon, the Netherlands.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{2}},
Journal-ISO = {{J. Med. Internet Res.}},
Doc-Delivery-Number = {{220XN}},
Unique-ID = {{ISI:000324620700003}},
}

@article{ ISI:000318861100001,
Author = {Ben-Assuli, Ofir and Shabtai, Itamar and Leshno, Moshe},
Title = {{The impact of EHR and HIE on reducing avoidable admissions: controlling
   main differential diagnoses}},
Journal = {{BMC MEDICAL INFORMATICS AND DECISION MAKING}},
Year = {{2013}},
Volume = {{13}},
Month = {{APR 17}},
Abstract = {{Background: Many medical organizations have invested heavily in
   electronic health record (EHR) and health information exchange (HIE)
   information systems (IS) to improve medical decision-making and increase
   efficiency. Despite the potential interoperability advantages of such
   IS, physicians do not always immediately consult electronic health
   information, and this decision may result in decreased level of quality
   of care as well as unnecessary costs. This study sought to reveal the
   effect of EHR IS use on the physicians' admission decisions. It was
   hypothesizing the using EHR IS will result in more accurate and informed
   admission decisions, which will manifest through reduction in single-day
   admissions and in readmissions within seven days.
   Methods: This study used a track log-file analysis of a database
   containing 281,750 emergency department (ED) referrals in seven main
   hospitals in Israel. Log-files were generated by the system and provide
   an objective and unbiased measure of system usage, Thus allowing us to
   evaluate the contribution of an EHR IS, as well as an HIE network, to
   decision-makers (physicians). This is done by investigating whether EHR
   IS lead to improved medical outcomes in the EDs, which are known for
   their tight time constraints and overcrowding. The impact of EHR IS and
   HIE network was evaluated by comparing decisions on patients classified
   by five main differential diagnoses (DDs), made with or without viewing
   the patients' medical history via the EHR IS.
   Results: The results indicate a negative relationship between viewing
   medical history via EHR systems and the number of possibly redundant
   admissions. Among the DDs, we found information viewed most impactful
   for gastroenteritis, abdominal pain, and urinary tract infection in
   reducing readmissions within seven days, and for gastroenteritis,
   abdominal pain, and chest pain in reducing the single-day admissions'
   rate. Both indices are key quality measures in the health system. In
   addition, we found that interoperability (using external information
   provided online by health suppliers) contributed more to this reduction
   than local files, which are available only in the specific hospital.
   Thus, reducing the rate of redundant admissions by using external
   information produced larger odds ratios (of the beta coefficients; e.g.
   viewing external information on patients resulted in negative
   associations of 27.2\% regarding readmissions within seven days, and
   13\% for single-day admissions as compared with viewing local
   information on patients respectively).
   Conclusions: Viewing medical history via an EHR IS and using HIE network
   led to a reduction in the number of seven day readmissions and
   single-day admissions for all patients. Using external medical history
   may imply a more thorough patient examination that can help eliminate
   unnecessary admissions. Nevertheless, in most instances physicians did
   not view medical history at all, probably due to the limited resources
   available, combined with the stress of rapid turnover in ED units.}},
Publisher = {{BIOMED CENTRAL LTD}},
Address = {{236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ben-Assuli, O (Reprint Author), Ono Acad Coll, Fac Business Adm, Kiryat Ono, IL, Israel.
   Ben-Assuli, Ofir, Ono Acad Coll, Fac Business Adm, Kiryat Ono, IL, Israel.
   Shabtai, Itamar, Coll Management Acad Studies, Sch Econ \& Management, Rishon Leziyyon, IL, Israel.
   Ben-Assuli, Ofir; Leshno, Moshe, Tel Aviv Univ, Fac Management, Ramat Aviv, IL, Israel.
   Leshno, Moshe, Tel Aviv Univ, Fac Med, Ramat Aviv, IL, Israel.}},
DOI = {{10.1186/1472-6947-13-49}},
Article-Number = {{49}},
ISSN = {{1472-6947}},
Keywords = {{Medical decision analysis; Electronic health record; Health information
   exchange; Medical informatics; Interoperability; Health maintenance
   organization; IS efficiency}},
Keywords-Plus = {{HEALTH INFORMATION EXCHANGE; READMISSION; SURGERY; SYSTEMS}},
Research-Areas = {{Medical Informatics}},
Web-of-Science-Categories  = {{Medical Informatics}},
Author-Email = {{ofir.benassuli@gmail.com}},
Number-of-Cited-References = {{24}},
Times-Cited = {{7}},
Journal-ISO = {{BMC Med. Inform. Decis. Mak.}},
Doc-Delivery-Number = {{143IO}},
Unique-ID = {{ISI:000318861100001}},
}

@article{ ISI:000311702600018,
Author = {Krishnan, Srinivas and Snow, Kevin Z. and Monrose, Fabian},
Title = {{Trail of Bytes: New Techniques for Supporting Data Provenance and
   Limiting Privacy Breaches}},
Journal = {{IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY}},
Year = {{2012}},
Volume = {{7}},
Number = {{6}},
Pages = {{1876-1889}},
Month = {{DEC}},
Abstract = {{Forensic analysis of computer systems requires that one first identify
   suspicious objects or events, and then examine them in enough detail to
   form a hypothesis as to their cause and effect. Sadly, while our ability
   to gather vast amounts of data has improved significantly over the past
   two decades, it is all too often the case that we lack detailed
   information just when we need it the most. In this paper, we attempt to
   improve on the state of the art by providing a forensic platform that
   transparently monitors and records data access events within a
   virtualized environment using only the abstractions exposed by the
   hypervisor. Our approach monitors accesses to objects on disk and
   follows the causal chain of these accesses across processes, even after
   the objects are copied into memory. Our forensic layer records these
   transactions in a tamper evident version-based audit log that allows for
   faithful, and efficient, reconstruction of the recorded events and the
   changes they induced. To demonstrate the utility of our approach, we
   provide an extensive empirical evaluation, including a real-world case
   study demonstrating how our platform can be used to reconstruct valuable
   information about the what, when, and how, after a compromise has been
   detected. We also extend our earlier work by providing a tracking
   mechanism that can monitor data exfiltration attempts across multiple
   disks and also block attempts to copy data over the network.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Krishnan, S (Reprint Author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
   Krishnan, Srinivas; Snow, Kevin Z.; Monrose, Fabian, Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.}},
DOI = {{10.1109/TIFS.2012.2210217}},
ISSN = {{1556-6013}},
Keywords = {{Computer security; information security; intrusion detection; system
   recovery; checkpointing; virtual machine monitors; operating systems}},
Keywords-Plus = {{INFORMATION-FLOW}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{krishnan@cs.unc.edu
   kzsnow@cs.unc.edu
   fabian@cs.unc.edu}},
Funding-Acknowledgement = {{National Science Foundation {[}OCI-1127361, CNS-0915364]}},
Funding-Text = {{Manuscript received February 08, 2012; revised May 29, 2012; accepted
   June 10, 2012. Date of publication July 24, 2012; date of current
   version November 15, 2012. This work is supported in part by the
   National Science Foundation under awards OCI-1127361 and CNS-0915364.
   The associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Dinei A. Florencio.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{0}},
Journal-ISO = {{IEEE Trans. Inf. Forensic Secur.}},
Doc-Delivery-Number = {{045ND}},
Unique-ID = {{ISI:000311702600018}},
}

@article{ ISI:000309348200036,
Author = {Ben-Assuli, Ofir and Leshno, Moshe and Shabtai, Itamar},
Title = {{Using Electronic Medical Record Systems for Admission Decisions in
   Emergency Departments: Examining the Crowdedness Effect}},
Journal = {{JOURNAL OF MEDICAL SYSTEMS}},
Year = {{2012}},
Volume = {{36}},
Number = {{6}},
Pages = {{3795-3803}},
Month = {{DEC}},
Abstract = {{Many medical organizations have deployed electronic medical record (EMR)
   information systems (IS) to improve medical decision-making and increase
   efficiency. Despite their advantages, however, EMR IS may make less of a
   contribution in the stressful environment of an emergency department
   (ED) that operates under tight time constraints. The high level of
   crowdedness in the EDs itself can cause physicians to make medical
   decisions resulting in more unnecessary admissions and fewer necessary
   admissions. Thus this study evaluated the contribution of an EMR IS to
   physicians by investigating whether EMR IS leads to improved medical
   outcomes in points of care in EDs under different levels of crowdedness.
   For this purpose a track log-file analysis of a database containing 3.2
   million ED referrals in seven main hospitals in Israel (the whole
   population in these hospitals) was conducted. The findings suggest that
   viewing medical history via the EMR IS leads to better admission
   decisions, and reduces the number of possibly avoidable single-day
   admissions. Furthermore, although the ED can be very stressful
   especially on crowded days, physicians used EMR IS more on crowded days
   than on non-crowded days. These results have implications as regards the
   viability of EMR IS in complex, fast-paced environments.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ben-Assuli, O (Reprint Author), Ono Acad Coll, IL-55451 Kiryat Ono, Israel.
   Ben-Assuli, Ofir, Ono Acad Coll, IL-55451 Kiryat Ono, Israel.
   Leshno, Moshe, Tel Aviv Univ, IL-69978 Tel Aviv, Israel.
   Shabtai, Itamar, Coll Management Acad Studies, IL-75490 Rishon Leziyyon, Israel.}},
DOI = {{10.1007/s10916-012-9852-0}},
ISSN = {{0148-5598}},
Keywords = {{Crowdedness in emergency medicine; Electronic medical record; Medical
   informatics; Medical decision-making}},
Keywords-Plus = {{HEALTH INFORMATION EXCHANGE; CARE; RISK; REGRESSION; EXPERT}},
Research-Areas = {{Health Care Sciences \& Services; Medical Informatics}},
Web-of-Science-Categories  = {{Health Care Sciences \& Services; Medical Informatics}},
Author-Email = {{ofir.benassuli@gmail.com}},
Number-of-Cited-References = {{33}},
Times-Cited = {{8}},
Journal-ISO = {{J. Med. Syst.}},
Doc-Delivery-Number = {{014AU}},
Unique-ID = {{ISI:000309348200036}},
}

@article{ ISI:000307426400014,
Author = {Sato, Masaya and Yamauchi, Toshihiro},
Title = {{VMM-Based Log-Tampering and Loss Detection Scheme}},
Journal = {{JOURNAL OF INTERNET TECHNOLOGY}},
Year = {{2012}},
Volume = {{13}},
Number = {{4, SI}},
Pages = {{655-666}},
Month = {{JUL}},
Abstract = {{Logging information about the activities that placed in a computer is
   essential for understanding its behavior. In Homeland Security, the
   reliability of the computers used in their activities is of paramount
   importance. However, attackers can delete logs to hide evidence of their
   activities. Additionally, various problems may result in logs being
   lost. These problems decrease the dependability of Homeland Security. To
   address these problems, we previously proposed a secure logging scheme
   using a virtual machine monitor (VMM). The scheme collects logs and
   isolates them from the monitored OS. However, the scheme cannot store
   them automatically. Thus, logs in memory are lost when the computer is
   shutdown. Further, if the logs are not stored, it is impossible to
   detect incidents of tampering by comparing the logs of the monitored OS
   with those of the logging OS. To address these additional problems, this
   paper proposes a log-storing module and a tamper detection scheme. The
   log-storing module automatically stores logs collected by the logging
   module, and tamper detection is realized by comparing these stored log
   files with those of the monitored OS. We implemented the log-storing
   module and realized the tamper detection scheme. Evaluations reveal the
   effectiveness of the tamper detection scheme.}},
Publisher = {{NATL ILAN UNIV, JIT}},
Address = {{LIB \& INFORMATION CTR, ILAN, 26047, TAIWAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sato, M (Reprint Author), Okayama Univ, Grad Sch Nat Sci \& Technol, Okayama 7008530, Japan.
   Sato, Masaya; Yamauchi, Toshihiro, Okayama Univ, Grad Sch Nat Sci \& Technol, Okayama 7008530, Japan.}},
ISSN = {{1607-9264}},
EISSN = {{2079-4029}},
Keywords = {{Log protection; Detecting log tampering; Syslog; Digital forensics;
   Virtualization technology}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{m-sato@swlab.cs.okayama-u.ac.jp
   yamauchi@cs.okayama-u.ac.jp}},
Funding-Acknowledgement = {{Telecommunications Advancement Foundation (TAF);  {[}21700034]}},
Funding-Text = {{This research was partially supported by Grant-in-Aid for Scientific
   Research 21700034 and a grant from the Telecommunications Advancement
   Foundation (TAF).}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Journal-ISO = {{J. Internet Technol.}},
Doc-Delivery-Number = {{987OH}},
Unique-ID = {{ISI:000307426400014}},
}

@article{ ISI:000307074600004,
Author = {Yavuz, Attila A. and Ning, Peng and Reiter, Michael K.},
Title = {{BAF and FI-BAF: Efficient and Publicly Verifiable Cryptographic Schemes
   for Secure Logging in Resource-Constrained Systems}},
Journal = {{ACM TRANSACTIONS ON INFORMATION AND SYSTEM SECURITY}},
Year = {{2012}},
Volume = {{15}},
Number = {{2}},
Month = {{JUL}},
Abstract = {{Audit logs are an integral part of modern computer systems due to their
   forensic value. Protecting audit logs on a physically unprotected
   machine in hostile environments is a challenging task, especially in the
   presence of active adversaries. It is critical for such a system to have
   forward security and append-only properties such that when an adversary
   compromises a logging machine, she cannot forge or selectively delete
   the log entries accumulated before the compromise. Existing
   public-key-based secure logging schemes are computationally costly.
   Existing symmetric secure logging schemes are not publicly verifiable
   and open to certain attacks.
   In this article, we develop a new forward-secure and aggregate signature
   scheme called Blind-Aggregate-Forward (BAF), which is suitable for
   secure logging in resource-constrained systems. BAF is the only
   cryptographic secure logging scheme that can produce publicly
   verifiable, forward-secure and aggregate signatures with low
   computation, key/signature storage, and signature communication
   overheads for the loggers, without requiring any online trusted third
   party support. A simple variant of BAF also allows a fine-grained
   verification of log entries without compromising the security or
   computational efficiency of BAF. We prove that our schemes are secure in
   Random Oracle Model (ROM). We also show that they are significantly more
   efficient than all the previous publicly verifiable cryptographic secure
   logging schemes.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yavuz, AA (Reprint Author), N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA.
   Yavuz, Attila A.; Ning, Peng, N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA.
   Reiter, Michael K., Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.}},
DOI = {{10.1145/2240276.2240280}},
Article-Number = {{9}},
ISSN = {{1094-9224}},
EISSN = {{1557-7406}},
Keywords = {{Security; Design; Applied cryptography; digital signature; secure audit
   logging; forward security; signature aggregation}},
Keywords-Plus = {{SIGNATURES; AGGREGATE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{aayavuz@ncsu.edu
   pning@ncsu.edu
   reiter@cs.unc.edu}},
Funding-Acknowledgement = {{U.S. National Science Foundation (NSF) {[}CAREER-0447761, 0910767]; U.S.
   Army Research Office (ARO) {[}W911NF-08-1-0105]}},
Funding-Text = {{This work was supported by the U.S. National Science Foundation (NSF)
   under grants CAREER-0447761 and 0910767, and the U.S. Army Research
   Office (ARO) under grant W911NF-08-1-0105 managed by NCSU Secure Open
   Systems Initiative (SOSI).}},
Number-of-Cited-References = {{40}},
Times-Cited = {{1}},
Journal-ISO = {{ACM Trans. Inf. Syst. Secur.}},
Doc-Delivery-Number = {{982VX}},
Unique-ID = {{ISI:000307074600004}},
}

@article{ ISI:000304145500001,
Author = {Fusco, Francesco and Vlachos, Michail and Stoecklin, Marc Ph},
Title = {{Real-time creation of bitmap indexes on streaming network data}},
Journal = {{VLDB JOURNAL}},
Year = {{2012}},
Volume = {{21}},
Number = {{3}},
Pages = {{287-307}},
Month = {{JUN}},
Abstract = {{High-speed archival and indexing solutions of streaming traffic are
   growing in importance for applications such as monitoring, forensic
   analysis, and auditing. Many large institutions require fast solutions
   to support expedient analysis of historical network data, particularly
   in case of security breaches. However, ``turning back the clock{''} is
   not a trivial task. The first major challenge is that such a technology
   needs to support data archiving under extremely high-speed insertion
   rates. Moreover, the archives created have to be stored in a compressed
   format that is still amenable to indexing and search. The above
   requirements make general-purpose databases unsuitable for this task and
   dedicated solutions are required. This work describes a solution for
   high-speed archival storage, indexing, and data querying on network flow
   information. We make the two following important contributions: (a) we
   propose a novel compressed bitmap index approach that significantly
   reduces both CPU load and disk consumption and, (b) we introduce an
   online stream reordering mechanism that further reduces space
   requirements and improves the time for data retrieval. The reordering
   methodology is based on the principles of locality-sensitive hashing
   (LSH) and also of interest for other bitmap creation techniques. Because
   of the synergy of these two components, our solution can sustain data
   insertion rates that reach 500,000-1 million records per second. To put
   these numbers into perspective, typical commercial network flow
   solutions can currently process 20,000-60,000 flows per second. In
   addition, our system offers interactive query response times that enable
   administrators to perform complex analysis tasks on the fly. Our
   technique is directly amenable to parallel execution, allowing its
   application in domains that are challenged by large volumes of
   historical measurement data, such as network auditing, traffic behavior
   analysis, and large-scale data visualization in service provider
   networks.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Fusco, F (Reprint Author), IBM Res Zurich, Ruschlikon, Switzerland.
   Fusco, Francesco; Vlachos, Michail, IBM Res Zurich, Ruschlikon, Switzerland.
   Stoecklin, Marc Ph, IBM Res TJ Watson Res Ctr, Hawthorne, NY USA.}},
DOI = {{10.1007/s00778-011-0242-x}},
ISSN = {{1066-8888}},
EISSN = {{0949-877X}},
Keywords = {{Bitmap index; Locality sensitive hashing; Data stream; Data archive}},
Keywords-Plus = {{COMPRESSION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems}},
Author-Email = {{ffu@zurich.ibm.com}},
Number-of-Cited-References = {{50}},
Times-Cited = {{1}},
Journal-ISO = {{VLDB J.}},
Doc-Delivery-Number = {{943SM}},
Unique-ID = {{ISI:000304145500001}},
}

@article{ ISI:000308583900014,
Author = {Sun, Baozhou and Rangaraj, Dharanipathy and Boddu, Sunita and Goddu,
   Murty and Yang, Deshan and Palaniswaamy, Geethpriya and Yaddanapudi,
   Sridhar and Wooten, Omar and Mutic, Sasa},
Title = {{Evaluation of the efficiency and effectiveness of independent dose
   calculation followed by machine log file analysis against conventional
   measurement based IMRT QA}},
Journal = {{JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS}},
Year = {{2012}},
Volume = {{13}},
Number = {{5}},
Pages = {{140-154}},
Abstract = {{Experimental methods are commonly used for patient-specific IMRT
   delivery verification. There are a variety of IMRT QA techniques which
   have been proposed and clinically used with a common understanding that
   not one single method can detect all possible errors. The aim of this
   work was to compare the efficiency and effectiveness of independent dose
   calculation followed by machine log file analysis to conventional
   measurement-based methods in detecting errors in IMRT delivery. Sixteen
   IMRT treatment plans (5 head-and-neck, 3 rectum, 3 breast, and 5
   prostate plans) created with a commercial treatment planning system
   (TPS) were recalculated on a QA phantom. All treatment plans underwent
   ion chamber (IC) and 2D diode array measurements. The same set of plans
   was also recomputed with another commercial treatment planning system
   and the two sets of calculations were compared. The deviations between
   dosimetric measurements and independent dose calculation were evaluated.
   The comparisons included evaluations of DVHs and point doses calculated
   by the two TPS systems. Machine log files were captured during
   pretreatment composite point dose measurements and analyzed to verify
   data transfer and performance of the delivery machine. Average deviation
   between IC measurements and point dose calculations with the two TPSs
   for head-and-neck plans were 1.2 +/- 1.3\% and 1.4 +/- 1.6\%,
   respectively. For 2D diode array measurements, the mean gamma value with
   3\% dose difference and 3 mm distance-to-agreement was within 1.5\% for
   13 of 16 plans. The mean 3D dose differences calculated from two TPSs
   were within 3\% for head-and-neck cases and within 2\% for other plans.
   The machine log file analysis showed that the gantry angle, jaw
   position, collimator angle, and MUs were consistent as planned, and
   maximal MLC position error was less than 0.5 mm. The independent dose
   calculation followed by the machine log analysis takes an average 47 +/-
   6 minutes, while the experimental approach (using IC and 2D diode array
   measurements) takes an average about 2 hours in our clinic. Independent
   dose calculation followed by machine log file analysis can be a reliable
   tool to verify IMRT treatments. Additionally, independent dose
   calculations have the potential to identify several problems
   (heterogeneity calculations, data corruptions, system failures) with the
   primary TPS, which generally are not identifiable with a
   measurement-based approach. Additionally, machine log file analysis can
   identify many problems (gantry, collimator, jaw setting) which also may
   not be detected with a measurement-based approach. Machine log file
   analysis could also detect performance problems for individual MLC
   leaves which could be masked in the analysis of a measured fluence.}},
Publisher = {{MULTIMED INC}},
Address = {{66 MARTIN ST, TORONTO, ON L9T 2R2, CANADA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Rangaraj, D (Reprint Author), Washington Univ, Sch Med, Dept Radiat Oncol, St Louis, MO 63130 USA.
   Sun, Baozhou; Rangaraj, Dharanipathy; Goddu, Murty; Yang, Deshan; Yaddanapudi, Sridhar; Wooten, Omar; Mutic, Sasa, Washington Univ, Sch Med, Dept Radiat Oncol, St Louis, MO 63130 USA.
   Rangaraj, Dharanipathy; Palaniswaamy, Geethpriya, Scott \& White Healthcare Syst, Dept Radiat Oncol, Temple, TX USA.
   Boddu, Sunita, Univ Calif Davis, Dept Radiat Oncol, Sacramento, CA 95817 USA.}},
ISSN = {{1526-9914}},
Keywords = {{quality assurance; IMRT; dose calculations; machine log file}},
Keywords-Plus = {{MODULATED RADIATION-THERAPY; STEP-AND-SHOOT; QUALITY-ASSURANCE;
   TREATMENT PLAN; VERIFICATION; DELIVERY; DOSIMETRY; VALIDATE; DOCUMENT;
   RAPIDARC}},
Research-Areas = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Web-of-Science-Categories  = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Author-Email = {{drangaraj@swmail.sw.org}},
Number-of-Cited-References = {{31}},
Times-Cited = {{4}},
Journal-ISO = {{J. Appl. Clin. Med. Phys}},
Doc-Delivery-Number = {{003BT}},
Unique-ID = {{ISI:000308583900014}},
}

@article{ ISI:000306380700010,
Author = {Bauer, Kathleen and Peterson-Hart, Alice},
Title = {{Does faceted display in a library Catalog increase use of subject
   headings?}},
Journal = {{LIBRARY HI TECH}},
Year = {{2012}},
Volume = {{30}},
Number = {{2}},
Pages = {{347-358}},
Abstract = {{Purpose - This research aimed to explore whether subject facets would
   increase patron use of subject headings in a faceted (Yufind) versus a
   non-faceted (Orbis) catalog interface at Yale University.
   Design/methodology/approach - Two rounds of think aloud protocol testing
   were done with students to measure the acceptance and use of subject
   heading facets. After a faceted and non-faceted interface were
   implemented, side-by-side, log file analysis was employed to measure and
   compare use of subject headings in both interfaces.
   Findings - Initial usability testing showed that patrons would try
   facets, but had some problems effectively using them. In production from
   January to May 2011, at least one facet was used in 25.4 percent of
   Yufind searches, and subject facets were used in 5.1 percent of
   searches, while in Orbis subject headings were used in 6.4 percent of
   searches. Facets were used less than subject heading links in records in
   either interface.
   Practical implications - The findings are important as libraries spend
   significant staff time adding subject headings to records, and their use
   by patrons is declining. As measured in two production systems running
   on exactly the same catalog records, subject heading facets did not
   successfully increase use of subject headings. Without further
   refinements, faceted display may not be a successful strategy to
   increase patron use of subject headings.
   Originality/value - A comparison of patron generated subject heading use
   in two concurrently running interfaces, one faceted and one not, has not
   been done before.}},
Publisher = {{EMERALD GROUP PUBLISHING LIMITED}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bauer, K (Reprint Author), Yale Univ Lib, New Haven, CT 06520 USA.
   Bauer, Kathleen; Peterson-Hart, Alice, Yale Univ Lib, New Haven, CT 06520 USA.}},
DOI = {{10.1108/07378831211240003}},
ISSN = {{0737-8831}},
Keywords = {{Next gen OPAC; Usability; Facets; Subject headings; Subject cataloguing;
   Subject heading lists}},
Keywords-Plus = {{ONLINE CATALOGS; QUERIES}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Author-Email = {{kathleen.bauer@yale.edu}},
Number-of-Cited-References = {{19}},
Times-Cited = {{1}},
Journal-ISO = {{Libr. Hi Tech}},
Doc-Delivery-Number = {{973SS}},
Unique-ID = {{ISI:000306380700010}},
}

@article{ ISI:000298524300051,
Author = {Lee, Young-Jin},
Title = {{Developing an efficient computational method that estimates the ability
   of students in a Web-based learning environment}},
Journal = {{COMPUTERS \& EDUCATION}},
Year = {{2012}},
Volume = {{58}},
Number = {{1}},
Pages = {{579-589}},
Month = {{JAN}},
Abstract = {{This paper presents a computational method that can efficiently estimate
   the ability of students from the log files of a Web-based learning
   environment capturing their problem solving processes. The computational
   method developed in this study approximates the posterior distribution
   of the student's ability obtained from the conventional Bayes Modal
   Estimation (BME) approach to a simple Gaussian function in order to
   reduce the amount of computations required in the subsequent ability
   update processes. To verify the correctness and usefulness of this
   method, the abilities of 407 college students who solved 61 physics
   problems in a Web-based learning environment were estimated from the log
   files of the learning environment. The reduced chi-squared statistic and
   Pearson's chi-square test for the goodness of fit indicate that the
   estimated abilities were able to successfully explain the observed
   problem solving performance of students within error. The educational
   implications of estimating the ability of students in Web-based learning
   environments were also discussed. (C) 2011 Elsevier Ltd. All rights
   reserved.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lee, YJ (Reprint Author), Univ Kansas, 1122 W Campus Rd,Room 413, Lawrence, KS 66045 USA.
   Univ Kansas, Lawrence, KS 66045 USA.}},
DOI = {{10.1016/j.compedu.2011.09.008}},
ISSN = {{0360-1315}},
Keywords = {{Ability estimation; Educational data mining; Item response theory; Log
   file analysis; Web-based learning environment}},
Keywords-Plus = {{ITEM RESPONSE THEORY; ADAPTIVE TEST; DESIGN; SYSTEM}},
Research-Areas = {{Computer Science; Education \& Educational Research}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Education \&
   Educational Research}},
Author-Email = {{yjlee@ku.edu}},
Funding-Acknowledgement = {{University of Kansas}},
Funding-Text = {{The author thanks Prof. D. E. Pritchard for allowing to analyze the log
   files from the 8.01 courses. The author also acknowledges supports from
   the University of Kansas.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{8}},
Journal-ISO = {{Comput. Educ.}},
Doc-Delivery-Number = {{868LH}},
Unique-ID = {{ISI:000298524300051}},
}

@article{ ISI:000292542600002,
Author = {Cocea, Mihaela and Weibelzahl, Stephan},
Title = {{Disengagement Detection in Online Learning: Validation Studies and
   Perspectives}},
Journal = {{IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES}},
Year = {{2011}},
Volume = {{4}},
Number = {{2}},
Pages = {{114-124}},
Month = {{APR-JUN}},
Abstract = {{Learning environments aim to deliver efficacious instruction, but rarely
   take into consideration the motivational factors involved in the
   learning process. However, motivational aspects like engagement play an
   important role in effective learning-engaged learners gain more.
   E-Learning systems could be improved by tracking students' disengagement
   that, in turn, would allow personalized interventions at appropriate
   times in order to reengage students. This idea has been exploited
   several times for Intelligent Tutoring Systems, but not yet in other
   types of learning environments that are less structured. To address this
   gap, our research looks at online learning-content-delivery systems
   using educational data mining techniques. Previously, several attributes
   relevant for disengagement prediction were identified by means of
   log-file analysis on HTML-Tutor, a web-based learning environment. In
   this paper, we investigate the extendibility of our approach to other
   systems by studying the relevance of these attributes for predicting
   disengagement in a different e-learning system. To this end, two
   validation studies were conducted indicating that the previously
   identified attributes are pertinent for disengagement prediction, and
   two new meta-attributes derived from log-data observations improve
   prediction and may potentially be used for automatic log-file
   annotation.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cocea, M (Reprint Author), Univ London, Birkbeck Coll, London Knowledge Lab, Dept Comp Sci \& Informat Syst, 23-29 Emerald St, London WC1N 3QS, England.
   Cocea, Mihaela, Univ London, Birkbeck Coll, London Knowledge Lab, Dept Comp Sci \& Informat Syst, London WC1N 3QS, England.
   Weibelzahl, Stephan, Natl Coll Ireland, Sch Comp, IFSC, Dublin 1, Ireland.}},
DOI = {{10.1109/TLT.2010.14}},
ISSN = {{1939-1382}},
Keywords = {{e-Learning; educational data mining; disengagement prediction; log-file
   analysis}},
Keywords-Plus = {{MODEL}},
Research-Areas = {{Computer Science; Education \& Educational Research}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Education \&
   Educational Research}},
Author-Email = {{mihaela@dcs.bbk.ac.uk
   sweibelzahl@ncirl.ie}},
ResearcherID-Numbers = {{Weibelzahl, Stephan/}},
ORCID-Numbers = {{Weibelzahl, Stephan/0000-0001-5919-6552}},
Number-of-Cited-References = {{38}},
Times-Cited = {{4}},
Journal-ISO = {{IEEE Trans. Learn. Technol.}},
Doc-Delivery-Number = {{789UT}},
Unique-ID = {{ISI:000292542600002}},
}

@article{ ISI:000291632400005,
Author = {Nakatani, Kazuo and Chuang, Ta-Tao},
Title = {{A web analytics tool selection method: an analytical hierarchy process
   approach}},
Journal = {{INTERNET RESEARCH}},
Year = {{2011}},
Volume = {{21}},
Number = {{2}},
Pages = {{171-186}},
Abstract = {{Purpose - The purpose of this paper is to develop an analytical
   hierarchy process (AHP)-based selection model for choosing a web
   analytics product/service that meets organizational needs.
   Design/methodology/approach - The research objective is achieved through
   modeling and empirical validation.
   Findings - While more criteria could be added, the proposed selection
   model provides a feasible approach to choosing a web analytics
   product/service. Cost- and risk-related criteria are weighed heavier
   than those of technical capabilities. Tools based on the page tagging
   method are more popular than those based on transaction log file
   analysis. The level of technology savvy might play a role in the
   application of the selection model.
   Research limitations/implications - The development of web analytics
   products/service is still evolving. Thus, as the use of web analytics
   increases, more criteria might be identified and added to the model. The
   model is validated by groups for different sectors. In the future, it is
   suggested to conduct a similar study with one sector by different
   groups.
   Practical implications - The selection model provides a process in which
   practitioners can systematically evaluate pros and cons of web analytics
   products/services. The selection model includes a comprehensive list of
   criteria that vendors of web analytics products/services can use to
   benchmark their products. Following this model, an organization
   contemplating the use of web analytics will more likely find one
   product/service that accommodates organizational and technological
   characteristics.
   Originality/value - A sufficiently comprehensive list of qualitative and
   quantitative criteria for evaluating web analytics products/services was
   developed. Practitioners will be able to use the model to select a
   proper tool. In academia, the article fills a gap in literature that
   might bring academics' interests in this area.}},
Publisher = {{EMERALD GROUP PUBLISHING LIMITED}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chuang, TT (Reprint Author), Gonzaga Univ, Sch Business Adm, Spokane, WA 99258 USA.
   Chuang, Ta-Tao, Gonzaga Univ, Sch Business Adm, Spokane, WA 99258 USA.
   Nakatani, Kazuo, Florida Gulf Coast Univ, Lutgert Coll Business, Ft Myers, FL USA.}},
DOI = {{10.1108/10662241111123757}},
ISSN = {{1066-2243}},
Keywords = {{Web design; Data analysis; Analytical hierarchy process}},
Keywords-Plus = {{SOFTWARE SELECTION; DECISION}},
Research-Areas = {{Business \& Economics; Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Business; Computer Science, Information Systems; Telecommunications}},
Author-Email = {{knakatan@fgcu.edu}},
Number-of-Cited-References = {{17}},
Times-Cited = {{3}},
Journal-ISO = {{Internet Res.}},
Doc-Delivery-Number = {{777OL}},
Unique-ID = {{ISI:000291632400005}},
}

@article{ ISI:000298051000002,
Author = {Vahey, Philip and Brecht, John and Patton, Charles and Rafanan, Ken and
   Cheng, Britte Haugan},
Title = {{Investigating Collaborative Innovation in a Virtual World Task}},
Journal = {{JOURNAL OF UNIVERSAL COMPUTER SCIENCE}},
Year = {{2011}},
Volume = {{17}},
Number = {{12}},
Pages = {{1638-1658}},
Abstract = {{While much has been written about the importance of innovation, there is
   still much to learn about the specific behaviours that lead to
   innovation among groups. In this paper we introduce a framework of
   innovation based on behaviours identified as being conducive to
   collaborative innovation. We also report on a study of a task designed
   to elicit innovation supportive behaviours in a virtual world
   environment. The task resulted in a variety of solutions and a range of
   participant behaviours, and specific behaviours were correlated with
   innovative solutions. Multiple forms of analysis provided unique
   insights into participant behaviour, and the combined set of analyses
   led to a richer understanding of participant behaviour than found
   through any individual analysis. The paper also presents implications
   for how organizations may scaffold group interactions to increase the
   chances of successful collaborative innovation.}},
Publisher = {{GRAZ UNIV TECHNOLGOY, INST INFORMATION SYSTEMS COMPUTER MEDIA-IICM}},
Address = {{INFFELDGASSE 16C, GRAZ, A-8010, AUSTRIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Vahey, P (Reprint Author), SRI Int, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA.
   Vahey, Philip; Brecht, John; Patton, Charles; Rafanan, Ken; Cheng, Britte Haugan, SRI Int, Menlo Pk, CA 94025 USA.}},
ISSN = {{0948-695X}},
Keywords = {{Innovation; Collaboration; Virtual Worlds; Log File Analysis; Word-Space
   Models}},
Keywords-Plus = {{DESIGN}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Computer Science, Theory \&
   Methods}},
Author-Email = {{philip.vahey@sri.com
   john.brecht@sri.com
   charles.patton@sri.com
   ken.rafanan@sri.com
   britte.cheng@sri.com}},
Funding-Acknowledgement = {{National Science Foundation {[}0745694]}},
Funding-Text = {{The authors would like to thank Valerie Crawford for her instrumental
   role in this project, as well as Yukie Toyama, Julie Remold and Geneva
   Haertel for their contributions to the project. We would also like to
   thank the participants who were willing to engage with the munchkin
   task. This manuscript is based upon work supported in part by the
   National Science Foundation under Grant No. 0745694. Any opinions,
   findings, and conclusions or recommendations expressed in this material
   are those of the author(s) and do not necessarily reflect the views of
   the National Science Foundation.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{0}},
Journal-ISO = {{J. Univers. Comput. Sci.}},
Doc-Delivery-Number = {{861WR}},
Unique-ID = {{ISI:000298051000002}},
}

@article{ ISI:000278543600012,
Author = {Luis Ortega, Jose and Aguillo, Isidro},
Title = {{Differences between web sessions according to the origin of their visits}},
Journal = {{JOURNAL OF INFORMETRICS}},
Year = {{2010}},
Volume = {{4}},
Number = {{3}},
Pages = {{331-337}},
Month = {{JUL}},
Abstract = {{The aim of this paper is to characterize the distribution of number of
   hits and spent time by web session. It also expects to find if there are
   significant differences between the length and the duration of a session
   with regard to the point of access-search engine, link or root. Web
   usage mining was used to analyse 17,174 web sessions that were
   identified from the webometrics.info web site. Results show that both
   distribution of length and duration follow an exponential decay.
   Significant differences between the different origins of the visits were
   also found, being the search engines' users those who spent most time
   and did more clicks in their sessions. We conclude that a good SEO
   policy would be justified, because search engines are the principal
   intermediaries to this web site. (C) 2010 Elsevier Ltd. All rights
   reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ortega, JL (Reprint Author), CSIC, Serrano 113, Madrid 28006, Spain.
   Luis Ortega, Jose, CSIC, Madrid 28006, Spain.
   Aguillo, Isidro, CSIC, CCHS, Cybermetr Lab, Madrid 28037, Spain.}},
DOI = {{10.1016/j.joi.2010.02.001}},
ISSN = {{1751-1577}},
EISSN = {{1875-5879}},
Keywords = {{Webometrics; Web usage mining; Web session; Log file analysis; Search
   engines; Navigational patterns}},
Keywords-Plus = {{LOG ANALYSIS; SEARCH; IDENTIFICATION}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Author-Email = {{jortega@orgc.csic.es
   isidro.aguillo@cchs.csic.es}},
ResearcherID-Numbers = {{Aguillo, Isidro/}},
ORCID-Numbers = {{Aguillo, Isidro/0000-0001-8927-4873}},
Number-of-Cited-References = {{32}},
Times-Cited = {{5}},
Journal-ISO = {{J. Informetr.}},
Doc-Delivery-Number = {{607YQ}},
Unique-ID = {{ISI:000278543600012}},
}

@article{ ISI:000275800200013,
Author = {Hopfgartner, Frank and Urruty, Thierry and Bermejo Lopez, Pablo and
   Villa, Robert and Jose, Joemon M.},
Title = {{Simulated evaluation of faceted browsing based on feature selection}},
Journal = {{MULTIMEDIA TOOLS AND APPLICATIONS}},
Year = {{2010}},
Volume = {{47}},
Number = {{3, SI}},
Pages = {{631-662}},
Month = {{MAY}},
Abstract = {{In this paper we explore the limitations of facet based browsing which
   uses sub-needs of an information need for querying and organising the
   search process in video retrieval. The underlying assumption of this
   approach is that the search effectiveness will be enhanced if such an
   approach is employed for interactive video retrieval using textual and
   visual features. We explore the performance bounds of a faceted system
   by carrying out a simulated user evaluation on TRECVid data sets, and
   also on the logs of a prior user experiment with the system. We first
   present a methodology to reduce the dimensionality of features by
   selecting the most important ones. Then, we discuss the simulated
   evaluation strategies employed in our evaluation and the effect on the
   use of both textual and visual features. Facets created by users are
   simulated by clustering video shots using textual and visual features.
   The experimental results of our study demonstrate that the faceted
   browser can potentially improve the search effectiveness.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hopfgartner, F (Reprint Author), Univ Glasgow, Dept Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.
   Hopfgartner, Frank; Villa, Robert; Jose, Joemon M., Univ Glasgow, Dept Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.
   Urruty, Thierry, Univ Lille 1, F-59655 Villeneuve Dascq, France.
   Bermejo Lopez, Pablo, Univ Castilla La Mancha, Intelligent Syst \& Data Min Grp SIMD, Albacete, Spain.}},
DOI = {{10.1007/s11042-009-0340-6}},
ISSN = {{1380-7501}},
Keywords = {{Video retrieval; Feature selection; Clustering; Log file analysis}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic}},
Author-Email = {{hopfgarf@dcs.gla.ac.uk
   thierry.urruty@lifl.fr
   pbermejo@dci.uclm.es
   villar@dcs.gla.ac.uk
   jj@dcs.gla.ac.uk}},
ResearcherID-Numbers = {{Jose, Joemon/}},
ORCID-Numbers = {{Jose, Joemon/0000-0001-9228-1759}},
Funding-Acknowledgement = {{European Commission {[}FP6-027122-SALERO]; JCCM {[}PCI08-0048-8577]; MEC
   {[}TIN2007-67418-C03-01]; FEDER}},
Funding-Text = {{This research was supported by the European Commission under contract
   FP6-027122-SALERO. The third author was supported by the JCCM under
   project (PCI08-0048-8577), MEC under project (TIN2007-67418-C03-01) and
   FEDER funds. It is the view of the authors but not necessarily the view
   of the community.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{2}},
Journal-ISO = {{Multimed. Tools Appl.}},
Doc-Delivery-Number = {{572BC}},
Unique-ID = {{ISI:000275800200013}},
}

@article{ ISI:000274324200002,
Author = {Kelders, Saskia M. and van Gemert-Pijnen, Julia E. W. C. and Werkman,
   Andrea and Seydel, Erwin R.},
Title = {{Evaluation of a web-based lifestyle coach designed to maintain a healthy
   bodyweight}},
Journal = {{JOURNAL OF TELEMEDICINE AND TELECARE}},
Year = {{2010}},
Volume = {{16}},
Number = {{1}},
Pages = {{3-7}},
Abstract = {{We evaluated a web-based intervention, the Healthy Weight Assistant
   (HWA), which was designed to help people with a healthy bodyweight, or
   those who are slightly overweight, to achieve and maintain a healthy
   weight. Four evaluation methods were used: (1) pre- and post-test
   questionnaires; (2) real time usability-tests; (3) log-file analysis;
   (4) qualitative analysis of forum posts, email messages and free-text
   responses in the questionnaires. A total of 703 respondents received
   access to the HWA. Six weeks after receiving access, 431 respondents
   completed a second questionnaire. The enthusiastic responses showed that
   many people were interested in using an interactive online application
   to support achieving and maintaining a healthy weight. The preliminary
   results suggest that improvements with respect to motivation may lead to
   large effects, yet require only small changes in the design of the HWA.
   Sending automatic tailored reminders may enhance motivation to keep
   using the application. Motivation to change behaviour may be enhanced by
   emphasizing goal setting and visualizing progress.}},
Publisher = {{ROYAL SOC MEDICINE PRESS LTD}},
Address = {{1 WIMPOLE STREET, LONDON W1G 0AE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kelders, SM (Reprint Author), Univ Twente, Dept Psychol \& Commun Hlth \& Risk, Fac Behav Sci, Afd PCGR Ci H403,POB 217, NL-7500 AE Enschede, Netherlands.
   Kelders, Saskia M.; van Gemert-Pijnen, Julia E. W. C.; Seydel, Erwin R., Univ Twente, Dept Psychol \& Commun Hlth \& Risk, Fac Behav Sci, NL-7500 AE Enschede, Netherlands.
   Werkman, Andrea, Netherlands Nutr Ctr, The Hague, Netherlands.
   Kelders, Saskia M., Natl Inst Publ Hlth \& Environm, NL-3720 BA Bilthoven, Netherlands.}},
DOI = {{10.1258/jtt.2009.001003}},
ISSN = {{1357-633X}},
Keywords-Plus = {{PHYSICAL-ACTIVITY; BEHAVIOR-CHANGE; WEIGHT-LOSS; CONTROLLED-TRIAL;
   PROGRAM}},
Research-Areas = {{Health Care Sciences \& Services}},
Web-of-Science-Categories  = {{Health Care Sciences \& Services}},
Author-Email = {{s.m.kelders@utwente.nl}},
Funding-Acknowledgement = {{Netherlands Nutrition Centre}},
Funding-Text = {{We are grateful for funding from the Netherlands Nutrition Centre.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{5}},
Journal-ISO = {{J. Telemed. Telecare}},
Doc-Delivery-Number = {{552WJ}},
Unique-ID = {{ISI:000274324200002}},
}

@article{ ISI:000271402200010,
Author = {Woltering, Vanessa and Herrler, Andreas and Spitzer, Klaus and
   Spreckelsen, Cord},
Title = {{Blended learning positively affects students' satisfaction and the role
   of the tutor in the problem-based learning process: results of a
   mixed-method evaluation}},
Journal = {{ADVANCES IN HEALTH SCIENCES EDUCATION}},
Year = {{2009}},
Volume = {{14}},
Number = {{5}},
Pages = {{725-738}},
Month = {{DEC}},
Abstract = {{Problem-based learning (PBL) is an established didactic approach in
   medical education worldwide. The impact of PBL depends on the tutors'
   quality and the students' motivation. To enhance students' motivation
   and satisfaction and to overcome the problems with the changing quality
   of tutors, online learning and face-to-face classes were systematically
   combined resulting in a blended learning scenario (blended problem-based
   learning-bPBL). The study aims at determining whether bPBL increases the
   students' motivation and supports the learning process with respect to
   the students' cooperation, their orientation, and more reliable
   tutoring. The blended PBL was developed in a cooperation of students and
   teachers. The well-established Seven Jump-scheme of PBL was carefully
   complemented by eLearning modules. On the first training day of bPBL the
   students start to work together with the online program, but without a
   tutor, on the final training day the tutor participates in the meeting
   for additional help and feedback. The program was evaluated by a
   mixed-method study. The traditional PBL course was compared with the
   blended PBL by means of qualitative and quantitative questionnaires,
   standardized group interviews, and students' test results. In addition
   log-files were analyzed. A total of 185 third-year students and 14
   tutors took part in the study. Motivation, subjective learning gains and
   satisfaction achieved significantly higher ratings by the bPBL students
   compared with the students learning by traditional PBL. The tutors'
   opinion and the test results showed no differences between the groups.
   Working with the web-based learning environment was assessed as very
   good by the students. According to the log-file analysis, the web-based
   learning module was frequently used and improved the cooperation during
   the self-directed learning.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Woltering, V (Reprint Author), Rhein Westfal TH Aachen, Dept Med Informat, Pauwelsstr 30, D-52074 Aachen, Germany.
   Woltering, Vanessa; Spitzer, Klaus; Spreckelsen, Cord, Rhein Westfal TH Aachen, Dept Med Informat, D-52074 Aachen, Germany.
   Herrler, Andreas, Rhein Westfal TH Aachen, Dept Anat, D-52074 Aachen, Germany.
   Herrler, Andreas, Maastricht Univ, Dept Anat \& Embryol, Maastricht, Netherlands.}},
DOI = {{10.1007/s10459-009-9154-6}},
ISSN = {{1382-4996}},
Keywords = {{Blended learning; Hybrid learning; Medical education; PBL; Problem-based
   learning}},
Keywords-Plus = {{OUTCOMES}},
Research-Areas = {{Education \& Educational Research; Health Care Sciences \& Services}},
Web-of-Science-Categories  = {{Education \& Educational Research; Education, Scientific Disciplines;
   Health Care Sciences \& Services}},
Author-Email = {{vanessa.woltering@rwth-aachen.de}},
Funding-Acknowledgement = {{Department of Medical Statistics}},
Funding-Text = {{The authors thank Timm Dirrichs and Marcel Louis for their contribution
   and ideas developing the bPBL concept, Christina Menzies for
   proof-reading the manuscript, and the Department of Medical Statistics,
   RWTH Aachen for statistical advice. Last but not least, we like to thank
   the anonymous reviewers for their detailed and very helpful criticism
   and suggestions for improvement.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{42}},
Journal-ISO = {{Adv. Health Sci. Educ.}},
Doc-Delivery-Number = {{514NS}},
Unique-ID = {{ISI:000271402200010}},
}

@article{ ISI:000270344900002,
Author = {Cocea, Mihaela and Weibelzahl, Stephan},
Title = {{Log file analysis for disengagement detection in e-Learning environments}},
Journal = {{USER MODELING AND USER-ADAPTED INTERACTION}},
Year = {{2009}},
Volume = {{19}},
Number = {{4}},
Pages = {{341-385}},
Month = {{OCT}},
Abstract = {{Most e-Learning systems store data about the learner's actions in log
   files, which give us detailed information about learner behaviour. Data
   mining and machine learning techniques can give meaning to these data
   and provide valuable information for learning improvement. One area that
   is of particular importance in the design of e-Learning systems is
   learner motivation as it is a key factor in the quality of learning and
   in the prevention of attrition. One aspect of motivation is engagement,
   a necessary condition for effective learning. Using data mining
   techniques for log file analysis, our research investigates the
   possibility of predicting users' level of engagement, with a focus on
   disengaged learners. As demonstrated previously across two different
   e-Learning systems, HTML-Tutor and iHelp, disengagement can be predicted
   by monitoring the learners' actions (e.g. reading pages and taking
   test/quizzes). In this paper we present the findings of three studies
   that refine this prediction approach. Results from the first study show
   that two additional reading speed attributes can increase the accuracy
   of prediction. The second study suggests that distinguishing between two
   different patterns of disengagement (spending a long time on a page/test
   and browsing quickly through pages/tests) may improve prediction in some
   cases. The third study demonstrates the influence of exploratory
   behaviour on prediction, as most users at the first login familiarize
   themselves with the system before starting to learn.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cocea, M (Reprint Author), Univ London, Birkbeck Coll, London Knowledge Lab, 23-29 Emerald St, London WC1N 3Q, England.
   Cocea, Mihaela, Univ London, Birkbeck Coll, London Knowledge Lab, London WC1N 3Q, England.
   Cocea, Mihaela; Weibelzahl, Stephan, Natl Coll Ireland, Sch Informat, Dublin 1, Ireland.}},
DOI = {{10.1007/s11257-009-9065-5}},
ISSN = {{0924-1868}},
Keywords = {{e-Learning; Disengagement; Log files analysis; Educational data mining;
   Motivation; User modelling}},
Keywords-Plus = {{MOTIVATION; KNOWLEDGE; SYSTEM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Cybernetics}},
Author-Email = {{mihaela@dcs.bbk.ac.uk
   sweibelzahl@ncirl.ie}},
ResearcherID-Numbers = {{Weibelzahl, Stephan/}},
ORCID-Numbers = {{Weibelzahl, Stephan/0000-0001-5919-6552}},
Number-of-Cited-References = {{35}},
Times-Cited = {{10}},
Journal-ISO = {{User Model. User-Adapt. Interact.}},
Doc-Delivery-Number = {{500ZF}},
Unique-ID = {{ISI:000270344900002}},
}

@article{ ISI:000263456400003,
Author = {Ortega, Jose-Luis and Aguillo, Isidro F.},
Title = {{Web usage data mining}},
Journal = {{PROFESIONAL DE LA INFORMACION}},
Year = {{2009}},
Volume = {{18}},
Number = {{1}},
Pages = {{20-26}},
Month = {{JAN-FEB}},
Abstract = {{The analysis of web usage information is an important cybermetric tool
   for describing the visits and visitors to a website, and their
   navigation behaviour which can help in designing the structure and
   contents of the webpages. The paper describes the main concepts (log
   file, session, user) and introduces both manual and automated techniques
   to study the log files. Finally, the counters and trackers are
   described, paying special attention to the statistics offered by two
   systems: Google Analytics and StatCounter}},
Publisher = {{EPI}},
Address = {{APARTADO 32 280, BARCELONA, 08080, SPAIN}},
Type = {{Article}},
Language = {{Spanish}},
Affiliation = {{Ortega, JL (Reprint Author), CSIC, Div Programac Cienti, Serrano 113, Madrid 28006, Spain.
   Ortega, Jose-Luis, CSIC, Div Programac Cienti, Madrid 28006, Spain.
   Aguillo, Isidro F., CSIC, CCHS, Lab Cibermetria, Madrid 28037, Spain.}},
DOI = {{10.3145/epi.2009.ene.03}},
ISSN = {{1386-6710}},
Keywords = {{Cybermetrics; Web data mining; Log file analysis; Usage statistics}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Author-Email = {{jortega@orgc.csic.es
   isidro.aguillo@cchs.csic.es}},
ResearcherID-Numbers = {{Aguillo, Isidro/A-7280-2008}},
ORCID-Numbers = {{Aguillo, Isidro/0000-0001-8927-4873}},
Number-of-Cited-References = {{10}},
Times-Cited = {{1}},
Journal-ISO = {{Prof. Inf.}},
Doc-Delivery-Number = {{408SX}},
Unique-ID = {{ISI:000263456400003}},
}

@article{ ISI:000246242300004,
Author = {Brinkman, Willem-Paul and Haakma, Reinder and Bouwhuis, Don G.},
Title = {{Towards an empirical method of efficiency testing of system parts: A
   methodological study}},
Journal = {{INTERACTING WITH COMPUTERS}},
Year = {{2007}},
Volume = {{19}},
Number = {{3}},
Pages = {{342-356}},
Month = {{MAY}},
Abstract = {{Current usability evaluation methods are essentially holistic in nature.
   However, engineers that apply a component-based software engineering
   approach might also be interested in understanding the usability of
   individual parts of an interactive system. This paper examines the
   efficiency dimension of usability by describing a method, which
   engineers can use to test, empirically and objectively, the physical
   interaction effort to operate components in a single device. The method
   looks at low-level events, such as button clicks, and attributes the
   physical effort associated with these interaction events to individual
   components in the system. This forms the basis for engineers to
   prioritise their improvement effort. The paper discusses face validity,
   content validity, criterion validity, and construct validity of the
   method. The discussion is set within the context of four usability
   tests, in which 40 users participated to evaluate the efficiency of four
   different versions of a mobile phone. The results of the study show that
   the method can provide a valid estimation of the physical interaction
   event effort users made when interacting with a specific part of a
   device. (c) 2007 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Brinkman, WP (Reprint Author), Brunel Univ, Sch Informat Syst Comp \& Math, Uxbridge UB8 3PH, Middx, England.
   Brunel Univ, Sch Informat Syst Comp \& Math, Uxbridge UB8 3PH, Middx, England.
   Philips Res Labs, NL-5665 AA Eindhoven, Netherlands.
   Tech Univ Eindhoven, NL-5600 MB Eindhoven, Netherlands.}},
DOI = {{10.1016/j.intcom.2007.01.002}},
ISSN = {{0953-5438}},
Keywords = {{efficiency; usability testing; HCI methodology; usability evaluation
   method; log file analysis; empirical method}},
Keywords-Plus = {{USABILITY EVALUATION METHODS; COMPUTER HUMAN DIALOG; LAYERED PROTOCOLS;
   PERCEPTUAL CONTROL; INTERFACE DESIGN; INFORMATION; MODEL}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Cybernetics; Ergonomics}},
Author-Email = {{willem.brinkman@brunel.ac.uk
   reinder.haakma@philips.com
   d.g.bouwhuis@tue.nl}},
ResearcherID-Numbers = {{Brinkman, WIllem-Paul/H-8159-2013}},
ORCID-Numbers = {{Brinkman, WIllem-Paul/0000-0001-8485-7092}},
Number-of-Cited-References = {{61}},
Times-Cited = {{3}},
Journal-ISO = {{Interact. Comput.}},
Doc-Delivery-Number = {{164OB}},
Unique-ID = {{ISI:000246242300004}},
}

@article{ ISI:000246207400005,
Author = {Peisert, Sean and Bishop, Matt and Karin, Sidney and Marzullo, Keith},
Title = {{Analysis of computer intrusions using sequences of function calls}},
Journal = {{IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING}},
Year = {{2007}},
Volume = {{4}},
Number = {{2}},
Pages = {{137-150}},
Month = {{APR-JUN}},
Abstract = {{paper demonstrates the value of analyzing sequences of function calls
   for forensic analysis. Although this approach has been used for
   intrusion detection (that is, determining that a system has been
   attacked), its value in isolating the cause and effects of the attack
   has not previously been shown. We also look for not only the presence of
   unexpected events but also the absence of expected events. We tested
   these techniques using reconstructed exploits in su, ssh, and 1pr, as
   well as proof-of-concept code, and, in all cases, were able to detect
   the anomaly and the nature of the vulnerability.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Peisert, S (Reprint Author), Univ Calif San Diego, Dept Comp Sci \& Engn, 9500 Gilman Dr 0404, La Jolla, CA 92093 USA.
   Univ Calif San Diego, Dept Comp Sci \& Engn, La Jolla, CA 92093 USA.
   Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.}},
DOI = {{10.1109/TDSC.2007.1003}},
ISSN = {{1545-5971}},
Keywords = {{security; forensic analysis; logging; auditing; intrusion detection;
   anomaly detection; management; design; unauthorized access ( for
   example, hacking)}},
Keywords-Plus = {{SYSTEM CALLS; UNIX}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Software Engineering}},
Author-Email = {{peisert@cs.ucsd.edu
   bishop@cs.ucdavis.edu
   karin@cs.ucsd.edu
   marzullo@cs.ucsd.edu}},
Number-of-Cited-References = {{64}},
Times-Cited = {{10}},
Journal-ISO = {{IEEE Trans. Dependable Secur. Comput.}},
Doc-Delivery-Number = {{164BK}},
Unique-ID = {{ISI:000246207400005}},
}

@article{ ISI:000206467500007,
Author = {Zuccala, Alesia and Thelwall, Mike and Oppenheim, Charles and Dhiensa,
   Rajveen},
Title = {{Web intelligence analyses of digital libraries A case study of the
   National electronic Library for Health (NeLH)}},
Journal = {{JOURNAL OF DOCUMENTATION}},
Year = {{2007}},
Volume = {{63}},
Number = {{4}},
Pages = {{558-589}},
Abstract = {{Purpose - The purpose of this paper is to explore the use of LexiURL as
   a Web intelligence tool for collecting and analysing links to digital
   libraries, focusing specifically on the National electronic Library for
   Health (NeLH).
   Design/methodology/approach - The Web intelligence techniques in this
   study are a combination of link analysis (web structure mining), web
   server log file analysis (web usage mining), and text analysis (web
   content mining), utilizing the power of commercial search engines and
   drawing upon the information science fields of bibliometrics and
   webometrics. LexiURL is a computer program designed to calculate summary
   statistics for lists of links or URLs. Its output is a series of
   standard reports, for example listing and counting all of the different
   domain names in the data.
   Findings - Link data, when analysed together with user transaction log
   files (i.e. Web referring domains) can provide insights into who is
   using a digital library and when, and who could be using the digital
   library if they are ``surfing{''} a particular part of the Web; in this
   case any site that is linked to or colinked with the NeLH. This study
   found that the NeLH was embedded in a multifaceted Web context,
   including many governmental, educational, commercial and organisational
   sites, with the most interesting being sites from the.edu domain,
   representing American Universities. Not many links directed to the NeLH
   were followed on September 25, 2005 (the date of the log file analysis
   and link extraction analysis), which means that users who access the
   digital library have been arriving at the site via only a few select
   links, bookmarks and search engine searches, or non-electronic sources.
   Originality/value - A number of studies concerning digital library users
   have been carried out using log file analysis as a research tool. Log
   files focus on real-time user transactions; while LexiURL can be used to
   extract links and colinks associated with a digital library's growing
   Web network. This Web network is not recognized often enough, and can be
   a useful indication of where potential users are surfing, even if they
   have not yet specifically visited the NeLH site.}},
Publisher = {{EMERALD GROUP PUBLISHING LIMITED}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zuccala, A (Reprint Author), Wolverhampton Univ, Sch Comp \& Informat Technol, Wolverhampton WV1 1DJ, W Midlands, England.
   Zuccala, Alesia; Thelwall, Mike, Wolverhampton Univ, Sch Comp \& Informat Technol, Wolverhampton WV1 1DJ, W Midlands, England.
   Oppenheim, Charles; Dhiensa, Rajveen, Univ Loughborough, Dept Informat Sci, Loughborough, Leics, England.}},
DOI = {{10.1108/00220410710759011}},
ISSN = {{0022-0418}},
EISSN = {{1758-7379}},
Keywords = {{Digital libraries; Worldwide web; Search engines; Generation and
   dissemination of information; Transmission control protocol/internet
   protocol; Communication technologies}},
Keywords-Plus = {{AUTHOR COCITATION; ROMEO; PERFORMANCE; INFORMATION; PATTERNS; IMPACT; US}},
Research-Areas = {{Computer Science; Information Science \& Library Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Information Science \& Library
   Science}},
Author-Email = {{a.zuccala@rathenau.nl}},
ResearcherID-Numbers = {{Thelwall, Mike/C-1449-2013}},
ORCID-Numbers = {{Thelwall, Mike/0000-0001-6065-205X}},
Number-of-Cited-References = {{69}},
Times-Cited = {{7}},
Journal-ISO = {{J. Doc.}},
Doc-Delivery-Number = {{V95RN}},
Unique-ID = {{ISI:000206467500007}},
}

@article{ ISI:000241627300006,
Author = {Mayr, Philipp},
Title = {{Constructing experimental indicators for open access documents}},
Journal = {{RESEARCH EVALUATION}},
Year = {{2006}},
Volume = {{15}},
Number = {{2}},
Pages = {{127-132}},
Month = {{AUG}},
Abstract = {{The ongoing paradigm change in the scholarly publication system makes it
   necessary to construct alternative evaluation criteria/metrics which
   appropriately take into account the unique characteristics of electronic
   publications and other research output in digital formats. Today, major
   parts of scholarly open access (OA) publications and the self-archiving
   area are not well covered in traditional citation and indexing
   databases. The growing share and importance of freely accessible
   research output demands new approaches/metrics for measuring and
   evaluating these new types of scientific publication. We propose a
   simple quantitative method which establishes indicators by measuring the
   access/download pattern of OA documents and other web entities of a
   single web server. The experimental indicators are constructed, based on
   standard local web usage data. This new type of web-based indicator is
   developed to model the specific demand for better study/evaluation of
   the accessibility, visibility and interlinking of open accessible
   documents. We conclude that e-science will need new stable e-indicators.}},
Publisher = {{BEECH TREE PUBLISHING}},
Address = {{10 WATFORD CLOSE,, GUILDFORD GU1 2EP, SURREY, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Mayr, P (Reprint Author), Humboldt Univ, Inst Lib \& Informat Sci, Steubenring 17, D-53175 Berlin, Germany.
   Humboldt Univ, Inst Lib \& Informat Sci, D-53175 Berlin, Germany.}},
DOI = {{10.3152/147154406781775940}},
ISSN = {{0958-2029}},
Keywords-Plus = {{LOG FILE ANALYSIS; WEB}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Author-Email = {{philippmayr@web.de}},
ResearcherID-Numbers = {{Mayr, Philipp/C-4359-2013}},
ORCID-Numbers = {{Mayr, Philipp/0000-0002-6656-1658}},
Number-of-Cited-References = {{19}},
Times-Cited = {{3}},
Journal-ISO = {{Res. Evaluat.}},
Doc-Delivery-Number = {{099WG}},
Unique-ID = {{ISI:000241627300006}},
}

@article{ ISI:000232754100006,
Author = {Hulshof, CD and Wilhelm, P and Beishuizen, JJ and van Rijn, H},
Title = {{FILE: a tool for the study of inquiry learning}},
Journal = {{COMPUTERS IN HUMAN BEHAVIOR}},
Year = {{2005}},
Volume = {{21}},
Number = {{6}},
Pages = {{945-956}},
Month = {{NOV}},
Abstract = {{A computerized learning environment (Flexible Inquiry Learning
   Environment; FILE) is discussed. FILE allows researchers in inquiry
   learning to design, administer, and analyze learning tasks in which
   content domain and task complexity call be configured independently,
   while other factors (e.g., the interface) are held constant. This allows
   for more valid across-task generalizations. FILE is based on a
   descriptive model of inquiry learning and its monitoring facilities
   allow for the extraction of learning indicators derived from the model.
   Furthermore, FILE is suitable from the age of eight years, which allows
   developmental issues in inquiry learning to be addressed. It is
   concluded that FILE can be used to set up studies in inquiry learning in
   an efficient way, saving expensive programming time. (c) 2004 Elsevier
   Ltd. All rights reserved.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hulshof, CD (Reprint Author), Univ Twente, Fac Behav Sci, Dept Instruct Technol, POB 217, NL-7500 AE Enschede, Netherlands.
   Univ Twente, Fac Behav Sci, Dept Instruct Technol, NL-7500 AE Enschede, Netherlands.
   Vrije Univ Amsterdam, Onderwijscentrum VU, NL-1081 HV Amsterdam, Netherlands.
   Univ Amsterdam, Dept Social Sci Informat, NL-1012 WX Amsterdam, Netherlands.}},
DOI = {{10.1016/j.chb.2004.03.014}},
ISSN = {{0747-5632}},
Keywords = {{inquiry learning; learning environment; authoring environment; discovery
   learning; log-file analysis}},
Keywords-Plus = {{SEARCH}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary; Psychology, Experimental}},
Author-Email = {{c.d.hulshof@utwente.nl}},
ResearcherID-Numbers = {{van Rijn, Hedderik/L-3685-2014}},
ORCID-Numbers = {{van Rijn, Hedderik/0000-0002-0461-9850}},
Number-of-Cited-References = {{18}},
Times-Cited = {{7}},
Journal-ISO = {{Comput. Hum. Behav.}},
Doc-Delivery-Number = {{976SR}},
Unique-ID = {{ISI:000232754100006}},
}

@article{ ISI:000233594900004,
Author = {Jordan, S},
Title = {{www.drugcom.de - an internet based information and counselling project
   for the prevention of addiction}},
Journal = {{PRAXIS DER KINDERPSYCHOLOGIE UND KINDERPSYCHIATRIE}},
Year = {{2005}},
Volume = {{54}},
Number = {{9}},
Pages = {{742-754}},
Month = {{NOV}},
Abstract = {{The Internet based addiction prevention project www.drugcom.de of the
   Federal Centre of Health Education (BZgA) offers information and
   anonymous counselling for adolescents and young adults. The internet
   project is based on a secondary preventive approach. The objective is to
   prevent misuse and addiction of substances/drugs and to reduce negative
   effects of consumption (risk competence). The effects of the project are
   on different levels: Transfer of knowledge and change of attitude and
   behaviour. The process evaluation is based on quantitative data from
   online questionnaires on the website and on the log file analysis of
   users, use and acceptance. According to the different sections of
   www.drugcom.de that the user has been visiting, different indicators are
   raised, e. g. comprehensibility of text, satisfaction with counselling
   service, completeness of information etc. In 2004 the number of visits
   per day compared with the previous year has almost doubled to more than
   at an average of 1,000 per day. Consumers of legal and illegal drugs
   build the majority of drugcom users. Their average age is 20 years. 79\%
   of those asked have consumed an illegal substance once in their life as
   a minimum, mostly cannabis. The knowledge tests and the self test
   concerning alcohol are used especially often. The results show that it
   is possible to reach the target group of drug consuming young people by
   an internet based service. The internet project www.drugcom.de as an
   online-service of addiction prevention has been established with
   success.}},
Publisher = {{VANDENHOECK \& RUPRECHT}},
Address = {{THEATERSTRASSE 13,, D-37073 GOTTINGEN, GERMANY}},
Type = {{Article}},
Language = {{German}},
Affiliation = {{Jordan, S (Reprint Author), BZgA, Ostmerheimer Str 220, D-51109 Cologne, Germany.
   BZgA, D-51109 Cologne, Germany.}},
ISSN = {{0032-7034}},
Keywords = {{prevention of addiction; internet; adolescents; evaluation; drug}},
Research-Areas = {{Psychology; Psychiatry}},
Web-of-Science-Categories  = {{Psychology, Developmental; Psychiatry}},
Author-Email = {{susanne.jordan@bzga.de}},
Number-of-Cited-References = {{8}},
Times-Cited = {{4}},
Journal-ISO = {{Prax. Kinderpsychol. Kinderpsychiatr.}},
Doc-Delivery-Number = {{988KF}},
Unique-ID = {{ISI:000233594900004}},
}

@article{ ISI:000227848500002,
Author = {Boyd, A},
Title = {{Case study (part 2) - A ``fuzzy{''} to multi-channel information
   optimisation}},
Journal = {{ASLIB PROCEEDINGS}},
Year = {{2005}},
Volume = {{57}},
Number = {{1}},
Pages = {{11-21}},
Abstract = {{Purpose - To validate the use of fuzzy control systems for information
   channel optimisation.
   Design/methodology/approach - The research presents findings from a
   multi-year case-based study of an international software Organisation.
   At the outset of the study, baseline log-file data were collected from
   the Organisation's customer relationship management and financial
   systems. As part of a business process reengineering effort, a fuzzy
   control system model was created and implemented to optimise the
   software support communication channels. After the first year, data were
   recollected to determine the effectiveness of the model. The log-file
   analysis was augmented with individual inter-views of stakeholders
   within the business.
   Findings - The optimisation strategy based on the fuzzy control system
   allowed the Organisation to focus on answering more queries from higher
   value customers and cut the support resolution time nearly in half, in
   less than a year. By focusing on higher value customers and more
   productive information channels, staff efficiency increased and costs
   were reduced. This research indicates that customers using synchronous
   communication channels such as the telephone seem to get better service
   than those using asynchronous channels such as e-mail or web.
   Additionally, the research also indicates that several geographic
   factors such as proximity and language proficiency could influence
   information channel choice affecting the level of service received.
   Research limitations/implications - The case findings could be specific
   to the observed organisation or to the software service industry.
   Additional research is necessary to determine the universality of the
   method and ancillary findings.
   Originality/value - Methods outlined in this case provide both
   practitioners and researchers with new tools to explore and react to the
   challenges of information channel proliferation.}},
Publisher = {{EMERALD GROUP PUBLISHING LIMITED}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Boyd, A (Reprint Author), UCL, Ciber, Sch Lib Arch \& Informat Studies, London, England.
   UCL, Ciber, Sch Lib Arch \& Informat Studies, London, England.}},
DOI = {{10.1108/00012530510579048}},
ISSN = {{0001-253X}},
Keywords = {{fuzzy control; information transfer; information management; customer
   service management; business process re-engineering}},
Research-Areas = {{Computer Science; Information Science \& Library Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Information Science \& Library
   Science}},
Number-of-Cited-References = {{2}},
Times-Cited = {{1}},
Journal-ISO = {{Aslib Proc.}},
Doc-Delivery-Number = {{909GN}},
Unique-ID = {{ISI:000227848500002}},
}

@inproceedings{ ISI:000233848300010,
Author = {Hay, B and Wets, G and Vanhoof, K},
Editor = {{Mobasher, B and Anand, SS}},
Title = {{Discovering interesting navigations on a web site using SAM}},
Booktitle = {{INTELLIGENT TECHNIQUES FOR WEB PERSONALIZATION}},
Series = {{LECTURE NOTES IN ARTIFICIAL INTELLIGENCE}},
Year = {{2005}},
Volume = {{3169}},
Pages = {{187-200}},
Note = {{Workshop on Intelligent Techniques for Web Personalization, Acapulco,
   MEXICO, AUG   11, 2003}},
Abstract = {{In this article, a new algorithm called Sequence Alignment Method
   extended with an Interestingness Measure (SAM(I)) is illustrated for
   mining navigation patterns on a web site. Through log file analysis,
   SAMI distinguishes interesting patterns (i.e. unexpected, surprising
   patterns contradicting with the structure of the web site or direct
   hyperlinks between web pages) from uninteresting patterns (i.e.
   expected, known, obvious patterns resulting from the structure of the
   web site or direct hyperlinks between web pages) and provides
   information about the order of visited web pages. The algorithm is
   validated using real data sets of the Music Machines web site
   http://machines.hyperreal.org, home of musical electronics on the web.
   Empirical results show that SAMI identifies profiles of visiting
   behavior, which may be used for web personalization techniques and for
   optimizing the layout of the web site through structuring of page-links.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hay, B (Reprint Author), Limburgs Univ Ctr, Fac Appl Econ Sci, B-3590 Diepenbeek, Belgium.
   Limburgs Univ Ctr, Fac Appl Econ Sci, B-3590 Diepenbeek, Belgium.}},
ISSN = {{0302-9743}},
ISBN = {{3-540-29846-0}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems}},
Author-Email = {{birgit.hay@luc.ac.be
   geert.wets@luc.ac.be
   koen.vanhoof@luc.ac.be}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Doc-Delivery-Number = {{BDJ66}},
Unique-ID = {{ISI:000233848300010}},
}

@article{ ISI:000222259100032,
Author = {Stell, AM and Li, JG and Zeidan, OA and Dempsey, JF},
Title = {{An extensive log-file analysis of step-and-shoot intensity modulated
   radiation therapy segment delivery errors}},
Journal = {{MEDICAL PHYSICS}},
Year = {{2004}},
Volume = {{31}},
Number = {{6}},
Pages = {{1593-1602}},
Month = {{JUN}},
Abstract = {{We present a study to evaluate the monitor unit (MU), dosimetric, and
   leaf-motion errors found in the delivery of 91 step-and-shoot IMRT
   treatment plans performed at three nominal dose rates using a dual
   modality high energy Linac (Varian 2 100 C/D, Varian Medical Systems
   Inc., Palo Alto, CA) equipped with a 120-leaf multileaf collimator
   (MLC). The analysis was performed by studying log files generated by the
   MLC controller system. Recent studies by our group have validate that
   the automatically generated MLC log files accurately record the actual
   system delivery. A total of 635 beams were delivered at three nominal
   dose rates: 100, 300, and 600 MU/min. The log files were manually
   retrieved and analysis software was developed to extract the recorded MU
   delivery and leaf positions for each segment. Our analysis revealed that
   the magnitude of segment MU errors were independent of the planned
   segment MUs. Segment MU errors were found to increase with dose rate
   having maximum errors per segment of +/-1.8 MU at 600 MU/min, +/-0.8 MU
   at 300 MU/min, and +/-0.5 MU at 100 MU/min. The total absolute MU error
   in each plan was observed to increase with the number of plan segments,
   with the trend increasing more rapidly for higher dose rates. Three
   dimensional dose distributions were recomputed based on the observed
   segment MU errors for three plans with large cumulative absolute MU
   errors. Comparison with the original treatment plans indicated no
   clinically significant consequences due to these errors. In addition,
   approximately 80\% of the total segment deliveries reported at least one
   collimator leaf moving at least 1 mm (projected at isocenter) during
   segment delivery. Such errors occur near the end of segment delivery and
   have been previously observed by our group using a fast video-based
   electronic portal imaging device. At 600 MU/min, between 5\% and 23\% of
   the plan MUs were delivered during leaf motion that had exceeded a 1 mm
   position tolerance. These leaf motion errors were not included in the
   treatment plan recalculations performed in this study. (C) 2004 American
   Association of Physicists in Medicine.}},
Publisher = {{AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS}},
Address = {{STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dempsey, JF (Reprint Author), Univ Florida, Dept Radiat Oncol, Gainesville, FL 32610 USA.
   Univ Florida, Dept Radiat Oncol, Gainesville, FL 32610 USA.}},
DOI = {{10.1118/1.1751011}},
ISSN = {{0094-2405}},
Keywords = {{IMRT; MLC; IMRT treatment plan verification}},
Keywords-Plus = {{IMRT DELIVERY; RADIOTHERAPY}},
Research-Areas = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Web-of-Science-Categories  = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Author-Email = {{dempsey@ufl.edu}},
Number-of-Cited-References = {{15}},
Times-Cited = {{48}},
Journal-ISO = {{Med. Phys.}},
Doc-Delivery-Number = {{832HW}},
Unique-ID = {{ISI:000222259100032}},
}

@inproceedings{ ISI:000223793600051,
Author = {Fine, N and Brinkman, WP},
Editor = {{Rauterberg, M}},
Title = {{Avoiding average: Recording interaction data to design for specific user
   groups}},
Booktitle = {{ENTERTAINMENT COMPUTING - ICEC 2004}},
Series = {{LECTURE NOTES IN COMPUTER SCIENCE}},
Year = {{2004}},
Volume = {{3166}},
Pages = {{398-401}},
Note = {{3rd International Conference on Entertainment Computing (ICEC 2004),
   Tech Univ, Eindhoven, NETHERLANDS, SEP 01-03, 2004}},
Organization = {{Tech Univ, Dept Ind Design; JF Schouten Sch User Syst Interact Res;
   Royal Netherlands Acad Arts \& Sci; Netherlands Org Sci Res; European
   Res Consortium Informat \& Math; Innovat Oriented Res Program Human
   Machine Interact}},
Abstract = {{Designing domestic user interfaces for broad user populations means
   designing for the average user. To design for more personally intuitive
   interfaces detailed interactive behaviours need to be captured and
   described in order to better inform the design process. By utilising
   technologies such as interface skins, log file analysis and user
   interface description languages, the PROSKIN project is developing an
   empirical tool for quantitative capture, description and analysis of
   interactive behaviour in a non-invasive and situated context. The
   purpose of the tool is to identify user groups by distinguishing
   behaviour or trait which will allow designers to develop more personally
   relevant user interfaces. The tool itself facilitates the analyses of
   large datasets of users and their interactive behaviours. This will
   allow designers to produce interface skins for user groups of similar
   interactive profile and subsequently providing a less average user
   experience.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Fine, N (Reprint Author), Brunel Univ, Dept Informat Syst \& Comp, Uxbridge UB8 3PH, Middx, England.
   Brunel Univ, Dept Informat Syst \& Comp, Uxbridge UB8 3PH, Middx, England.}},
ISSN = {{0302-9743}},
ISBN = {{3-540-22947-7}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Computer Science,
   Theory \& Methods}},
Author-Email = {{nick.fine@brunel.ac.uk
   willem.brinkman@brunel.ac.uk}},
ResearcherID-Numbers = {{Brinkman, WIllem-Paul/H-8159-2013}},
ORCID-Numbers = {{Brinkman, WIllem-Paul/0000-0001-8485-7092}},
Number-of-Cited-References = {{3}},
Times-Cited = {{1}},
Doc-Delivery-Number = {{BAV52}},
Unique-ID = {{ISI:000223793600051}},
}

@article{ ISI:000183992500005,
Author = {Andrews, JH and Zhang, YJ},
Title = {{General test result checking with log file analysis}},
Journal = {{IEEE TRANSACTIONS ON SOFTWARE ENGINEERING}},
Year = {{2003}},
Volume = {{29}},
Number = {{7}},
Pages = {{634-648}},
Month = {{JUL}},
Abstract = {{We describe and apply a lightweight formal method for checking test
   results. The method assumes that the software under test writes a text
   log file; this log file is then analyzed by a program to see if it
   reveals failures. We suggest a state-machine-based formalism for
   specifying the log file analyzer programs and describe a language and
   implementation based on that formalism. We report on empirical studies
   of the application of log file analysis to random testing of units. We
   describe the results of experiments done to compare the performance and
   effectiveness of random unit testing with coverage checking and log file
   analysis to other unit testing procedures. The experiments suggest that
   writing a formal log file analyzer and using random testing is
   competitive with other formal and informal methods for unit testing.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Andrews, JH (Reprint Author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.
   Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.}},
DOI = {{10.1109/TSE.2003.1214327}},
ISSN = {{0098-5589}},
Keywords = {{testing; specification; safety verification; lightweight formal methods;
   test oracles; unit testing; log file analysis}},
Keywords-Plus = {{COMPLEX-SYSTEMS; ADA PROGRAMS; SOFTWARE; SPECIFICATIONS; VERIFICATION}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Engineering, Electrical \&
   Electronic}},
Number-of-Cited-References = {{45}},
Times-Cited = {{17}},
Journal-ISO = {{IEEE Trans. Softw. Eng.}},
Doc-Delivery-Number = {{698HG}},
Unique-ID = {{ISI:000183992500005}},
}

@article{ ISI:000185037100012,
Author = {Cohen, LB},
Title = {{A two-tiered model for analyzing library website usage statistics, part
   2: Log file analysis}},
Journal = {{PORTAL-LIBRARIES AND THE ACADEMY}},
Year = {{2003}},
Volume = {{3}},
Number = {{3}},
Pages = {{517-526}},
Month = {{JUL}},
Abstract = {{The author proposes a two-tiered model for analyzing website usage
   statistics for academic libraries: one tier for library administrators
   that analyzes measures indicating library use, and a second tier for
   website managers that analyzes measures that aid in server maintenance
   and site design. The author discusses the technology of website usage
   statistics, including several caveats about the accuracy of derived
   counts, and recommends important measures for each tier. Part I
   describes Web server logs and the challenges inherent in their analysis.
   Part 2 presents recommendations for conducting log file analysis to
   obtain meaningful information, benefiting administrators and site
   managers.}},
Publisher = {{JOHNS HOPKINS UNIV PRESS}},
Address = {{JOURNALS PUBLISHING DIVISION, 2715 NORTH CHARLES ST, BALTIMORE, MD
   21218-4319 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cohen, LB (Reprint Author), SUNY Albany, Network Serv, Albany, NY 12222 USA.
   SUNY Albany, Network Serv, Albany, NY 12222 USA.}},
DOI = {{10.1353/pla.2003.0054}},
ISSN = {{1531-2542}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Number-of-Cited-References = {{11}},
Times-Cited = {{1}},
Journal-ISO = {{Portal-Libr. Acad}},
Doc-Delivery-Number = {{716PG}},
Unique-ID = {{ISI:000185037100012}},
}

@article{ ISI:000184273600005,
Author = {Richter, T and Naumann, J and Noller, S},
Title = {{LOGPAT: A semi-automatic way to analyze hypertext navigation behavior}},
Journal = {{SWISS JOURNAL OF PSYCHOLOGY}},
Year = {{2003}},
Volume = {{62}},
Number = {{2}},
Pages = {{113-120}},
Month = {{JUN}},
Abstract = {{In hypertext research, log files,represent a useful I source of
   information about users' navigational behavior. Since log files can
   contain enormous amounts of-data, methods for data reduction with a
   minimum loss of information are needed. In this paper, LOGPAT (Log file
   Pattern Analysis) is presented, a Web-based tool for analyzing log
   files. With LOGPAT, single-unit, sequential,and graph-theoretic measures
   (including distance matrices) for the description of user navigation,
   can be computed. The paper gives an overview of these methods and
   discusses their value for psychological research on hypertext.
   Components and analysis options of LOGPAT are described in detail. The
   program's basic options are illustrated by data from a study on learning
   with hypertext.}},
Publisher = {{VERLAG HANS HUBER}},
Address = {{LANGGASS-STRASSE 76, CH-3000 BERN 9, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Richter, T (Reprint Author), Univ Cologne, Psychol Dept, Herbert Lewin Str 2, D-50931 Cologne, Germany.
   Univ Cologne, Psychol Dept, D-50931 Cologne, Germany.}},
DOI = {{10.1024//1421-0185.62.2.113}},
ISSN = {{1421-0185}},
Keywords = {{hypertext; log file analysis; navigation behavior; software tool}},
Keywords-Plus = {{HYPERMEDIA; HYPERSPACE; PATTERNS}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
ResearcherID-Numbers = {{Richter, Tobias/C-3447-2015}},
ORCID-Numbers = {{Richter, Tobias/0000-0002-0467-9044}},
Number-of-Cited-References = {{23}},
Times-Cited = {{10}},
Journal-ISO = {{Swiss J. Psychol.}},
Doc-Delivery-Number = {{703HH}},
Unique-ID = {{ISI:000184273600005}},
}

@article{ ISI:000183232300012,
Author = {Cohen, LB},
Title = {{A two-tiered model for analyzing library website usage statistics, Part
   1: Web server logs}},
Journal = {{PORTAL-LIBRARIES AND THE ACADEMY}},
Year = {{2003}},
Volume = {{3}},
Number = {{2}},
Pages = {{315-326}},
Month = {{APR}},
Abstract = {{The author proposes a two-tiered model for analyzing website usage
   statistics for academic libraries: one tier for library administrators
   that analyzes measures indicating library use, and a second tier for
   website managers that analyzes measures that aid in server maintenance
   and site design. The author discusses the technology of website usage
   statistics, including several caveats about the accuracy of derived
   counts, and recommends important measures for each tier. Part 1
   describes Web server logs and the challenges inherent in their analysis.
   Part 2 presents recommendations for conducting log file analysis to
   obtain meaningful information, benefiting administrators and site
   managers.}},
Publisher = {{JOHNS HOPKINS UNIV PRESS}},
Address = {{JOURNALS PUBLISHING DIVISION, 2715 NORTH CHARLES ST, BALTIMORE, MD
   21218-4319 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cohen, LB (Reprint Author), SUNY Albany, Albany, NY 12222 USA.
   SUNY Albany, Albany, NY 12222 USA.}},
DOI = {{10.1353/pla.2003.0028}},
ISSN = {{1531-2542}},
Keywords-Plus = {{SITE USAGE}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Number-of-Cited-References = {{13}},
Times-Cited = {{3}},
Journal-ISO = {{Portal-Libr. Acad}},
Doc-Delivery-Number = {{684XT}},
Unique-ID = {{ISI:000183232300012}},
}

@article{ ISI:000186405700005,
Author = {Nicholas, D and Huntington, P},
Title = {{Micro-mining and segmented log file analysis: a method for enriching the
   data yield from Internet log files}},
Journal = {{JOURNAL OF INFORMATION SCIENCE}},
Year = {{2003}},
Volume = {{29}},
Number = {{5}},
Pages = {{391-404}},
Abstract = {{The authors propose improved ways of analysing web server log files.
   Traditionally web site statistics focus on giving a big (and shallow)
   picture analysis based on all transaction log entries. The pictures are,
   however, distorted because of the problems associated with resolving
   Internet protocol (IP) numbers to a sin-le user and cross-border IP
   registration. The authors argue that analysing extracted sub-groups and
   categories presents a more accurate picture of the data and that the
   analysis of the online behaviour of selected individuals (rather than of
   very large groups) can add much to our understanding of how people use
   web sites and, indeed, any digital information source. The analysis is
   labelled `micro' to distinguish it from traditional macro, big picture
   transactional log analysis. The methods are illustrated with recourse to
   the logs of the SurgeryDoor (www.surgerydoor.co.uk) consumer health web
   site. It was found that use attributed to academic users gave a better
   approximation of the sites' geographical distribution of users than an
   analysis based on all users. This occurs as academic institutions,
   unlike other user types, register in their host country. Selecting log
   entries where each user is allocated a unique IP number can be
   particularly beneficial, especially to analyses of returnees. Finally
   the paper tracks the online behaviour of a small number of IP numbers,
   in an example of the application of microanalysis.}},
Publisher = {{SAGE PUBLICATIONS LTD}},
Address = {{6 BONHILL STREET, LONDON EC2A 4PU, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Nicholas, D (Reprint Author), City Univ London, Dept Informat Sci, Ciber, Northampton Sq, London EC1V 0HQ, England.
   City Univ London, Dept Informat Sci, Ciber, London EC1V 0HQ, England.}},
DOI = {{10.1177/01655515030295005}},
ISSN = {{0165-5515}},
Keywords = {{websites; data mining; user profiles; user behaviour; consumer health
   information}},
Keywords-Plus = {{WEB SITES}},
Research-Areas = {{Computer Science; Information Science \& Library Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Information Science \& Library
   Science}},
Number-of-Cited-References = {{14}},
Times-Cited = {{15}},
Journal-ISO = {{J. Inf. Sci.}},
Doc-Delivery-Number = {{740MG}},
Unique-ID = {{ISI:000186405700005}},
}

@inproceedings{ ISI:000185995400012,
Author = {Geyer-Schulz, A and Neumann, A and Thede, A},
Editor = {{Koch, T and Solvberg, IT}},
Title = {{Others also use: A robust recommender system for scientific libraries}},
Booktitle = {{RESEARCH AND ADVANCED TECHNOLOGY FOR DIGITAL LIBRARIES}},
Series = {{LECTURE NOTES IN COMPUTER SCIENCE}},
Year = {{2003}},
Volume = {{2769}},
Pages = {{113-125}},
Note = {{7th European Conference on Research and Advanced Technology for Digital
   Libraries, TRONDHEIM, NORWAY, AUG 17-22, 2003}},
Organization = {{ABM; BIBSYS; ERCIM; NFR; Nordic Council Sci Informat; Norwegian Univ Sci
   \& Technol; Comp \& Informat Sci; SINTEF Telecom \& Informat; Sun
   Microsyst}},
Abstract = {{Scientific digital library systems are a very promising application area
   for value-added expert advice services. Such systems could significantly
   reduce the search and evaluation costs of information products for
   students and scientists. This holds for pure digital libraries as well
   as for traditional scientific libraries with online public access
   catalogs (OPAC). In this contribution we first outline different types
   of recommendation services for scientific libraries and their general
   integration strategies. Then we focus on a recommender system based on
   log file analysis that is fully operational within the legacy library
   system of the Universitat Karlsruhe (TH) since June 2002. Its underlying
   mathematical model, the implementation within the OPAC, as well as the
   first user evaluation is presented.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Geyer-Schulz, A (Reprint Author), Univ Karlsruhe, Inst Informat Engn \& Management, Dept Econ \& Business Engn, Div Informat Serv \& Elect Markets, Kaiserstr 12, D-76128 Karlsruhe, Germany.
   Univ Karlsruhe, Inst Informat Engn \& Management, Dept Econ \& Business Engn, Div Informat Serv \& Elect Markets, D-76128 Karlsruhe, Germany.}},
ISSN = {{0302-9743}},
ISBN = {{3-540-40726-X}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Computer Science,
   Theory \& Methods}},
Number-of-Cited-References = {{28}},
Times-Cited = {{5}},
Doc-Delivery-Number = {{BX65E}},
Unique-ID = {{ISI:000185995400012}},
}

@article{ ISI:000179041900007,
Author = {Tannery, NH and Foust, JE and Gregg, AL and Hartman, LM and Kuller, AB
   and Worona, P and Tulsky, AA},
Title = {{Use of Web-based library resources by medical students in community and
   ambulatory settings}},
Journal = {{JOURNAL OF THE MEDICAL LIBRARY ASSOCIATION}},
Year = {{2002}},
Volume = {{90}},
Number = {{3}},
Pages = {{305-309}},
Month = {{JUL}},
Abstract = {{Purpose: The purpose was to evaluate the use of Web-based library
   resources by third-year medical students.
   Setting/Participants/Resources: Third-year medical students (147) in a
   twelve-week multidisciplinary primary care rotation in community and
   ambulatory settings.
   Methodology: Individual user surveys and log file analysis of Website
   were used.
   Results/Outcomes: Twenty resource topics were compiled into a Website to
   provide students with access to electronic library resources from any
   community-based clerkship location. These resource topics, covering
   subjects such as hypertension and back pain, linked to curriculum
   training problems, full-text journal articles, MEDLINE searches,
   electronic book chapters, and relevant Websites. More than half of the
   students (69\%) accessed the Website on a daily or weekly basis. Over
   80\% thought the Website was a valuable addition to their clerkship.
   Discussion/Conclusion: Web-based information resources can provide
   curriculum support to students for whom access to the library is
   difficult and time consuming.}},
Publisher = {{MEDICAL LIBRARY ASSOC}},
Address = {{65 EAST WACKER PLACE, STE 1900, CHICAGO, IL 60601-7298 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tannery, NH (Reprint Author), Univ Pittsburgh, Informat Serv, Hlth Sci Lib Syst, Falk Lib Hlth Sci, 200 Scaife Hall, Pittsburgh, PA 15213 USA.
   Univ Pittsburgh, Informat Serv, Hlth Sci Lib Syst, Falk Lib Hlth Sci, Pittsburgh, PA 15213 USA.
   Univ Pittsburgh, Dept Med, Pittsburgh, PA 15260 USA.}},
ISSN = {{1536-5050}},
Keywords-Plus = {{PRIMARY-CARE CLERKSHIP; INFORMATION NEEDS}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
ResearcherID-Numbers = {{Tannery, Nancy/B-5688-2009}},
ORCID-Numbers = {{Tannery, Nancy/0000-0003-3478-3720}},
Number-of-Cited-References = {{9}},
Times-Cited = {{13}},
Journal-ISO = {{J. Med. Libr. Assoc.}},
Doc-Delivery-Number = {{611WY}},
Unique-ID = {{ISI:000179041900007}},
}

@article{ ISI:000176250800007,
Author = {Rozic-Hristovski, A and Hristovski, D and Todorovski, L},
Title = {{Users' information-seeking behavior on a medical library Website}},
Journal = {{JOURNAL OF THE MEDICAL LIBRARY ASSOCIATION}},
Year = {{2002}},
Volume = {{90}},
Number = {{2}},
Pages = {{210-217}},
Month = {{APR}},
Abstract = {{The Central Medical Library (CMK) at the Faculty of Medicine, University
   of Ljubljana, Slovenia, started to build a library Website that included
   a guide to library services and resources in 1997. The evaluation of
   Website usage plays an important role in its maintenance and
   development. Analyzing and exploring regularities in the visitors'
   behavior can be used to enhance the quality and facilitate delivery of
   information services, identify visitors' interests, and improve the
   server's performance. The analysis of the CMK Website users'
   navigational behavior was carried out by analyzing the Web server log
   files. These files contained information on all user accesses to the
   Website and provided a great opportunity to learn more about the
   behavior of visitors to the Website. The majority of the available tools
   for Web log file analysis provide a predefined set of reports showing
   the access count and the transferred bytes grouped along several
   dimensions. In addition to the reports mentioned above, the authors
   wanted to be able to perform interactive exploration and ad hoc analysis
   and discover trends in a user-friendly way. Because of that, we
   developed our own solution for exploring an analyzing the Web logs based
   on data warehousing and online analytical processing technologies. The
   analytical solution we developed proved successful, so it may find
   further application in the field of Web log file analysis. We will apply
   the findings of the analysis to restructuring the CMK Website.}},
Publisher = {{MEDICAL LIBRARY ASSOC}},
Address = {{65 EAST WACKER PLACE, STE 1900, CHICAGO, IL 60601-7298 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Rozic-Hristovski, A (Reprint Author), Univ Ljubljana, Fac Med, Cent Med Lib, Vrazov Trg 2, Ljubljana 1000, Slovenia.
   Univ Ljubljana, Fac Med, Cent Med Lib, Ljubljana 1000, Slovenia.
   Univ Ljubljana, Fac Med, Inst Biomed Informat, Ljubljana 1000, Slovenia.
   Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia.}},
ISSN = {{1536-5050}},
Keywords-Plus = {{USAGE; WEB}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
ResearcherID-Numbers = {{Hristovski, Dimitar/A-6288-2009}},
Number-of-Cited-References = {{12}},
Times-Cited = {{10}},
Journal-ISO = {{J. Med. Libr. Assoc.}},
Doc-Delivery-Number = {{563HT}},
Unique-ID = {{ISI:000176250800007}},
}

@article{ ISI:000173447700003,
Author = {Hong, JI and Heer, J and Waterson, S and Landay, JA},
Title = {{WebQuilt: A proxy-based approach to remote web usability testing}},
Journal = {{ACM TRANSACTIONS ON INFORMATION SYSTEMS}},
Year = {{2001}},
Volume = {{19}},
Number = {{3}},
Pages = {{263-285}},
Month = {{JUL}},
Abstract = {{WebQuilt is a web logging and visualization system that helps web design
   teams run usability tests (both local and remote) and analyze the
   collected data. Logging is done through a proxy, overcoming many of the
   problems with server-side and client-side logging. Captured usage traces
   can be aggregated and visualized it in a zooming interface that shows
   the web pages people viewed. The visualization also shows the most
   common paths taken through the web site for a given task, as well as the
   optimal path for that task, as designated by the designer. This paper
   discusses the architecture of WebQuilt and describes how it can be
   extended for new kinds of analyses and visualizations.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hong, JI (Reprint Author), Univ Calif Berkeley, Div Comp Sci, Grp User Interface Res, Berkeley, CA 94720 USA.
   Univ Calif Berkeley, Div Comp Sci, Grp User Interface Res, Berkeley, CA 94720 USA.}},
DOI = {{10.1145/502115.502118}},
ISSN = {{1046-8188}},
Keywords = {{measurement; design; experimentation; human factors; usability
   evalution; log file analysis; web visualization; web proxy; WebQuilt}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Number-of-Cited-References = {{31}},
Times-Cited = {{34}},
Journal-ISO = {{ACM Trans. Inf. Syst.}},
Doc-Delivery-Number = {{514NN}},
Unique-ID = {{ISI:000173447700003}},
}

@article{ ISI:000169965200002,
Author = {Thelwall, M},
Title = {{Web log file analysis: backlinks and queries}},
Journal = {{ASLIB PROCEEDINGS}},
Year = {{2001}},
Volume = {{53}},
Number = {{6}},
Pages = {{217-223}},
Month = {{JUN}},
Abstract = {{As has been described elsewhere, web log files are a useful source of
   information about visitor site use, navigation behaviour, and, to some
   extent, demographics. But log files can also reveal the existence of
   both web pages and search engine queries that are sources of new
   visitors. This study extracts such information from a single web log
   file and uses it to illustrate its value, not only to the site owner but
   also to those interested in investigating the online behaviour of web
   users.}},
Publisher = {{ASLIB}},
Address = {{STAPLE HALL, STONE HOUSE COURT, LONDON EC3A 7PB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Thelwall, M (Reprint Author), Wolverhampton Univ, Sch Comp \& Informat Technol, Wulfruna St, Wolverhampton WV1 1SB, England.
   Wolverhampton Univ, Sch Comp \& Informat Technol, Wolverhampton WV1 1SB, England.}},
DOI = {{10.1108/EUM0000000007055}},
ISSN = {{0001-253X}},
Keywords-Plus = {{SEARCH ENGINES; INFORMATION; SITES}},
Research-Areas = {{Computer Science; Information Science \& Library Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Information Science \& Library
   Science}},
ResearcherID-Numbers = {{Thelwall, Mike/C-1449-2013}},
ORCID-Numbers = {{Thelwall, Mike/0000-0001-6065-205X}},
Number-of-Cited-References = {{18}},
Times-Cited = {{15}},
Journal-ISO = {{Aslib Proc.}},
Doc-Delivery-Number = {{454GQ}},
Unique-ID = {{ISI:000169965200002}},
}

@article{ ISI:000169705000008,
Author = {Wilson, AS and Kitas, GD and Llewellyn, P and Carruthers, DM and
   Cheseldine, DC and Harris, S and Huissoon, AP and Bacon, PA and Young,
   SP},
Title = {{Provision of Internet-based rheumatology education (http
   ://rheuma.bham.ac.uk)}},
Journal = {{RHEUMATOLOGY}},
Year = {{2001}},
Volume = {{40}},
Number = {{6}},
Pages = {{645-651}},
Month = {{JUN}},
Abstract = {{Objectives. The Internet is becoming an important way of delivering
   medical information, and if used appropriately may assist in improving
   patients' self-management of their disease. We have established an
   arthritis education website ('Arthritis Help') and investigated its use
   over the last 2 yr.
   Method's, Computer-generated log-file analysis and on-line
   questionnaires were used to create user profiles of our website.
   Results. An average of 288 people visited our site each day,
   predominantly from America and the UK (49\% of users). The typical
   questionnaire respondent (n = 770) was an American female with
   arthritis, aged 30+ yr, accessing the Internet from home. Typically,
   respondents had previously obtained information from medical staff or in
   written form, but Were now more likely to use the Internet. One hundred
   and sixty-seven out of 585 respondents found our site to be useful,
   prompting them to seek more information (29\%), change their behaviour
   or engage in more effective discussions with their physician (15\%).
   Conclusions. These data indicate that it is possible to use the Internet
   to deliver medical information to its target audience, and that this
   process can have some impact on the way disease is self-managed. This
   information may aid more focused website design to maximize the use and
   potential benefits of such a resource.}},
Publisher = {{OXFORD UNIV PRESS}},
Address = {{GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wilson, AS (Reprint Author), Univ Birmingham, Dept Rheumatol, Div Immun \& Infect, Birmingham B15 2TT, W Midlands, England.
   Univ Birmingham, Dept Rheumatol, Div Immun \& Infect, Birmingham B15 2TT, W Midlands, England.
   Univ Birmingham, Canc Res Campaign Clin Trials Unit, Birmingham B15 2TT, W Midlands, England.
   Guest Hosp, Dudley Grp Hosp NHS Trust, Dept Rheumatol, Dudley DY1 4SE, W Midlands, England.}},
DOI = {{10.1093/rheumatology/40.6.645}},
ISSN = {{1462-0324}},
Keywords = {{rheumatology; education; arthritis; Internet; World Wide Web; rheumatoid
   arthritis; osteoarthritis; systemic lupus erythematosus}},
Keywords-Plus = {{PATIENT EDUCATION; CHRONIC ARTHRITIS; HEALTH-CARE}},
Research-Areas = {{Rheumatology}},
Web-of-Science-Categories  = {{Rheumatology}},
ResearcherID-Numbers = {{Young, Stephen/A-7380-2008}},
ORCID-Numbers = {{Young, Stephen/0000-0002-6355-3361}},
Number-of-Cited-References = {{15}},
Times-Cited = {{16}},
Journal-ISO = {{RHEUMATOLOGY}},
Doc-Delivery-Number = {{449UF}},
Unique-ID = {{ISI:000169705000008}},
}

@article{ ISI:000168009200002,
Author = {Ribaric, S and Todorovski, L and Dimec, J and Lunder, T},
Title = {{Presentation of dermatological images on the Internet}},
Journal = {{COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE}},
Year = {{2001}},
Volume = {{65}},
Number = {{2}},
Pages = {{111-121}},
Month = {{MAY}},
Abstract = {{In this paper, we focused on selected problems of integrating and
   presenting medical images organised in a World Wide Web (WW) database.
   To solve these problems we developed a prototype of a bilingual
   (Slovenian and English) WWW database of medical images for the field of
   dermatology. This dermatology database includes a graphic interface with
   four modes of access: (1) browsing, (2) searching, (3) comparison of
   images, and (4) self-testing. The quantity and quality of requests to
   this WWW database was estimated with log file analysis. There was a
   steady increase in the number of users and volume of data transfer-red
   from the dermatology WWW database. (C) 2001 Elsevier Science Ireland
   Ltd. All rights reserved.}},
Publisher = {{ELSEVIER SCI IRELAND LTD}},
Address = {{CUSTOMER RELATIONS MANAGER, BAY 15, SHANNON INDUSTRIAL ESTATE CO, CLARE,
   IRELAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ribaric, S (Reprint Author), Fac Med, Inst Pathophysiol, Zaloska 4, SI-1000 Ljubljana, Slovenia.
   Fac Med, Inst Pathophysiol, SI-1000 Ljubljana, Slovenia.
   Fac Med, Inst Biomed Informat, SI-1000 Ljubljana, Slovenia.
   Univ Med Ctr, Dept \& Chair Dermatovenerol, SI-1000 Ljubljana, Slovenia.}},
DOI = {{10.1016/S0169-2607(00)00118-8}},
ISSN = {{0169-2607}},
Keywords = {{medical images; dermatology database; self-learning; internet; user
   interfaces}},
Keywords-Plus = {{ANGIOGRAPHY}},
Research-Areas = {{Computer Science; Engineering; Medical Informatics}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Computer Science,
   Theory \& Methods; Engineering, Biomedical; Medical Informatics}},
Number-of-Cited-References = {{5}},
Times-Cited = {{1}},
Journal-ISO = {{Comput. Meth. Programs Biomed.}},
Doc-Delivery-Number = {{420MR}},
Unique-ID = {{ISI:000168009200002}},
}

@inproceedings{ ISI:000171796600001,
Author = {Graef, G and Gaedke, M},
Editor = {{Bauknecht, K and Madria, SK and Pernul, G}},
Title = {{Construction of adaptive web-applications from reusable components}},
Booktitle = {{ELECTRONIC COMMERCE AND WEB TECHNOLOGIES, PROCEEDINGS}},
Series = {{LECTURE NOTES IN COMPUTER SCIENCE}},
Year = {{2000}},
Volume = {{1875}},
Pages = {{1-12}},
Note = {{1st International Conference on Electronic Commerce and Web
   Technologies, LONDON, ENGLAND, SEP 04-06, 2000}},
Abstract = {{The Web has become a ubiquitous environment for application delivery.
   The originally intended idea, as a distributed system for
   knowledge-interchange, has given way to organizations offering their
   products and services using the Web as a global point of sale. The
   centralized delivery-mechanism enables the construction of E-Commerce
   applications personalized for each user by using behavior analysis.
   Current technologies suffer from the Web's legacy and use Log
   file-analysis or collaborative filtering only to adapt the content to
   users' needs. Motivated by the results of collaborative filtering
   algorithms, we describe a construction approach based on the abstract
   concept of services. To support the fine-grained concept we use the
   component-based WebComposition Markup Language to support reuse and
   seamless evolution of E-Commerce applications.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Graef, G (Reprint Author), Univ Karlsruhe, TecO, Vincenz Priessnitz Str 1, D-76131 Karlsruhe, Germany.
   Univ Karlsruhe, TecO, D-76131 Karlsruhe, Germany.}},
ISSN = {{0302-9743}},
ISBN = {{3-540-67981-2}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods}},
Number-of-Cited-References = {{17}},
Times-Cited = {{0}},
Doc-Delivery-Number = {{BT05Y}},
Unique-ID = {{ISI:000171796600001}},
}

@article{ ISI:000084946300028,
Author = {Heautot, JF and Eichelberg, M and Gibaud, B and Treguier, C and Lemoine,
   D and Scarabin, JM and Piqueras, J and Carsin, M and Gandon, Y},
Title = {{The RETAIN project: dicom teleradiology over an ATM-based network}},
Journal = {{EUROPEAN RADIOLOGY}},
Year = {{2000}},
Volume = {{10}},
Number = {{1}},
Pages = {{175-182}},
Abstract = {{The RETAIN project (Radiological Examinations Transfer on an ATM
   Integrated Network) has aimed at testing videoconferencing and DICOM
   image transfers to get advice about difficult radiological cases over an
   asynchronous transfer mode (ATM)-based network, which affords a more
   comfortable interface than narrow-band networks and allows exchange of
   complete image series using the DICOM format of studies, For this
   purpose, an experimental ATM network was applied between six university
   hospitals in four different countries. An assessment of the
   functionalities of the system was performed by means of log-file
   analysis, video recording of the sessions and forms filled out by the
   participants at the end of each session. Questionnaires were answered by
   the users at the end of the project to bring out perspectives of
   utilisation and added value, We discussed 43 cases during 20 sessions.
   For technical or organisational problems, only 20 of the 36 planned
   sessions took place. The throughput over ATM (10.5 Mbit/s, 20 times
   faster than six ISDN B-channels) was adequate. Despite the experimental
   configuration of the network, the system was considered as satisfactory
   by all the physicians. In 72 \% of the sessions, the expected result
   (answer to the question) was gained. By common consent,
   videoconferencing was unanimously regarded as a prominent tool in
   improving the interaction quality. Asynchronous transfer mode is an
   efficient method for fast transferring of radiologic examinations in
   DICOM format and for discussing them through high-quality
   videoconferencing.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Heautot, JF (Reprint Author), CHRU Pontchaillou, Serv Radiol Cent, F-35033 Rennes, France.
   CHRU Pontchaillou, Serv Radiol Cent, F-35033 Rennes, France.
   OFFIS, D-26121 Oldenburg, Germany.
   Lab Signaux \& Images Med, Fac Med, F-35000 Rennes, France.
   ETIAM SA, F-35000 Rennes, France.
   CHRU Pontchaillou, Serv Neurochirurg, F-35033 Rennes, France.
   Hosp Materno Infantil Vall Hebron, E-08035 Barcelona, Spain.}},
DOI = {{10.1007/s003300050029}},
ISSN = {{0938-7994}},
Keywords = {{teleradiology; telemedicine; DICOM; ATM; assessment}},
Keywords-Plus = {{ASYNCHRONOUS TRANSFER MODE; TECHNOLOGY}},
Research-Areas = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Web-of-Science-Categories  = {{Radiology, Nuclear Medicine \& Medical Imaging}},
ResearcherID-Numbers = {{Piqueras, Joaquim/}},
ORCID-Numbers = {{Piqueras, Joaquim/0000-0002-8983-3732}},
Number-of-Cited-References = {{19}},
Times-Cited = {{4}},
Journal-ISO = {{Eur. Radiol.}},
Doc-Delivery-Number = {{277RA}},
Unique-ID = {{ISI:000084946300028}},
}

@article{ ISI:000083448000035,
Author = {D'Alessandro, DM and Kreiter, CD},
Title = {{Improving usage of pediatric information on the Internet: The Virtual
   Children's Hospital}},
Journal = {{PEDIATRICS}},
Year = {{1999}},
Volume = {{104}},
Number = {{5}},
Pages = {{art. no.-e55}},
Month = {{NOV}},
Abstract = {{Objective. Digital health sciences libraries (DHSLs) bring order to the
   chaos of the Internet by making authoritative medical information easily
   and conveniently available to patrons. The goal of this project was to
   perform a baseline usage analysis of the pediatric-related information
   in a general DHSL and to determine whether reorganization of the
   pediatric-related information into its own pediatric DHSL could increase
   the usage of the pediatric-related information.
   Methods. From March through August 1997, a baseline analysis of a
   general DHSL (Virtual Hospital) was conducted using computer server log
   file analysis programs. The quantity of pediatric-related information in
   the general DHSL and its baseline usage were determined. In September
   1997, the pediatric-related information was reorganized into its own
   pediatric DHSL (Virtual Children's Hospital), and server log file
   analyses were conducted of the pediatric DHSL from September 1997 to
   August 1998. Statistical analysis was performed by time series
   autoregression.
   Results. During the baseline, the general DHSL and the pediatric-related
   information received a monthly average of 2 320 782 and 141 444
   qualified hits, respectively. After the intervention, the general DHSL
   and the pediatric DHSL received a monthly average of 2 765 454 and 256
   998 qualified hits, respectively. This is an increase of 19.2\% for the
   general DHSL and 81.7\% for the pediatric DHSL. These changes were
   statistically significant at the P > .0001 level. The most requested
   pediatric-related content in the pediatric DHSL did not change
   substantively from preintervention to postintervention.
   Discussion. On the Internet, as in real life, children's services must
   have their own distinct identity and must be differentiated from adult
   services. Therefore, pediatric-related information will receive
   increased usage if it is part of a pediatric DHSL rather than part of a
   general DHSL. Others can use this process and the lessons learned to
   develop and enhance their own pediatric-related information on the
   Internet.}},
Publisher = {{AMER ACAD PEDIATRICS}},
Address = {{141 NORTH-WEST POINT BLVD,, ELK GROVE VILLAGE, IL 60007-1098 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{D'Alessandro, DM (Reprint Author), Childrens Hosp Iowa, Dept Pediat, 200 Hawkins Dr, Iowa City, IA 52242 USA.
   Childrens Hosp Iowa, Dept Pediat, Iowa City, IA 52242 USA.
   Univ Iowa, Coll Med, Off Consultat \& Res Med Educ, Iowa City, IA USA.}},
DOI = {{10.1542/peds.104.5.e55}},
ISSN = {{0031-4005}},
Keywords = {{Internet; pediatrics; digital health sciences libraries; digital
   library; medical library}},
Keywords-Plus = {{WORLD-WIDE-WEB; RESOURCES; QUALITY; LIBRARY}},
Research-Areas = {{Pediatrics}},
Web-of-Science-Categories  = {{Pediatrics}},
Number-of-Cited-References = {{16}},
Times-Cited = {{4}},
Journal-ISO = {{Pediatrics}},
Doc-Delivery-Number = {{251LW}},
Unique-ID = {{ISI:000083448000035}},
}

@article{ ISI:000080299400039,
Author = {Peterson, MW and Galvin, JR and Dayton, C and D'Alessandro, MP},
Title = {{Realizing the promise - Delivering pulmonary continuing medical
   education over the Internet}},
Journal = {{CHEST}},
Year = {{1999}},
Volume = {{115}},
Number = {{5}},
Pages = {{1429-1436}},
Month = {{MAY}},
Abstract = {{Study objectives: Continuing medical education (CME) is meant to bridge
   the gap between new scientific observations and clinical practice.
   However, traditional CR IE has not been effective at altering the
   behaviors of physicians. One reason for this failure of traditional CME
   programs may; be their inflexibility, In traditional CME, the clinician
   does not choose the topic, the pace of the program, or the place of
   learning, and the CME material cannot be easily delivered to the point
   of care where the clinician needs the information. Computers and
   computer networks have the potential to accomplish these goals. CME has
   begun to appear on the Inter-net; however, there have been few
   evaluations of its usefulness, acceptance, and effectiveness. Over the
   last 18 months, we have developed three on-line pulmonary CME programs,
   and we have delivered them on the Virtual Hospital, the University of
   Iowa's digital health sciences library on the Internet, We report our
   initial experience with this CME material.
   Design: We measured the frequency with which the Internet-delivered CME
   is accessed by monitoring page accessions and by using a log file
   analysis program (Analog 1.2.3; University of Cambridge Statistical
   Laboratory; Cambridge, UK), In addition, we collected all completed CME
   examinations and evaluation forms submitted by registered users.
   Measurements and results: We have found that the frequency with which
   the Internet-delivered CME is accessed has continued to increase with
   time (2.3-fold increase over 18 months), that evaluations of technical
   and content issues are strongly favorable, and that some clinicians have
   been willing to pay to receive CME through the medium of the Internet,
   Conclusions: We feel that with adequate peer review and quality control,
   physicians will use the Internet-delivered CME. However, several
   obstacles to nide use remain. These obstacles include issues regarding
   training in using the Internet for physicians, reluctance of physicians
   to participate in on-line commerce, and the current unavailability of
   CME to be delivered in small-grained quantities to the point of care, As
   these issues are addressed, we feel that on-line CME will represent an
   increasingly important CME medium for clinicians.}},
Publisher = {{AMER COLL CHEST PHYSICIANS}},
Address = {{3300 DUNDEE ROAD, NORTHBROOK, IL 60062-2348 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Peterson, MW (Reprint Author), Univ Iowa, Coll Med, Dept Internal Med, C33H GH, Iowa City, IA 52242 USA.
   Univ Iowa, Coll Med, Dept Internal Med, Iowa City, IA 52242 USA.
   Univ Iowa, Coll Med, Dept Pharmaceut Care, Iowa City, IA 52242 USA.
   Univ Iowa, Coll Med, Dept Radiol, Iowa City, IA 52242 USA.}},
DOI = {{10.1378/chest.115.5.1429}},
ISSN = {{0012-3692}},
Keywords = {{computer; continuing education; internet}},
Keywords-Plus = {{WORLD-WIDE-WEB; INFORMATION NEEDS; CLINICAL QUESTIONS; RURAL PHYSICIAN;
   LIBRARY; MEDLINE; TRIAL; CARE}},
Research-Areas = {{General \& Internal Medicine; Respiratory System}},
Web-of-Science-Categories  = {{Critical Care Medicine; Respiratory System}},
ResearcherID-Numbers = {{D'Alessandro, Michael/}},
ORCID-Numbers = {{D'Alessandro, Michael/0000-0003-1772-4032}},
Number-of-Cited-References = {{39}},
Times-Cited = {{21}},
Journal-ISO = {{Chest}},
Doc-Delivery-Number = {{196FY}},
Unique-ID = {{ISI:000080299400039}},
}

@article{ ISI:000076507200022,
Author = {D'Alessandro, MP and D'Alessandro, DM and Galvin, JR and Erkonen, WE},
Title = {{Evaluating overall usage of a digital health sciences library}},
Journal = {{BULLETIN OF THE MEDICAL LIBRARY ASSOCIATION}},
Year = {{1998}},
Volume = {{86}},
Number = {{4}},
Pages = {{602-609}},
Month = {{OCT}},
Abstract = {{Background: Digital health sciences library (DHSL) evaluation involves
   studying the usage of the DHSL by individuals as well as populations.
   The purpose of this study was to evaluate trends in overall usage of a
   DHSL as part of a process of continuous quality improvement in order to
   learn how to enhance a DHSL in order to meet its users' needs better.
   Methods: Web server log file analysis was performed on a prototype DHSL,
   the Virtual Hospital, using two log file analysis programs on data from
   the month of February over four consecutive years, 1995 to 1998. Result:
   Overall DHSL usage increased between 1995 and 1997 and leveled off in
   1998. Fifteen percent of usage came from countries outside the United
   States. A broad spectrum of medical information for health care
   providers and patients was accessed and centered around specialty
   medical information. Conclusions: To be of optimal assistance to users,
   DHSLs should (1) contain a broad base of information on common and
   uncommon medical problems, (2) accommodate the needs of the significant
   percentage of users that are international through content translation
   and mirroring, and (3) ensure they are indexed and catalogued in the
   major Web search engines and Web general and medical indices so they can
   be easily found by users.}},
Publisher = {{MEDICAL LIBRARY ASSOC}},
Address = {{65 EAST WACKER PLACE, STE 1900, CHICAGO, IL 60601-7298 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{D'Alessandro, MP (Reprint Author), Univ Iowa Hosp \& Clin, Dept Radiol, 200 Hawkins Dr, Iowa City, IA 52242 USA.
   Univ Iowa, Coll Med, Dept Radiol, Iowa City, IA 52242 USA.
   Univ Iowa, Coll Med, Dept Pediat, Iowa City, IA 52242 USA.
   Univ Iowa, Coll Med, Dept Internal Med, Iowa City, IA 52242 USA.}},
ISSN = {{0025-7338}},
Keywords-Plus = {{INFORMATION}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
ResearcherID-Numbers = {{D'Alessandro, Donna/
   D'Alessandro, Michael/}},
ORCID-Numbers = {{D'Alessandro, Donna/0000-0001-7972-9088
   D'Alessandro, Michael/0000-0003-1772-4032}},
Number-of-Cited-References = {{20}},
Times-Cited = {{16}},
Journal-ISO = {{Bull. Med. Libr. Assoc.}},
Doc-Delivery-Number = {{130EP}},
Unique-ID = {{ISI:000076507200022}},
}

@article{ ISI:000071443000020,
Author = {D'Alessandro, MP and Galvin, JR},
Title = {{SPR Online: Creating, maintaining, and distributing a virtual
   professional society on the Internet}},
Journal = {{RADIOGRAPHICS}},
Year = {{1998}},
Volume = {{18}},
Number = {{1}},
Pages = {{189-194}},
Month = {{JAN-FEB}},
Abstract = {{SPR Online (http://www.pedrad.org) is a recently developed digital
   representation of the Society for Pediatric Radiology (SPR) that enables
   physicians to access pertinent information and services on the Internet.
   SPR Online was organized on the basis of the five main services of the
   SPR, which include Administration, Patient Care, Education, Research,
   and Meetings. For each service, related content from the SPR was
   digitized and placed onto SPR Online. Usage over a 12-month period was
   evaluated with server log file analysis. A total of 3,209 users accessed
   SPR Online, viewing 11,246 pages of information. A wide variety of
   information was accessed, with that from the Education, Administration,
   and Meetings services being the most popular. Fifteen percent of users
   came from foreign countries. As a virtual professional society, SPR
   Online greatly enhances the power and scope of the SPR and has proved to
   be a popular resource, meeting the diverse information needs of an
   international community of pediatric radiologists.}},
Publisher = {{RADIOLOGICAL SOC NORTH AMER}},
Address = {{20TH AND NORTHAMPTON STS, EASTON, PA 18042 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{D'Alessandro, MP (Reprint Author), Univ Iowa Hosp \& Clin, Dept Radiol, Elect Differential Multimedia Lab, 200 Hawkins Dr, Iowa City, IA 52242 USA.
   Univ Iowa Hosp \& Clin, Dept Radiol, Elect Differential Multimedia Lab, Iowa City, IA 52242 USA.}},
ISSN = {{0271-5333}},
Keywords = {{computers; Internet; radiology and radiologists}},
Keywords-Plus = {{INFORMATION; WEB}},
Research-Areas = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Web-of-Science-Categories  = {{Radiology, Nuclear Medicine \& Medical Imaging}},
ResearcherID-Numbers = {{D'Alessandro, Michael/}},
ORCID-Numbers = {{D'Alessandro, Michael/0000-0003-1772-4032}},
Number-of-Cited-References = {{5}},
Times-Cited = {{3}},
Journal-ISO = {{Radiographics}},
Doc-Delivery-Number = {{YQ965}},
Unique-ID = {{ISI:000071443000020}},
}

@article{ ISI:A1997YC76800005,
Author = {Bertot, JC and McClure, CR and Moen, WE and Rubin, J},
Title = {{Web usage statistics: Measurement issues and analytical techniques}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1997}},
Volume = {{14}},
Number = {{4}},
Pages = {{373-395}},
Abstract = {{The number of federal agencies creating and maintaining electronic
   networked resources continues to increase. One networked resource
   federal agencies are increasingly using is the World Wide Web (Web). As
   government use of the Web rises, so too does the need for assessing the
   extent and nature of public use of agency Web sites. One means of Web
   use evaluation is through the analysis of Web server-generated log
   files. This article presents various log file analysis techniques and
   issues related to the interpretation of log file data.}},
Publisher = {{JAI PRESS INC}},
Address = {{55 OLD POST RD-\#2, PO BOX 1678, GREENWICH, CT 06836-1678}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bertot, JC (Reprint Author), UNIV MARYLAND BALTIMORE CTY,DEPT INFORMAT SYST,1000 HILLTOP CIRCLE,BALTIMORE,MD 21250, USA.}},
DOI = {{10.1016/S0740-624X(97)90034-4}},
ISSN = {{0740-624X}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Number-of-Cited-References = {{10}},
Times-Cited = {{27}},
Journal-ISO = {{Gov. Inf. Q.}},
Doc-Delivery-Number = {{YC768}},
Unique-ID = {{ISI:A1997YC76800005}},
}

@article{ ISI:A1995QV57500035,
Author = {CATLEDGE, LD and PITKOW, JE},
Title = {{CHARACTERIZING BROWSING STRATEGIES IN THE WORLD-WIDE-WEB}},
Journal = {{COMPUTER NETWORKS AND ISDN SYSTEMS}},
Year = {{1995}},
Volume = {{27}},
Number = {{6}},
Pages = {{1065-1073}},
Month = {{APR}},
Note = {{3rd International World-Wide Web Conference, DARMSTADT, GERMANY, APR
   10-14, 1995}},
Abstract = {{This paper presents the results of a study conducted at Georgia
   Institute of Technology that captured client-side user events of NCSA's
   XMosaic. Actual user behavior, as determined from client-side log file
   analysis, supplemented our understanding of user navigation strategies
   as well as provided real interface usage data. Log file analysis also
   yielded design and usability suggestions for WWW pages, sites and
   browsers. The methodology of the study and findings are discussed along
   with future research directions.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{CATLEDGE, LD (Reprint Author), GEORGIA INST TECHNOL,SCH LITERATURE COMMUN \& CULTURE,ATLANTA,GA 30332, USA.
   GEORGIA INST TECHNOL,CTR GRAPH VISUALIZ \& USABIL,ATLANTA,GA 30332.}},
DOI = {{10.1016/0169-7552(95)00043-7}},
ISSN = {{0169-7552}},
Keywords = {{HYPERTEXT NAVIGATION; LOG FILES; USER MODELING}},
Keywords-Plus = {{ONLINE}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Number-of-Cited-References = {{16}},
Times-Cited = {{214}},
Journal-ISO = {{Comput. Netw. ISDN Syst.}},
Doc-Delivery-Number = {{QV575}},
Unique-ID = {{ISI:A1995QV57500035}},
}
