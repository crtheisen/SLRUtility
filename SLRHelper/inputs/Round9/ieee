TY  - CONF
JO  - Globecom Workshops (GC Wkshps), 2013 IEEE
TI  - Massive distributed and parallel log analysis for organizational security
T2  - Globecom Workshops (GC Wkshps), 2013 IEEE
IS  - 
SN  - 
VO  - 
SP  - 194
EP  - 199
AU  - Xiaokui Shu
AU  - Smiy, J.
AU  - Danfeng Yao
AU  - Heshan Lin
Y1  - 9-13 Dec. 2013
PY  - 2013
KW  - cloud computing
KW  - distributed processing
KW  - security of data
KW  - system monitoring
KW  - Amazon cloud environments
KW  - EC2
KW  - MapReduce
KW  - S3
KW  - cloud-based distributed framework
KW  - dynamic task scheduling
KW  - log data demands
KW  - massive distributed frameworks
KW  - organizational security
KW  - parallel security log analysis framework
KW  - streaming logs
KW  - transaction logs
KW  - Cloud computing
KW  - Conferences
KW  - Data privacy
KW  - Organizations
KW  - Security
VL  - 
JA  - Globecom Workshops (GC Wkshps), 2013 IEEE
DO  - 10.1109/GLOCOMW.2013.6824985
AB  - Security log analysis is extremely useful for uncovering intrusions and anomalies. However, the sheer volume of log data demands new frameworks and techniques of computing and security. We present a lightweight distributed and parallel security log analysis framework that allows organizations to analyze a massive number of system, network, and transaction logs efficiently and scalably. Different from the general distributed frameworks, e.g., MapReduce, our framework is specifically designed for security log analysis. It features a minimum set of necessary properties, such as dynamic task scheduling for streaming logs. For prototyping, we implement our framework in Amazon cloud environments (EC2 and S3) with a basic analysis application. Our evaluation demonstrates the effectiveness of our design and shows the potential of our cloud-based distributed framework in large-scale log analysis scenarios.
ER  - 

TY  - CONF
JO  - Software Engineering (ICSE), 2013 35th International Conference on
TI  - Measuring the forensic-ability of audit logs for nonrepudiation
T2  - Software Engineering (ICSE), 2013 35th International Conference on
IS  - 
SN  - 
VO  - 
SP  - 1419
EP  - 1422
AU  - King, J.
Y1  - 18-26 May 2013
PY  - 2013
KW  - auditing
KW  - digital forensics
KW  - educational computing
KW  - financial data processing
KW  - fraud
KW  - health care
KW  - software metrics
KW  - system monitoring
KW  - activity logging mechanism
KW  - application performance monitoring
KW  - audit log
KW  - compliance checking
KW  - data field
KW  - debugging
KW  - education
KW  - finance
KW  - forensic ability measurement
KW  - forensic analysis
KW  - fraud detection
KW  - grounded theory method
KW  - healthcare
KW  - log file attribute
KW  - software log files
KW  - software security events
KW  - software security metrics
KW  - software system
KW  - system resources
KW  - unique user identifier
KW  - user access tracking
KW  - user behavior profile extraction
KW  - user nonrepudiation
KW  - user privilege revocation
KW  - Forensics
KW  - Measurement
KW  - Medical services
KW  - Security
KW  - Software systems
KW  - Standards
KW  - forensics
KW  - grounded theory
KW  - logging
KW  - metric
KW  - nonrepudiation
KW  - security
KW  - software logs
VL  - 
JA  - Software Engineering (ICSE), 2013 35th International Conference on
DO  - 10.1109/ICSE.2013.6606732
AB  - Forensic analysis of software log files is used to extract user behavior profiles, detect fraud, and check compliance with policies and regulations. Software systems maintain several types of log files for different purposes. For example, a system may maintain logs for debugging, monitoring application performance, and/or tracking user access to system resources. The objective of my research is to develop and validate a minimum set of log file attributes and software security metrics for user nonrepudiation by measuring the degree to which a given audit log file captures the data necessary to allow for meaningful forensic analysis of user behavior within the software system. For a log to enable user nonrepudiation, the log file must record certain data fields, such as a unique user identifier. The log must also record relevant user activity, such as creating, viewing, updating, and deleting system resources, as well as software security events, such as the addition or revocation of user privileges. Using a grounded theory method, I propose a methodology for observing the current state of activity logging mechanisms in healthcare, education, and finance, then I quantify differences between activity logs and logs not specifically intended to capture user activity. I will then propose software security metrics for quantifying the forensic-ability of log files. I will evaluate my work with empirical analysis by comparing the performance of my metrics on several types of log files, including both activity logs and logs not directly intended to record user activity. My research will help software developers strengthen user activity logs for facilitating forensic analysis for user nonrepudiation.
ER  - 

TY  - CONF
JO  - Military Communications Conference (MILCOM), 2014 IEEE
TI  - Using Security Logs for Collecting and Reporting Technical Security Metrics
T2  - Military Communications Conference (MILCOM), 2014 IEEE
IS  - 
SN  - 
VO  - 
SP  - 294
EP  - 299
AU  - Vaarandi, R.
AU  - Pihelgas, M.
Y1  - 6-8 Oct. 2014
PY  - 2014
KW  - Big Data
KW  - computer network security
KW  - big data
KW  - log analysis methods
KW  - log analysis techniques
KW  - open source technology
KW  - security logs
KW  - technical security metric collection
KW  - technical security metric reporting
KW  - Correlation
KW  - Internet
KW  - Measurement
KW  - Monitoring
KW  - Peer-to-peer computing
KW  - Security
KW  - Workstations
KW  - security log analysis
KW  - security metrics
VL  - 
JA  - Military Communications Conference (MILCOM), 2014 IEEE
DO  - 10.1109/MILCOM.2014.53
AB  - During recent years, establishing proper metrics for measuring system security has received increasing attention. Security logs contain vast amounts of information which are essential for creating many security metrics. Unfortunately, security logs are known to be very large, making their analysis a difficult task. Furthermore, recent security metrics research has focused on generic concepts, and the issue of collecting security metrics with log analysis methods has not been well studied. In this paper, we will first focus on using log analysis techniques for collecting technical security metrics from security logs of common types (e.g., Network IDS alarm logs, workstation logs, and Net flow data sets). We will also describe a production framework for collecting and reporting technical security metrics which is based on novel open-source technologies for big data.
ER  - 

TY  - CONF
JO  - Future Information Technology (FutureTech), 2010 5th International Conference on
TI  - Intrusion Investigations with Data-Hiding for Computer Log-File Forensics
T2  - Future Information Technology (FutureTech), 2010 5th International Conference on
IS  - 
SN  - 
VO  - 
SP  - 1
EP  - 6
AU  - Ya-Ting Fan
AU  - Shiuh-Jeng Wang
Y1  - 21-23 May 2010
PY  - 2010
KW  - computer forensics
KW  - data privacy
KW  - steganography
KW  - system monitoring
KW  - backup logs
KW  - computer forensics operation
KW  - computer log file forensics
KW  - data hiding
KW  - information security
KW  - intrusion investigation
KW  - logging mechanism
KW  - steganography
KW  - traditional log security strategy
KW  - Computer network management
KW  - Computer networks
KW  - Computer security
KW  - Data security
KW  - Forensics
KW  - Information security
KW  - Internet
KW  - Maintenance
KW  - Management training
KW  - Protection
VL  - 
JA  - Future Information Technology (FutureTech), 2010 5th International Conference on
DO  - 10.1109/FUTURETECH.2010.5482741
AB  - In most of companies or organizations, logs play important role in information security. However, the common security mechanism only backup logs, it is not able to find out traces of intruders because the hacker who is able to intrudes the security mechanism of organization would try to alter logs or destroy important intrusion evidences making it impossible to preserve evidence using traditional log security strategies. Thus, logs are not considered as evidence to prove the damage. In that case, digital evidence lacks in terms of completeness which makes it difficult to perform computer forensics operations. In order to maintain the completeness and reliability of evidence for later forensic procedures and intrusion detection, the study applies concepts of steganography to logs forensics, for which even intrusion altered records will be kept as well. Comparing to traditional security strategies, this study proposes a better logging mechanism to ensure the completeness of logs. Furthermore, the study will assist in intrusion detection through alteration behavior, and help in forensic operations.
ER  - 

TY  - CONF
JO  - Systematic Approaches to Digital Forensic Engineering (SADFE), 2010 Fifth IEEE International Workshop on
TI  - Explorative Visualization of Log Data to Support Forensic Analysis and Signature Development
T2  - Systematic Approaches to Digital Forensic Engineering (SADFE), 2010 Fifth IEEE International Workshop on
IS  - 
SN  - 
VO  - 
SP  - 109
EP  - 118
AU  - Schmerl, S.
AU  - Vogel, M.
AU  - Rietz, R.
AU  - Ko&#x0308;nig, H.
Y1  - 20-20 May 2010
PY  - 2010
KW  - computer forensics
KW  - data visualisation
KW  - digital signatures
KW  - computers security threats
KW  - explorative log data visualization
KW  - forensic analysis
KW  - intrusion detection systems
KW  - signature development
KW  - Character generation
KW  - Communication networks
KW  - Communication system security
KW  - Data security
KW  - Data visualization
KW  - Digital forensics
KW  - Event detection
KW  - Information analysis
KW  - Information security
KW  - Proposals
KW  - Attack Signatures
KW  - Audit Data Analysis
KW  - Computer Forensic
KW  - Computer Security
KW  - Data Visualization
KW  - Intrusion Detection
KW  - Misuse Detection
VL  - 
JA  - Systematic Approaches to Digital Forensic Engineering (SADFE), 2010 Fifth IEEE International Workshop on
DO  - 10.1109/SADFE.2010.10
AB  - Today's growing number of security threats to computers and networks also increase the importance of log inspections to support the detection of possible breaches. The investigation and assessment of security incidents becomes more and more a daily business. Further, the manual log analysis is essentially in the context of developing signatures for intrusion detection systems (IDS), which allow for an automated defense against security attacks or incidents. But the analysis of log data in the context of fo-rensic investigations and IDS signature development is a tedious and time-consuming task, due to the large amount of textual data. Moreover, this task requires a skilled knowledge to differentiate between the important and the non-relevant information. In this paper, we propose an approach for log resp. audit data representation, which aims at simplifying the analysis process for the security officer. For this purpose audit data and existing relations between audit events are represented graphically in a three-dimensional space. We describe a general approach for analyzing and exploring audit or log data in the context of this presentation paradigm. Further, we introduce our tool, which implements this approach and demonstrate the strengths and benefits of this presentation and exploration form.
ER  - 

TY  - JOUR
JO  - Network, IEEE
TI  - Flow-net methodology for accountability in wireless networks
T2  - Network, IEEE
IS  - 5
SN  - 0890-8044
VO  - 23
SP  - 30
EP  - 37
AU  - Yang Xiao
Y1  - September 2009
PY  - 2009
KW  - access protocols
KW  - computer network management
KW  - mobile computing
KW  - security of data
KW  - telecommunication network routing
KW  - computing infrastructure
KW  - flow net methodology
KW  - forensic purposes
KW  - intrusion detection purposes
KW  - media access control
KW  - network infrastructure
KW  - routing layers
KW  - traffic data collection
KW  - wireless network accountability
KW  - Communication system traffic control
KW  - Computer crime
KW  - Computer networks
KW  - Forensics
KW  - Information security
KW  - Intrusion detection
KW  - Media Access Protocol
KW  - Reconnaissance
KW  - Routing
KW  - Wireless networks
VL  - 23
JA  - Network, IEEE
DO  - 10.1109/MNET.2009.5274919
AB  - Accountability implies that any entity should be held responsible for its own specific action or behavior so that the entity is part of larger chains of accountability. One of the goals of accountability is that once an event has transpired, the events that took place are traceable so that the causes can be determined afterward. The poor accountability provided by today's computers and networks wastes a great deal of money and effort; examples include activities to identify whether a system is under reconnaissance or attack, and the difficulties of distinguishing legitimate emails from phishing attacks. This is due to the simple fact that today's computing and network infrastructure was not built with accountability in mind. In this article we propose a novel methodology called flow-net for accountability. We apply this methodology to media access control and routing layers in wireless networks. We then compare the performance of flow-net with audit log files. This article presents a novel approach for traffic data collection that can also be used for forensics and intrusion detection purposes.
ER  - 

TY  - CONF
JO  - Machine Learning and Cybernetics, 2003 International Conference on
TI  - Wavelet based data mining and querying in network security databases
T2  - Machine Learning and Cybernetics, 2003 International Conference on
IS  - 
SN  - 
VO  - 1
SP  - 178
EP  - 182 Vol.1
AU  - Wu Liu
AU  - Hai-Xin Duan
AU  - Ping Ren
AU  - Xing Li
AU  - Jian-Ping Wu
Y1  - 2-5 Nov. 2003
PY  - 2003
KW  - computer networks
KW  - data mining
KW  - database management systems
KW  - security of data
KW  - wavelet transforms
KW  - computer forensics
KW  - content-based queries
KW  - intrusion detection
KW  - network security databases
KW  - time-serial database
KW  - wavelet based data mining
KW  - wavelet transform analysis algorithm
KW  - Computer hacking
KW  - Computer networks
KW  - Computer security
KW  - Computer worms
KW  - Data mining
KW  - Data security
KW  - Databases
KW  - Forensics
KW  - Intrusion detection
KW  - Wavelet analysis
VL  - 1
JA  - Machine Learning and Cybernetics, 2003 International Conference on
DO  - 10.1109/ICMLC.2003.1264466
AB  - The phenomenal increase in the amounts of network security data are due to the hacker attacks, virus, worm and Slapper etc. Network security log databases are very important in intrusion detection and computer forensics. A lot of data mining methods to research it have been found. Fast and accurate retrievals for content-based queries are crucial for such numerous database systems to be useful. In this paper, a new method is provided to analyze and mine this kind of time-serial database. After signalize the NSD databases, we first represent a DWT wavelet transform analysis algorithm, then present two wavelet-based algorithms GET&#095;INDICES and QUERY for querying the complex and numerous NSD, and finally give the experimental result using these algorithms.
ER  - 

TY  - CONF
JO  - MILITARY COMMUNICATIONS CONFERENCE, 2010 - MILCOM 2010
TI  - Implementation and evaluation of accountability using flow-net in wireless networks
T2  - MILITARY COMMUNICATIONS CONFERENCE, 2010 - MILCOM 2010
IS  - 
SN  - 2155-7578
VO  - 
SP  - 7
EP  - 12
AU  - Yang Xiao
AU  - Ke Meng
AU  - Takahashi, D.
Y1  - Oct. 31 2010-Nov. 3 2010
PY  - 2010
KW  - authorisation
KW  - performance evaluation
KW  - radio networks
KW  - telecommunication security
KW  - accountability
KW  - audit log files
KW  - flow-net methodology
KW  - logging mechanism
KW  - logging system
KW  - performance evaluation
KW  - wireless networks
KW  - Complexity theory
KW  - Computers
KW  - IEEE 802.11 Standards
KW  - Security
KW  - Wireless LAN
KW  - Wireless networks
KW  - Accountability
KW  - Logging
KW  - Media Access Control (MAC)
KW  - Trace
KW  - routing
KW  - wireless networks
VL  - 
JA  - MILITARY COMMUNICATIONS CONFERENCE, 2010 - MILCOM 2010
DO  - 10.1109/MILCOM.2010.5680278
AB  - In order to provide accountability, a better logging system is needed so that not only the activities but also their relationships are captured. To this end, our previous work proposed a novel logging mechanism, flow-net methodology, for accountability. In this paper, we extend the flow-net methodology and present its design and implementation in wireless networks. We also evaluate the performance of flow-net and compare it to that of audit log files.
ER  - 

TY  - CONF
JO  - Communication Technology Proceedings, 2003. ICCT 2003. International Conference on
TI  - Wavelet-based analysis of network security databases
T2  - Communication Technology Proceedings, 2003. ICCT 2003. International Conference on
IS  - 
SN  - 
VO  - 1
SP  - 372
EP  - 377 vol.1
AU  - Wu Liu
AU  - Haixin Duan
AU  - Peng Wang
AU  - Jianping Wu
AU  - Lu Yang
Y1  - 9-11 April 2003
PY  - 2003
KW  - computer crime
KW  - computer network management
KW  - computer viruses
KW  - data mining
KW  - database management systems
KW  - wavelet transforms
KW  - computer forensics
KW  - computer virus
KW  - computer worm
KW  - content-based queries
KW  - data mining methods
KW  - hacker attacks
KW  - log file databases
KW  - network security data
KW  - network security databases
KW  - similarity searches
KW  - time-serial database
KW  - wavelet-based transform analysis
KW  - Computer hacking
KW  - Computer networks
KW  - Computer security
KW  - Computer worms
KW  - Content management
KW  - Data mining
KW  - Data security
KW  - Databases
KW  - Forensics
KW  - Wavelet analysis
VL  - 1
JA  - Communication Technology Proceedings, 2003. ICCT 2003. International Conference on
DO  - 10.1109/ICCT.2003.1209101
AB  - The phenomenal increase in the amounts of network security data are due to the hacker attacks, virus, worm and Shapper etc. Network security log file databases are very important in computer forensics. From researches, a lot of data mining methods have been found, such as content-based queries and similarity searches to manage and use such data. Fast and accurate retrievals for content-based queries are crucial for such numerous database systems to be useful. In this paper, a new method is provided to analyze and mine this kind of time-serial database. We first signalize the NSD databases, then we use these wavelet based transform to analyze the NSD and get the periodic law of intrusion event.
ER  - 

TY  - CONF
JO  - Network and Parallel Computing Workshops, 2007. NPC Workshops. IFIP International Conference on
TI  - A Log Analysis Audit Model Based on Optimized Clustering Algorithm
T2  - Network and Parallel Computing Workshops, 2007. NPC Workshops. IFIP International Conference on
IS  - 
SN  - 
VO  - 
SP  - 841
EP  - 848
AU  - Hui Yu
AU  - Xingjian Shi
Y1  - 18-21 Sept. 2007
PY  - 2007
KW  - auditing
KW  - pattern clustering
KW  - security of data
KW  - cluster number
KW  - network attack type
KW  - optimized clustering algorithm
KW  - security log analysis audit model
KW  - unknown intrusion detection
KW  - Algorithm design and analysis
KW  - Application software
KW  - Automatic control
KW  - Clustering algorithms
KW  - Computer science
KW  - Computer security
KW  - Data mining
KW  - Intrusion detection
KW  - Parallel processing
KW  - Protection
VL  - 
JA  - Network and Parallel Computing Workshops, 2007. NPC Workshops. IFIP International Conference on
DO  - 10.1109/NPC.2007.116
AB  - In view of the problem how to detect the network unknown attacks, a security log analysis audit model based on optimized clustering algorithm is proposed in this paper. Since the main question which influence the clustering algorithm application in the log analysis is uneasy to determine the network attack type and the cluster number, so we bring forward an optimized cluster algorithm to solve this problem. By means of simulated experiments, this algorithm is proved feasible, efficient and extensible for unknown intrusion detection.
ER  - 

TY  - CONF
JO  - Computer Science and Information Systems (FedCSIS), 2013 Federated Conference on
TI  - FAL: A forensics aware language for secure logging
T2  - Computer Science and Information Systems (FedCSIS), 2013 Federated Conference on
IS  - 
SN  - 
VO  - 
SP  - 1579
EP  - 1586
AU  - Zawoad, S.
AU  - Mernik, M.
AU  - Hasan, R.
Y1  - 8-11 Sept. 2013
PY  - 2013
KW  - data integrity
KW  - data privacy
KW  - digital forensics
KW  - specification languages
KW  - trusted computing
KW  - FAL
KW  - application logging
KW  - application logs
KW  - digital forensics
KW  - domain-specific language
KW  - forensics aware language
KW  - heterogeneous formats
KW  - log confidentiality
KW  - log integrity
KW  - log structure
KW  - logging security
KW  - source code generation
KW  - trustworthy system logs
KW  - DSL
KW  - Encryption
KW  - Indexes
KW  - Semantics
KW  - Syntactics
KW  - Audit Trail
KW  - DSL
KW  - Digital Forensics
KW  - Secure Logging
VL  - 
JA  - Computer Science and Information Systems (FedCSIS), 2013 Federated Conference on
DO  - 
AB  - Trustworthy system logs and application logs are crucial for digital forensics. Researchers have proposed different security mechanisms to ensure the integrity and confidentiality of logs. However, applying current secure logging schemes on heterogeneous formats of logs is tedious. Here, we propose FAL, a domain-specific language (DSL) through which we can apply a secure logging mechanism on any format of logs. Using FAL, we can define log structure, which represents the format of logs and ensures the security properties of a chosen secure logging scheme. This log structure can be later used by FAL to serve two purposes: it can be used to store system logs securely, and it will help application developers for secure application logging by generating required source code.
ER  - 

TY  - CONF
JO  - Cloud Computing and Intelligence Systems (CCIS), 2014 IEEE 3rd International Conference on
TI  - A model for website anomaly detection based on log analysis
T2  - Cloud Computing and Intelligence Systems (CCIS), 2014 IEEE 3rd International Conference on
IS  - 
SN  - 
VO  - 
SP  - 604
EP  - 608
AU  - Xu Han
AU  - Tao Lv
AU  - Lin Wei
AU  - Yanyan Wu
AU  - Jianyi Liu
AU  - Cong Wang
Y1  - 27-29 Nov. 2014
PY  - 2014
KW  - Algorithm design and analysis
KW  - Analytical models
KW  - Classification algorithms
KW  - Data models
KW  - Databases
KW  - Feature extraction
KW  - Security
KW  - Anomaly detection
KW  - C4.5 algorithm
KW  - Feature sets
KW  - Log analysis
VL  - 
JA  - Cloud Computing and Intelligence Systems (CCIS), 2014 IEEE 3rd International Conference on
DO  - 10.1109/CCIS.2014.7175806
AB  - To found security events from web logs has become an important aspect of network security. This paper proposes a website anomaly detection model based on security-log-analysis. After creating a anomaly feature sets of the model, C4.5 algorithm was used to improve feature sets, making the abnormal records in feature sets store hierarchically. Compared logs in website with the treated feature stes, the model ultimately achieves the purpose of checking website's security event fast and accurately.
ER  - 

TY  - CONF
JO  - Trust, Security and Privacy in Computing and Communications (TrustCom), 2013 12th IEEE International Conference on
TI  - S2Logger: End-to-End Data Tracking Mechanism for Cloud Data Provenance
T2  - Trust, Security and Privacy in Computing and Communications (TrustCom), 2013 12th IEEE International Conference on
IS  - 
SN  - 
VO  - 
SP  - 594
EP  - 602
AU  - Chun Hui Suen
AU  - Ko, R.K.L.
AU  - Yu Shyang Tan
AU  - Jagadpramana, P.
AU  - Bu Sung Lee
Y1  - 16-18 July 2013
PY  - 2013
KW  - cloud computing
KW  - data analysis
KW  - data loggers
KW  - data protection
KW  - security of data
KW  - system monitoring
KW  - S2Logger
KW  - atomic data events
KW  - cloud computing environments
KW  - cloud data provenance
KW  - cloud data provenance records
KW  - cloud servers
KW  - cloud stakeholders
KW  - critical data-related cloud security problems
KW  - data activities
KW  - data event analysis
KW  - data event capturing
KW  - data event logging mechanism
KW  - data event visualization
KW  - data leakages
KW  - data lifecycle
KW  - data movement accountability
KW  - data movement transparency
KW  - data policy violations
KW  - data tracking tools
KW  - data-centric logging techniques
KW  - end-to-end data tracking mechanism
KW  - file creation
KW  - file deletions
KW  - file duplication
KW  - file edition
KW  - file transfers
KW  - logging mechanisms
KW  - malicious actions
KW  - system-centric security tools
KW  - Cloud computing
KW  - Distributed databases
KW  - Kernel
KW  - Linux
KW  - Monitoring
KW  - Security
KW  - Virtual machine monitors
KW  - Cloud Computing
KW  - Cloud data provenance
KW  - S2Logger
KW  - accountability in cloud computing
KW  - cloud computing security
KW  - cloud computing transparency
KW  - data tracing
KW  - data tracking
KW  - file tracking
VL  - 
JA  - Trust, Security and Privacy in Computing and Communications (TrustCom), 2013 12th IEEE International Conference on
DO  - 10.1109/TrustCom.2013.73
AB  - The inability to effectively track data in cloud computing environments is becoming one of the top concerns for cloud stakeholders. This inability is due to two main reasons. Firstly, the lack of data tracking tools built for clouds. Secondly, current logging mechanisms are only designed from a system-centric perspective. There is a need for data-centric logging techniques which can trace data activities (e.g. file creation, edition, duplication, transfers, deletions, etc.) within and across all cloud servers. This will effectively enable full transparency and accountability for data movements in the cloud. In this paper, we introduce S2Logger, a data event logging mechanism which captures, analyses and visualizes data events in the cloud from the data point of view. By linking together atomic data events captured at both file and block level, the resulting sequence of data events depicts the cloud data provenance records throughout the data lifecycle. With this information, we can then detect critical data-related cloud security problems such as malicious actions, data leakages and data policy violations by analysing the data provenance. S2Logger also enables us to address the gaps and inadequacies of existing system-centric security tools.
ER  - 

TY  - CONF
JO  - Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on
TI  - Data Generation and Analysis for Digital Forensic Application Using Data Mining
T2  - Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on
IS  - 
SN  - 
VO  - 
SP  - 458
EP  - 462
AU  - Khobragade, P.K.
AU  - Malik, L.G.
Y1  - 7-9 April 2014
PY  - 2014
KW  - computer crime
KW  - data analysis
KW  - data mining
KW  - digital forensics
KW  - firewalls
KW  - storage management
KW  - FTK 4.0
KW  - Web browser
KW  - cyber crime huge log data
KW  - cyber system
KW  - data analysis
KW  - data collection
KW  - data generation
KW  - data mining
KW  - data storage
KW  - digital forensic application
KW  - firewall logs
KW  - intrusion detection system
KW  - memory forensic analysis
KW  - network attack detection
KW  - network forensic analysis
KW  - network traces
KW  - network traffic
KW  - packet captures
KW  - remote system forensic
KW  - transactional data
KW  - Computers
KW  - Data mining
KW  - Data visualization
KW  - Databases
KW  - Digital forensics
KW  - Security
KW  - Clustering
KW  - Data Collection
KW  - Digital forensic tool
KW  - Log Data collection
VL  - 
JA  - Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on
DO  - 10.1109/CSNT.2014.97
AB  - In the cyber crime huge log data, transactional data occurs which tends to plenty of data for storage and analyze them. It is difficult for forensic investigators to play plenty of time to find out clue and analyze those data. In network forensic analysis involves network traces and detection of attacks. The trace involves an Intrusion Detection System and firewall logs, logs generated by network services and applications, packet captures by sniffers. In network lots of data is generated in every event of action, so it is difficult for forensic investigators to find out clue and analyzing those data. In network forensics is deals with analysis, monitoring, capturing, recording, and analysis of network traffic for detecting intrusions and investigating them. This paper focuses on data collection from the cyber system and web browser. The FTK 4.0 is discussing for memory forensic analysis and remote system forensic which is to be used as evidence for aiding investigation.
ER  - 

TY  - CONF
JO  - Engineering in Medicine and Biology Society, 2005. IEEE-EMBS 2005. 27th Annual International Conference of the
TI  - HIPPA's compliant Auditing System for Medical Imaging System
T2  - Engineering in Medicine and Biology Society, 2005. IEEE-EMBS 2005. 27th Annual International Conference of the
IS  - 
SN  - 
VO  - 
SP  - 562
EP  - 563
AU  - Xiaomeng Chen
AU  - Jianguo Zhang
AU  - Dongjing Wu
AU  - RuoLing Han
Y1  - 17-18 Jan. 2006
PY  - 2005
KW  - PACS
KW  - authorisation
KW  - data privacy
KW  - Audit Trail Messages
KW  - DICOM
KW  - HIPPA compliant auditing system
KW  - HIPPA compliant auditing trails
KW  - Health Insurance Portability and Accountability Act
KW  - PACS
KW  - Protected Health Information
KW  - RIS
KW  - access control
KW  - audit controls
KW  - authorization control
KW  - data authentication
KW  - entity authentication
KW  - healthcare privacy
KW  - healthcare security
KW  - medical imaging system
KW  - security monitoring system
KW  - Access control
KW  - Authentication
KW  - Authorization
KW  - Biomedical imaging
KW  - Data privacy
KW  - Data security
KW  - Information security
KW  - Insurance
KW  - Medical control systems
KW  - Medical services
VL  - 
JA  - Engineering in Medicine and Biology Society, 2005. IEEE-EMBS 2005. 27th Annual International Conference of the
DO  - 10.1109/IEMBS.2005.1616473
AB  - As an official rule for healthcare privacy and security, Health Insurance Portability and Accountability Act (HIPAA) requires security services supporting implementation features: access control; audit controls; authorization control; data authentication; and entity authentication. Audit controls proposed by HIPPA Security Standards are audit trails, which audit activities, to assess compliance with a secure domain's policies, to detect instances of non-compliant behavior, and to facilitate detection of improper creation, access, modification and deletion of Protected Health Information (PHI). Although current medical imaging systems generate activity logs, there is a lack of regular description to integrate these large volumes of log data into generating HIPPA compliant auditing trails. The paper outlines the design of a HIPAA's compliant auditing system for medical imaging system such as PACS and RIS and discusses the development of this security monitoring system based on the Supplement 95 of the DICOM standard: Audit Trail Messages
ER  - 

TY  - CONF
JO  - Data and Software Engineering (ICODSE), 2014 International Conference on
TI  - Information system log visualization to monitor anomalous user activity based on time
T2  - Data and Software Engineering (ICODSE), 2014 International Conference on
IS  - 
SN  - 
VO  - 
SP  - 1
EP  - 6
AU  - Hanniel, J.J.
AU  - Widagdo, T.E.
AU  - Asnar, Y.D.W.
Y1  - 26-27 Nov. 2014
PY  - 2014
KW  - Internet
KW  - cognition
KW  - data analysis
KW  - data visualisation
KW  - information systems
KW  - security of data
KW  - Web-based data visualization
KW  - anomalous user activity detection
KW  - anomalous user activity monitoring
KW  - anomaly detection
KW  - cognition
KW  - data variables
KW  - design concept
KW  - dot plot
KW  - focused exploration
KW  - heatmap
KW  - information system log visualization
KW  - log data analysis
KW  - log files analysis
KW  - security
KW  - time-based data visualization method
KW  - Data visualization
KW  - Geology
KW  - Heating
KW  - IP networks
KW  - Information systems
KW  - Java
KW  - Monitoring
KW  - anomalous user activity
KW  - data visualization
KW  - log file
VL  - 
JA  - Data and Software Engineering (ICODSE), 2014 International Conference on
DO  - 10.1109/ICODSE.2014.7062673
AB  - As information systems start to manage the more crucial parts of human lives, their security cannot be neglected. One way to ensure the security is by analyzing their generated log files of anomalous user activity. Data visualization has become a common solution to help get around the problems in log analysis. In this paper, we tried to determine key characteristics of effective data visualization on detecting those anomalous user activity recorded in log files. First we analyzed the log data we have and derived 4 anomalies whose indicators are made into visualization topics. Hence we built 4 data visualizations to detect the 4 anomalies. Next, we transformed our data so that they can be visualized. After that, we analyzed the suitable time-based data visualization method to represent our data and decided on heatmap for its wide application on existing solutions and dot plot for it is able to accommodate all data variables needed on every visualization topic and has the suitable nuance for monitoring purposes. Next we decided on design concept of our data visualizations and implemented them as web-based data visualization. We conducted 2 tests in this paper to determine the key characteristics of effective data visualization. Even though the results are inconclusive, but they hinted that an effective data visualization on this matter should support large amount of perceived information through cognition and support focused exploration.
ER  - 

TY  - JOUR
JO  - Dependable and Secure Computing, IEEE Transactions on
TI  - Ensuring Distributed Accountability for Data Sharing in the Cloud
T2  - Dependable and Secure Computing, IEEE Transactions on
IS  - 4
SN  - 1545-5971
VO  - 9
SP  - 556
EP  - 568
AU  - Sundareswaran, S.
AU  - Squicciarini, A.C.
AU  - Lin, D.
Y1  - July-Aug. 2012
PY  - 2012
KW  - authorisation
KW  - cloud computing
KW  - security of data
KW  - system monitoring
KW  - Internet
KW  - JAR programmable capabilities
KW  - cloud computing
KW  - cloud services
KW  - data sharing
KW  - decentralized information accountability framework
KW  - distributed accountability ensurance
KW  - distributed auditing mechanisms
KW  - logging mechanism
KW  - object-centered approach
KW  - Access control
KW  - Authentication
KW  - Cryptography
KW  - Distributed databases
KW  - Monitoring
KW  - Privacy
KW  - Cloud computing
KW  - accountability
KW  - data sharing.
VL  - 9
JA  - Dependable and Secure Computing, IEEE Transactions on
DO  - 10.1109/TDSC.2012.26
AB  - Cloud computing enables highly scalable services to be easily consumed over the Internet on an as-needed basis. A major feature of the cloud services is that users' data are usually processed remotely in unknown machines that users do not own or operate. While enjoying the convenience brought by this new emerging technology, users' fears of losing control of their own data (particularly, financial and health data) can become a significant barrier to the wide adoption of cloud services. To address this problem, in this paper, we propose a novel highly decentralized information accountability framework to keep track of the actual usage of the users' data in the cloud. In particular, we propose an object-centered approach that enables enclosing our logging mechanism together with users' data and policies. We leverage the JAR programmable capabilities to both create a dynamic and traveling object, and to ensure that any access to users' data will trigger authentication and automated logging local to the JARs. To strengthen user's control, we also provide distributed auditing mechanisms. We provide extensive experimental studies that demonstrate the efficiency and effectiveness of the proposed approaches.
ER  - 

TY  - CONF
JO  - Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on
TI  - User and Device Tracking in Private Networks by Correlating Logs: A System for Responsive Forensic Analysis
T2  - Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on
IS  - 
SN  - 
VO  - 
SP  - 1142
EP  - 1147
AU  - Chaudhari, S.
AU  - Chauhan, H.
AU  - Tomar, S.S.
AU  - Rawat, A.
Y1  - 7-9 April 2014
PY  - 2014
KW  - computer network security
KW  - local area networks
KW  - relational databases
KW  - DHCP
KW  - Flat file based sequential search system
KW  - IP address
KW  - Internet protocol address
KW  - RDBMS based tracking systems
KW  - browsing habits
KW  - device connection time
KW  - device location
KW  - device physical address
KW  - device tracking
KW  - electronic mail
KW  - email server logs
KW  - information context
KW  - mail access transactions
KW  - network access control
KW  - private networks
KW  - relational database management system
KW  - responsive forensic analysis
KW  - user tracking
KW  - Correlation
KW  - Databases
KW  - Electronic mail
KW  - Forensics
KW  - IP networks
KW  - Postal services
KW  - Servers
KW  - Logs; DHCP; NAC; squid; email; security logs; data monitoring and analysis tool
VL  - 
JA  - Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on
DO  - 10.1109/CSNT.2014.253
AB  - IP address of a device, from where an offending activity was performed, is of limited value, because it does not specify a physical device/user, but an endpoint in network. It is useful to have information about where a device/user was at the time the offending activity was performed. It would be desirable to correlate different pieces of evidence to discover information, such as IP addresses used by the same device, physical address and location of the device, connection time of the device, browsing habits and mail access transactions carried out by the user using the device. Log data from various sources are required to be correlated together to create contexts of information, which is not visible from one source alone. In large networks, users/devices accessing a private network repeatedly can be tracked by analyzing and correlating DHCP, Network Access Control, WWW, Email server logs. With huge amount of logs, the common approach of manual browsing, correlating of log events, based on timelines is tedious, unresponsive approach. Flat file based sequential search system is not responsive, hence RDBMS based tracking systems are desirable. To build a responsive system requires identifying, consolidating log files, conversion, transmission and storage into relational databases. An automated system has been developed at our organization for forensic analysis of network accesses, with device and user tracking as its goal. We present, our approach to perform log management, correlation, which assists in performing responsive forensic analysis of real network with more than 2500 nodes, aimed at tracking users/devices.
ER  - 

TY  - CONF
JO  - Services (SERVICES), 2014 IEEE World Congress on
TI  - Audit Log Management in MongoDB
T2  - Services (SERVICES), 2014 IEEE World Congress on
IS  - 
SN  - 
VO  - 
SP  - 53
EP  - 57
AU  - Murugesan, P.
AU  - Ray, I.
Y1  - June 27 2014-July 2 2014
PY  - 2014
KW  - Internet
KW  - database management systems
KW  - MongoDB
KW  - NIST standard
KW  - NoSQL databases
KW  - Web-based applications
KW  - agile database
KW  - audit log management
KW  - complex multisite architectures
KW  - data management
KW  - log management techniques
KW  - mongosniff
KW  - single server environment
KW  - Indexes
KW  - Monitoring
KW  - NIST
KW  - Security
KW  - Servers
KW  - Audit Trail
KW  - Log Management
KW  - MongoDB
KW  - NoSQL
VL  - 
JA  - Services (SERVICES), 2014 IEEE World Congress on
DO  - 10.1109/SERVICES.2014.19
AB  - In the past few years, web-based applications and their data management needs have changed dramatically. Relational databases are often being replaced by other viable alternatives, such as NoSQL databases, for reasons of scalability and heterogeneity. MongoDB, a NoSQL database, is an agile database built for scalability, performance and high availability. It can be deployed in single server environment and also on complex multi-site architectures. MongoDB provides high performance for read and write operations by leveraging in-memory computing. Although researchers have motivated the need for MongoDB, not much appears in the area of log management. Efficient log management techniques are needed for various reasons including security, accountability, and improving the performance of the system. Towards this end, we analyze the different logging methods offered by MongoDB and compare them to the NIST standard. Our analysis indicates that profiling and mongosniff are useful for log management and we present a simple model that combines the two techniques.
ER  - 

TY  - CONF
JO  - Network Operations and Management Symposium, 2008. NOMS 2008. IEEE
TI  - Mining event logs with SLCT and LogHound
T2  - Network Operations and Management Symposium, 2008. NOMS 2008. IEEE
IS  - 
SN  - 1542-1201
VO  - 
SP  - 1071
EP  - 1074
AU  - Vaarandi, R.
Y1  - 7-11 April 2008
PY  - 2008
KW  - data mining
KW  - security of data
KW  - telecommunication computing
KW  - LogHound
KW  - communication networks
KW  - event log analysis
KW  - event logs mining
KW  - log data
KW  - security events
KW  - system management personnel
KW  - Algorithm design and analysis
KW  - Clustering algorithms
KW  - Communication networks
KW  - Communication system security
KW  - Data analysis
KW  - Data mining
KW  - Data security
KW  - Event detection
KW  - Monitoring
KW  - Personnel
KW  - data mining
KW  - data security
KW  - event log analysis
VL  - 
JA  - Network Operations and Management Symposium, 2008. NOMS 2008. IEEE
DO  - 10.1109/NOMS.2008.4575281
AB  - With the growth of communication networks, event logs are increasing in size at a fast rate. Today, it is not uncommon to have systems that generate tens of gigabytes of log data per day. Log data are likely to contain information that deserves closer attention - such as security events - but the task of reviewing logs manually is beyond the capabilities of a human. This paper discusses data mining tools SLCT and log hound that were designed for assisting system management personnel in extracting knowledge from event logs.
ER  - 

TY  - CONF
JO  - Information and Telecommunication Technologies (APSITT), 2010 8th Asia-Pacific Symposium on
TI  - A study on the requirements of accountable cloud services and log management
T2  - Information and Telecommunication Technologies (APSITT), 2010 8th Asia-Pacific Symposium on
IS  - 
SN  - 
VO  - 
SP  - 1
EP  - 6
AU  - Nakahara, S.
AU  - Ishimoto, H.
Y1  - 15-18 June 2010
PY  - 2010
KW  - Web services
KW  - cryptography
KW  - network servers
KW  - Web-based cloud services
KW  - accountable cloud services
KW  - cloud-based services tracing
KW  - computer resources
KW  - cryptography
KW  - link log data accountability
KW  - log management
KW  - nonlocal servers
KW  - Application software
KW  - Cloud computing
KW  - Cryptography
KW  - Laboratories
KW  - Network servers
KW  - Outsourcing
KW  - Resource virtualization
KW  - Robustness
KW  - Service oriented architecture
KW  - Web server
KW  - Accountability
KW  - Accountability Framework
KW  - Cloud Service
KW  - Data Security
KW  - Log Management
VL  - 
JA  - Information and Telecommunication Technologies (APSITT), 2010 8th Asia-Pacific Symposium on
DO  - 
AB  - As services themselves and computer resources of cloud services become increasingly non-local, accountability to users for the results and implementation status of the service have emerged as important issues. This paper gives a detailed overview of what would be required to (1) link log data for multiple services supported by non-local servers and (2) trace cloud-based services, focusing on prevailing web-based cloud services. The paper presents a robust accountability framework and discusses how cryptography could be applied to log data accountability.
ER  - 

TY  - JOUR
JO  - Information Forensics and Security, IEEE Transactions on
TI  - Trail of Bytes: New Techniques for Supporting Data Provenance and Limiting Privacy Breaches
T2  - Information Forensics and Security, IEEE Transactions on
IS  - 6
SN  - 1556-6013
VO  - 7
SP  - 1876
EP  - 1889
AU  - Krishnan, S.
AU  - Snow, K.Z.
AU  - Monrose, F.
Y1  - Dec. 2012
PY  - 2012
KW  - computer forensics
KW  - data privacy
KW  - computer systems
KW  - data access
KW  - data exfiltration attempts
KW  - data provenance
KW  - forensic analysis
KW  - forensic layer records
KW  - forensic platform
KW  - hypervisor
KW  - multiple disks
KW  - privacy breaches
KW  - tracking mechanism
KW  - version-based audit log
KW  - virtualized environment
KW  - Couplings
KW  - Forensics
KW  - Monitoring
KW  - Semantics
KW  - Virtual machine monitors
KW  - Virtual machining
KW  - Computer security
KW  - checkpointing
KW  - information security
KW  - intrusion detection
KW  - operating systems
KW  - system recovery
KW  - virtual machine monitors
VL  - 7
JA  - Information Forensics and Security, IEEE Transactions on
DO  - 10.1109/TIFS.2012.2210217
AB  - Forensic analysis of computer systems requires that one first identify suspicious objects or events, and then examine them in enough detail to form a hypothesis as to their cause and effect. Sadly, while our ability to gather vast amounts of data has improved significantly over the past two decades, it is all too often the case that we lack detailed information just when we need it the most. In this paper, we attempt to improve on the state of the art by providing a forensic platform that transparently monitors and records data access events within a virtualized environment using only the abstractions exposed by the hypervisor. Our approach monitors accesses to objects on disk and follows the causal chain of these accesses across processes, even after the objects are copied into memory. Our forensic layer records these transactions in a tamper evident version-based audit log that allows for faithful, and efficient, reconstruction of the recorded events and the changes they induced. To demonstrate the utility of our approach, we provide an extensive empirical evaluation, including a real-world case study demonstrating how our platform can be used to reconstruct valuable information about the what, when, and how, after a compromise has been detected. We also extend our earlier work by providing a tracking mechanism that can monitor data exfiltration attempts across multiple disks and also block attempts to copy data over the network.
ER  - 

TY  - CONF
JO  - IT Security Incident Management and IT Forensics, 2009. IMF '09. Fifth International Conference on
TI  - Safe-Keeping Digital Evidence with Secure Logging Protocols: State of the Art and Challenges
T2  - IT Security Incident Management and IT Forensics, 2009. IMF '09. Fifth International Conference on
IS  - 
SN  - 
VO  - 
SP  - 94
EP  - 110
AU  - Accorsi, R.
Y1  - 15-17 Sept. 2009
PY  - 2009
KW  - cryptographic protocols
KW  - legislation
KW  - system monitoring
KW  - legal requirement
KW  - logging protocol security
KW  - safe-keeping digital evidence
KW  - Computer security
KW  - Cryptographic protocols
KW  - Cryptography
KW  - Data security
KW  - Law
KW  - Legal factors
KW  - Legislation
KW  - Protection
KW  - Protective relaying
KW  - Systems engineering and theory
KW  - Digital evidence
KW  - Legal and security requirements
KW  - Preservation
KW  - Secure logging protocols
VL  - 
JA  - IT Security Incident Management and IT Forensics, 2009. IMF '09. Fifth International Conference on
DO  - 10.1109/IMF.2009.18
AB  - While log data are being increasingly used as digital evidence in court, the extent to which existing secure logging protocols used to collect log data fulfill the legal requirements for admissible evidence remain largely unclear. This paper elucidates a subset of the necessary secure requirements for digital evidence and extensively surveys the state of the art secure logging protocols, thereby demonstrating that none of the current protocols completely fulfills the elucidated requirements for admissible evidence. In analyzing the shortcoming of logging protocols, the paper also elaborates on the related research challenges.
ER  - 

TY  - CONF
JO  - Computer Software and Applications Conference Workshops (COMPSACW), 2010 IEEE 34th Annual
TI  - ULMS: An Accelerator for the Applications by Shifting Writing Log from Local Disk to Clouds
T2  - Computer Software and Applications Conference Workshops (COMPSACW), 2010 IEEE 34th Annual
IS  - 
SN  - 
VO  - 
SP  - 104
EP  - 108
AU  - Li Zhou
AU  - Yong Zhang
AU  - Chunxiao Xing
Y1  - 19-23 July 2010
PY  - 2010
KW  - Web services
KW  - data analysis
KW  - data mining
KW  - database management systems
KW  - disc storage
KW  - software architecture
KW  - system monitoring
KW  - SaaS method
KW  - ULMS
KW  - accelerator
KW  - database system
KW  - local disk
KW  - local storage efficiency
KW  - log analysis
KW  - log data analysis
KW  - log management
KW  - shift-log-by-ActiveMQ
KW  - shift-log-by-Webservice
KW  - user log mining system
KW  - writing log data shift
KW  - Log
KW  - Log Analysis
KW  - Performance
KW  - SaaS
VL  - 
JA  - Computer Software and Applications Conference Workshops (COMPSACW), 2010 IEEE 34th Annual
DO  - 10.1109/COMPSACW.2010.28
AB  - Log data is critical to applications and the management and analysis of log data is a hot research topic. Existing log managements are normally tightly integrated with applications themselves, which may lead to problems including performance, local storage efficiency, security and non realtime functionality. To solve these problems, we present a SaaS method which shifts writing log data from local disk to clouds, at the same time the log management and analysis functionalities are also done by a cloud. We analyze two architectures to implement this method which are Shift-Log-by-WebService and Shift-Log-by-ActiveMQ. Initial experiments show the efficiency of later one. In the future, we can apply this tool to application systems which are based on web and database systems to improve their performances.
ER  - 

TY  - CONF
JO  - Emerging Information Technology and Engineering Solutions (EITES), 2015 International Conference on
TI  - Experiments in Encrypted and Searchable Network Audit Logs
T2  - Emerging Information Technology and Engineering Solutions (EITES), 2015 International Conference on
IS  - 
SN  - 
VO  - 
SP  - 18
EP  - 22
AU  - Gopularam, B.P.
AU  - Dara, S.
AU  - Niranjan, N.
Y1  - 20-21 Feb. 2015
PY  - 2015
KW  - cloud computing
KW  - cryptography
KW  - data privacy
KW  - digital forensics
KW  - telemetry
KW  - attribute-based encryption
KW  - cloud service provider
KW  - encrypted network audit logs
KW  - identity based encryption
KW  - network telemetry data
KW  - privacy preserving search
KW  - searchable network audit logs
KW  - security forensics
KW  - Encryption
KW  - Privacy
KW  - Public key
KW  - Servers
KW  - Telemetry
KW  - audit log privacy
KW  - identity based encryption
KW  - network telemetry
VL  - 
JA  - Emerging Information Technology and Engineering Solutions (EITES), 2015 International Conference on
DO  - 10.1109/EITES.2015.13
AB  - We consider the scenario where a consumer can securely outsource their network telemetry data to a Cloud Service Provider and enable a third party to audit such telemetry for any security forensics. Especially we consider the use case of privacy preserving search in network log audits. In this paper we experiment with advances in Identity Based Encryption and Attribute-Based encryption schemes for auditing network logs.
ER  - 

TY  - CONF
JO  - Information Security (AsiaJCIS), 2015 10th Asia Joint Conference on
TI  - iF2: An Interpretable Fuzzy Rule Filter for Web Log Post-Compromised Malicious Activity Monitoring
T2  - Information Security (AsiaJCIS), 2015 10th Asia Joint Conference on
IS  - 
SN  - 
VO  - 
SP  - 130
EP  - 137
AU  - Chih-Hung Hsieh
AU  - Yu-Siang Shen
AU  - Chao-Wen Li
AU  - Jain-Shing Wu
Y1  - 24-26 May 2015
PY  - 2015
KW  - Internet
KW  - data mining
KW  - fuzzy set theory
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pattern classification
KW  - statistical analysis
KW  - support vector machines
KW  - Internet address
KW  - SVM
KW  - Web log file tracking
KW  - Web log post-compromised malicious activity monitoring
KW  - Web-access log dataset
KW  - decision tree
KW  - expectation maximization based kernel algorithm
KW  - fuzzy rule filter
KW  - iF<sup>2</sup>
KW  - interpretable fuzzy rule filter
KW  - kernel based techniques
KW  - log data analysis
KW  - logic based classifiers
KW  - logic based techniques
KW  - machine learning methods
KW  - malicious activities
KW  - neural network
KW  - parameter optimization problem
KW  - recall rate
KW  - rule-based algorithm
KW  - support vector machine
KW  - Accuracy
KW  - Internet
KW  - Kernel
KW  - Monitoring
KW  - Optimization
KW  - Prediction algorithms
KW  - Support vector machines
KW  - Fuzzy Rule Based Filter
KW  - Machine Learning
KW  - Parameter Optimization
KW  - Pattern Recognition
KW  - Post-Compromised Threat Identification
KW  - Web Log Analysis
VL  - 
JA  - Information Security (AsiaJCIS), 2015 10th Asia Joint Conference on
DO  - 10.1109/AsiaJCIS.2015.19
AB  - To alleviate the loads of tracking web log file by human effort, machine learning methods are now commonly used to analyze log data and to identify the pattern of malicious activities. Traditional kernel based techniques, like the neural network and the support vector machine (SVM), typically can deliver higher prediction accuracy. However, the user of a kernel based techniques normally cannot get an overall picture about the distribution of the data set. On the other hand, logic based techniques, such as the decision tree and the rule-based algorithm, feature the advantage of presenting a good summary about the distinctive characteristics of different classes of data such that they are more suitable to generate interpretable feedbacks to domain experts. In this study, a real web-access log dataset from a certain organization was collected. An efficient interpretable fuzzy rule filter (iF<sup>2</sup>) was proposed as a filter to analyze the data and to detect suspicious internet addresses from the normal ones. The historical information of each internet address recorded in web log file is summarized as multiple statistics. And the design process of iF<sup>2</sup> is elaborately modeled as a parameter optimization problem which simultaneously considers 1) maximizing prediction accuracy, 2) minimizing number of used rules, and 3) minimizing number of selected statistics. Experimental results show that the fuzzy rule filter constructed with the proposed approach is capable of delivering superior prediction accuracy in comparison with the conventional logic based classifiers and the expectation maximization based kernel algorithm. On the other hand, though it cannot match the prediction accuracy delivered by the SVM, however, when facing real web log file where the ratio of positive and negative cases is extremely unbalanced, the proposed iF<sup>2</sup> of having optimization flexibility results in a better recall rate and enjoys one major advantage due to providing th- user with an overall picture of the underlying distributions.
ER  - 

TY  - CONF
JO  - Information Assurance Workshop, 2005. IAW '05. Proceedings from the Sixth Annual IEEE SMC
TI  - Virtual honeynets revisited
T2  - Information Assurance Workshop, 2005. IAW '05. Proceedings from the Sixth Annual IEEE SMC
IS  - 
SN  - 
VO  - 
SP  - 232
EP  - 239
AU  - Lok Kwong Yan
Y1  - 15-17 June 2005
PY  - 2005
KW  - Linux
KW  - computer networks
KW  - data handling
KW  - network operating systems
KW  - security of data
KW  - virtual machines
KW  - virtual private networks
KW  - FSLog
KW  - GenII honeynet
KW  - Linux
KW  - SELinux
KW  - UML
KW  - data control
KW  - disk imager
KW  - file system logging
KW  - forensic images
KW  - honeypot controller
KW  - system call redirection
KW  - trusted honeywall
KW  - virtual honeynet architecture
KW  - virtual honeynet security
KW  - virtual machine
KW  - Computer architecture
KW  - Control systems
KW  - Costs
KW  - File systems
KW  - Forensics
KW  - Image analysis
KW  - Linux
KW  - Security
KW  - Unified modeling language
KW  - Virtual machining
VL  - 
JA  - Information Assurance Workshop, 2005. IAW '05. Proceedings from the Sixth Annual IEEE SMC
DO  - 10.1109/IAW.2005.1495957
AB  - A new user-mode Linux based virtual honeynet architecture is presented in this paper. The new architecture has improved functionality that is difficult to realize in the GenII honeynet. Two new honeynet capabilities in particular are introduced. Honeypot controller is a new virtual honeynet component that assists in data control. The honeywall promises to have finer control over the honeypots through signal and system call redirections. The second new capability is the disk imager. The disk imager is capable of making forensic images of the virtual machine's file systems for further analysis. Since security for virtual honeynets is a big concern, the new virtual honeynet architecture utilizes security enhanced Linux to isolate the untrusted honeypots from the completely trusted honeywall. SELinux and other research work done in this field made the new honeynet architecture a viable alternative to GenII honeynets. A file system logging mechanism, FSLog, has been developed for the UML based virtual honeynet. In conjunction with the built-in tty logger, UML based honeynets have logging capabilities that are equivalent to their GenII honeynet counterparts. The current version of FSLog successfully logs eighteen virtual file systems system calls including the common, read(), write(), open() and close() functions. Its current functionality and how it pieces into the new architecture is also discussed. This work provides researchers with an alternative honeynet platform. The new virtual honeynet architecture is more portable, easier to setup, more cost effective and as secure as the GenII honeynet. The addition of the honeypot controller and disk imager components also makes the new virtual honeynet architecture more capable.
ER  - 

TY  - CONF
JO  - Systematic Approaches to Digital Forensic Engineering, 2008. SADFE '08. Third International Workshop on
TI  - Finding the Evidence in Tamper-Evident Logs
T2  - Systematic Approaches to Digital Forensic Engineering, 2008. SADFE '08. Third International Workshop on
IS  - 
SN  - 
VO  - 
SP  - 69
EP  - 75
AU  - Sandler, D.
AU  - Derr, K.
AU  - Crosby, S.
AU  - Wallach, D.S.
Y1  - 22-22 May 2008
PY  - 2008
KW  - data recording
KW  - query processing
KW  - security of data
KW  - Querifier
KW  - flexible pattern-matching language
KW  - forensic scrutiny
KW  - hash chaining
KW  - secure log
KW  - suspicious activity
KW  - tamper-evident chronological records
KW  - tamper-evident logs
KW  - Business
KW  - Data structures
KW  - Digital forensics
KW  - Forgery
KW  - Humans
KW  - Law
KW  - Legal factors
KW  - Power engineering and energy
KW  - Resists
KW  - Runtime
KW  - hash chaining
KW  - predicate logic
KW  - query processing
KW  - secure logs
KW  - tamper evidence
VL  - 
JA  - Systematic Approaches to Digital Forensic Engineering, 2008. SADFE '08. Third International Workshop on
DO  - 10.1109/SADFE.2008.22
AB  - Secure logs are powerful tools for building systems that must resist forgery, prove temporal relationships, and stand up to forensic scrutiny. The proofs of order and integrity encoded in these tamper-evident chronological records, typically built using hash chaining, may be used by applications to enforce operating constraints or sound alarms at suspicious activity. However, existing research stops short of discussing how one might go about automatically determining whether a given secure log satisfies a given set of constraints on its records. In this paper, we discuss our work on Querifier, a tool that accomplishes this. It can be used offline as an analyzer for static logs, or online during the runtime of a logging application. Querifier rules are written in a flexible pattern-matching language that adapts to arbitrary log structures; given a set of rules and available log data, Querifier presents evidence of correctness and offers counterexamples if desired. We describe Querfier's implementation and offer early performance results.
ER  - 

TY  - CONF
JO  - Business Management and Electronic Information (BMEI), 2011 International Conference on
TI  - An improved algorithm with key attributes constraints for mining interesting association rules in network log
T2  - Business Management and Electronic Information (BMEI), 2011 International Conference on
IS  - 
SN  - 
VO  - 3
SP  - 104
EP  - 107
AU  - Jin Kezhong
AU  - Wu Chengwen
Y1  - 13-15 May 2011
PY  - 2011
KW  - computer forensics
KW  - data mining
KW  - pattern classification
KW  - security of data
KW  - association rule mining
KW  - computer forensic analysis
KW  - computer log data source
KW  - intrusion detection analysis
KW  - key attribute constraint
KW  - network access
KW  - network log data
KW  - outlier detection
KW  - user pattern mining
KW  - Algorithm design and analysis
KW  - Association rules
KW  - Computers
KW  - Databases
KW  - Performance evaluation
KW  - Protocols
KW  - association rule
KW  - data mining
KW  - key attribute
KW  - network log
VL  - 3
JA  - Business Management and Electronic Information (BMEI), 2011 International Conference on
DO  - 10.1109/ICBMEI.2011.5920405
AB  - Computer logs are generated by application activities, network accesses and system audit, which are important data sources for user pattern mining, computer forensic analysis, intrusion detection analysis and outlier detection. Algorithms for mining association rule are useful methods to find interesting rules implied in large computer log data. But existing algorithms which based on confidence and support are unfit for mining computer log data, many uninteresting rules will be generated and useful rules will be shadowed. To solve this problem, the concept of key attributes of network log data is introduced, and an algorithm with key attributes constraints for mining interesting association rules in network log data is designed. Experimental result shows that the number of uninteresting rules can be reduced effectively and the validity of rules which mined are improved.
ER  - 

TY  - CONF
JO  - Network Operations and Management Symposium (NOMS), 2012 IEEE
TI  - A distance-based method to detect anomalous attributes in log files
T2  - Network Operations and Management Symposium (NOMS), 2012 IEEE
IS  - 
SN  - 1542-1201
VO  - 
SP  - 498
EP  - 501
AU  - Hommes, S.
AU  - State, R.
AU  - Engel, T.
Y1  - 16-20 April 2012
PY  - 2012
KW  - computer network security
KW  - data analysis
KW  - information theory
KW  - statistical process control
KW  - system monitoring
KW  - ISP-provided firewall logs
KW  - anomalous attribute detection
KW  - automated log analysis
KW  - data volume
KW  - distance-based method
KW  - domain-specific knowledge
KW  - haystack problem
KW  - human expertise
KW  - information theory
KW  - log data analysis
KW  - operational logs
KW  - proverbial needle
KW  - real time analysis
KW  - statistical process control
KW  - suspicious network activity detection
KW  - Control charts
KW  - Correlation
KW  - Humans
KW  - IP networks
KW  - Process control
KW  - Protocols
KW  - Real time systems
VL  - 
JA  - Network Operations and Management Symposium (NOMS), 2012 IEEE
DO  - 10.1109/NOMS.2012.6211940
AB  - Dealing with large volumes of logs is like the proverbial needle in the haystack problem. Finding relevant events that might be associated with an incident, or real time analysis of operational logs is extremely difficult when the underlying data volume is huge and when no explicit misuse model exists. While domain-specific knowledge and human expertise may be useful in analysing log data, automated approaches for detecting anomalies and track incidents are the only viable solutions when confronted with large volumes of data. In this paper we address the issue of automated log analysis and consider more specifically the case of ISP-provided firewall logs. We leverage approaches derived from statistical process control and information theory in order to track potential incidents and detect suspicious network activity.
ER  - 

TY  - CONF
JO  - Computer Software and Applications Conference, 2009. COMPSAC '09. 33rd Annual IEEE International
TI  - Log Data as Digital Evidence: What Secure Logging Protocols Have to Offer?
T2  - Computer Software and Applications Conference, 2009. COMPSAC '09. 33rd Annual IEEE International
IS  - 
SN  - 0730-3157
VO  - 2
SP  - 398
EP  - 403
AU  - Accorsi, R.
Y1  - 20-24 July 2009
PY  - 2009
KW  - security of data
KW  - system monitoring
KW  - digital evidence
KW  - log data
KW  - secure logging protocol
KW  - secure requirements
KW  - Computer applications
KW  - Computer security
KW  - Cryptographic protocols
KW  - Cryptography
KW  - Data security
KW  - Law
KW  - Legal factors
KW  - Proposals
KW  - Protection
KW  - Protective relaying
KW  - Digital Evidence
KW  - Forensics
KW  - Secure Logging
VL  - 2
JA  - Computer Software and Applications Conference, 2009. COMPSAC '09. 33rd Annual IEEE International
DO  - 10.1109/COMPSAC.2009.166
AB  - While log data are being increasingly used as digital evidence in judicial disputes, the extent to which existing secure logging protocols used to collect log data fulfill the legal requirements for admissible evidence remain largely unclear. We elucidate the necessary secure requirements for digital evidence and extensively survey the state of the art secure logging protocols,thereby demonstrating that none of the current proposals fulfills the necessary conditions for admissible evidence.
ER  - 

TY  - CONF
JO  - Computer Software and Applications Conference (COMPSAC), 2012 IEEE 36th Annual
TI  - Domain Independent Event Analysis for Log Data Reduction
T2  - Computer Software and Applications Conference (COMPSAC), 2012 IEEE 36th Annual
IS  - 
SN  - 0730-3157
VO  - 
SP  - 225
EP  - 232
AU  - Kalamatianos, T.
AU  - Kontogiannis, K.
AU  - Matthews, P.
Y1  - 16-20 July 2012
PY  - 2012
KW  - data analysis
KW  - data reduction
KW  - program diagnostics
KW  - security of data
KW  - DARPA Intrusion Detection Evaluation 1999 data sets
KW  - KDD 1999 data sets
KW  - domain independent event analysis
KW  - large software systems
KW  - log analysis technique
KW  - log data reduction
KW  - run time behavior analysis
KW  - similarity score
KW  - Algorithm design and analysis
KW  - Analytical models
KW  - Intrusion detection
KW  - Software
KW  - Standards
KW  - Weight measurement
KW  - Software engineering
KW  - dynamic analysis
KW  - log analysis
KW  - log reduction
KW  - software maintenance
KW  - system understanding
VL  - 
JA  - Computer Software and Applications Conference (COMPSAC), 2012 IEEE 36th Annual
DO  - 10.1109/COMPSAC.2012.33
AB  - Analyzing the run time behavior of large software systems is a difficult and challenging task. Log analysis has been proposed as a possible solution. However, such an analysis poses unique challenges, mostly due to the volume and diversity of the logged data that is collected, thus making this analysis often intractable for practical purposes. In this paper, we present a log analysis technique that aims to compute a smaller, compared to the original, collection of events that relate to a given analysis objective. The technique is based on computing a similarity score between the logged events and a collection of significant events that we refer to as beacons. The major novelties of the proposed technique are that it is domain independent and that it does not require the use of a pre-existing training data set. The technique has been evaluated against the DARPA Intrusion Detection Evaluation 1999 and the KDD 1999 data sets with promising results.
ER  - 

TY  - CONF
JO  - Intelligence and Security Informatics Conference (EISIC), 2011 European
TI  - Trees Cannot Lie: Using Data Structures for Forensics Purposes
T2  - Intelligence and Security Informatics Conference (EISIC), 2011 European
IS  - 
SN  - 
VO  - 
SP  - 282
EP  - 285
AU  - Kieseberg, P.
AU  - Schrittwieser, S.
AU  - Mulazzani, M.
AU  - Huber, M.
AU  - Weippl, E.
Y1  - 12-14 Sept. 2011
PY  - 2011
KW  - computer forensics
KW  - database management systems
KW  - tree data structures
KW  - tree searching
KW  - cache clock hands
KW  - data storage
KW  - data structures
KW  - database management system
KW  - digital forensic research community
KW  - flushing transient artifact
KW  - log files
KW  - logging mechanism
KW  - malicious administrator modification
KW  - plan caches
KW  - tree forensic technique
KW  - Digital forensics
KW  - Engines
KW  - Indexes
KW  - Vegetation
KW  - InnoDB
KW  - b+ tree
KW  - database forensics
VL  - 
JA  - Intelligence and Security Informatics Conference (EISIC), 2011 European
DO  - 10.1109/EISIC.2011.18
AB  - Today's forensic techniques for databases are primarily focused on logging mechanisms and artifacts accessible in the database management systems (DBMSs). While log files, plan caches, cache clock hands, etc. can reveal past transactions, a malicious administrator's modifications might be much more difficult to detect, because he can cover his tracks by also manipulating the log files and flushing transient artifacts such as caches. The internal structure of the data storage inside databases, however, has not yet received much attention from the digital forensic research community. In this paper, we want to show that the diversity of B<sup>+</sup>-Trees, a widely used data structure in today's database storage engines, enables a deep insight of the database's history. Hidden manipulations such as predated INSERT operations in a logging database can be revealed by our approach. We introduce novel forensic techniques for B<sup>+</sup>-Trees that are based on characteristics of the tree structure and show how database management systems would have to be modified to even better support tree forensic techniques.
ER  - 

TY  - CONF
JO  - Computer Software and Applications, 2008. COMPSAC '08. 32nd Annual IEEE International
TI  - Pattern and Policy Driven Log Analysis for Software Monitoring
T2  - Computer Software and Applications, 2008. COMPSAC '08. 32nd Annual IEEE International
IS  - 
SN  - 0730-3157
VO  - 
SP  - 108
EP  - 111
AU  - Razavi, A.
AU  - Kontogiannis, Kostas
Y1  - July 28 2008-Aug. 1 2008
PY  - 2008
KW  - object-oriented programming
KW  - program diagnostics
KW  - risk analysis
KW  - security of data
KW  - Viterbi algorithm
KW  - component-based software
KW  - industrial software systems
KW  - pattern driven log analysis
KW  - pattern recognition
KW  - policy driven log analysis
KW  - software monitoring
KW  - system auditing
KW  - system diagnosis
KW  - system maintenance
KW  - system monitoring
KW  - system risk
KW  - system threat profile
KW  - Application software
KW  - Collaborative software
KW  - Computer industry
KW  - Context modeling
KW  - Monitoring
KW  - Pattern analysis
KW  - Pattern matching
KW  - Pattern recognition
KW  - Risk analysis
KW  - Software systems
KW  - Software Auditing
KW  - Software Monitoring
KW  - Trace Analysis
VL  - 
JA  - Computer Software and Applications, 2008. COMPSAC '08. 32nd Annual IEEE International
DO  - 10.1109/COMPSAC.2008.81
AB  - The component-based nature of large industrial software systems that consist of a number of diverse collaborating applications, pose significant challenges with respect to system maintenance, monitoring, auditing, and diagnosing. In this context, a monitoring and diagnostic system interprets log data to recognize patterns of significant events that conform to specific threat models. Threat models have been used by the software industry for analyzing and documenting a systempsilas risks in order to understand a systempsilas threat profile. In this paper, we propose a framework whereby patterns of significant events are represented as expressions of a specialized monitoring language that are used to annotate specific threat models. An approximate matching technique that is based on the Viterbi algorithm is then used to identify whether system generated events, fit the given patterns. The technique has been applied and evaluated considering threat models and monitoring policies in logs that have been obtained from multi-user MS-Windows based systems.
ER  - 

TY  - CONF
JO  - Cloud Computing Technology and Science (CloudCom), 2013 IEEE 5th International Conference on
TI  - Supporting Cloud Accountability by Collecting Evidence Using Audit Agents
T2  - Cloud Computing Technology and Science (CloudCom), 2013 IEEE 5th International Conference on
IS  - 
SN  - 
VO  - 1
SP  - 185
EP  - 190
AU  - Ruebsamen, T.
AU  - Reich, C.
Y1  - 2-5 Dec. 2013
PY  - 2013
KW  - auditing
KW  - cloud computing
KW  - data privacy
KW  - agent based architecture
KW  - audit processing
KW  - audit tasks
KW  - cloud computing
KW  - cloud services process data
KW  - cloud-adopted evidence collection process
KW  - complexity reduction
KW  - log data analysis
KW  - multi-provider scenario
KW  - privacy issues
KW  - Cloud computing
KW  - Customer relationship management
KW  - Data privacy
KW  - Monitoring
KW  - Security
KW  - Virtual machine monitors
KW  - Virtual machining
KW  - Accountability
KW  - Audit
KW  - Cloud Computing
KW  - Evidence
VL  - 1
JA  - Cloud Computing Technology and Science (CloudCom), 2013 IEEE 5th International Conference on
DO  - 10.1109/CloudCom.2013.32
AB  - Today's cloud services process data and let it often unclear to customers, how and by whom data is collected, stored and processed. This hinders the adoption of cloud computing by businesses. One way to address this problem is to make clouds more accountable, which has to be provable by third parties through audits. In this paper we present a cloud-adopted evidence collection process, possible evidence sources and discuss privacy issues in the context of audits. We introduce an agent based architecture, which is able to perform audit processing and reporting continuously. Agents can be specialized to perform specific audit tasks (e.g., log data analysis) whenever necessary, to reduce complexity and the amount of collected evidence information. Finally, a multi-provider scenario is discussed, which shows the usefulness of this approach.
ER  - 

TY  - CONF
JO  - Securecomm and Workshops, 2006
TI  - System Anomaly Detection: Mining Firewall Logs
T2  - Securecomm and Workshops, 2006
IS  - 
SN  - 
VO  - 
SP  - 1
EP  - 5
AU  - Winding, R.
AU  - Wright, T.
AU  - Chapple, M.
Y1  - Aug. 28 2006-Sept. 1 2006
PY  - 2006
KW  - authorisation
KW  - computer networks
KW  - data mining
KW  - learning (artificial intelligence)
KW  - statistical analysis
KW  - telecommunication traffic
KW  - data mining
KW  - firewall audit log mining
KW  - machine learning
KW  - network traffic anomalies
KW  - statistical analysis
KW  - system anomaly detection
KW  - Data mining
KW  - Data security
KW  - Forensics
KW  - Intrusion detection
KW  - Machine learning
KW  - Protection
KW  - Reconnaissance
KW  - Statistical analysis
KW  - Telecommunication traffic
KW  - Traffic control
KW  - Data mining
KW  - Firewall log analysis
KW  - Intrusion Detection
VL  - 
JA  - Securecomm and Workshops, 2006
DO  - 10.1109/SECCOMW.2006.359572
AB  - This paper describes an application of data mining and machine learning to discovering network traffic anomalies in firewall logs. There is a variety of issues and problems that can occur with systems that are protected by firewalls. These systems can be improperly configured, operate unexpected services, or fall victim to intrusion attempts. Firewall logs often generate hundreds of thousands of audit entries per day. It is often easy to use these records for forensics if one knows that something happened and when. However, it can be burdensome to attempt to manually review logs for anomalies. This paper uses data mining techniques to analyze network traffic, based on firewall audit logs, to determine if statistical analysis of the logs can be used to identify anomalies
ER  - 

TY  - CONF
JO  - Systematic Approaches to Digital Forensic Engineering, 2008. SADFE '08. Third International Workshop on
TI  - Exemplifying Attack Identification and Analysis in a Novel Forensically Viable Syslog Model
T2  - Systematic Approaches to Digital Forensic Engineering, 2008. SADFE '08. Third International Workshop on
IS  - 
SN  - 
VO  - 
SP  - 57
EP  - 68
AU  - Monteiro, S.D.S.
AU  - Erbacher, R.F.
Y1  - 22-22 May 2008
PY  - 2008
KW  - computer crime
KW  - message authentication
KW  - Syslog model
KW  - authentication log
KW  - computer forensic
KW  - Authentication
KW  - Computer networks
KW  - Computer science
KW  - Digital forensics
KW  - Drives
KW  - Fingerprint recognition
KW  - Frequency
KW  - Guns
KW  - Protocols
KW  - Security
KW  - Digital Forensics
KW  - Forensic Validity
KW  - Syslog Authentication
VL  - 
JA  - Systematic Approaches to Digital Forensic Engineering, 2008. SADFE '08. Third International Workshop on
DO  - 10.1109/SADFE.2008.14
AB  - This research builds on our method for validating syslog entries proposed in [5]. The goal of the proposed method is to allow syslog files to be forensically viable. The goal with this phase of the work is to implement the proposed method and evaluate the forensic validity of the method under real-world conditions. This paper discusses that implementation and the ability for the generated authentication logs and access fingerprints to both identify malicious activity and identify the source of this activity. While work has been done to develop secure log files, i.e., making them tamper resistant, there has been no prior work to ensure they are forensically valid.
ER  - 

TY  - CONF
JO  - Computational Intelligence and Security Workshops, 2007. CISW 2007. International Conference on
TI  - Time Bounding Event Reasoning in Computer Forensic
T2  - Computational Intelligence and Security Workshops, 2007. CISW 2007. International Conference on
IS  - 
SN  - 
VO  - 
SP  - 946
EP  - 952
AU  - Liu Zhi Jun
AU  - Zhang Huan guo
Y1  - 15-19 Dec. 2007
PY  - 2007
KW  - file organisation
KW  - police data processing
KW  - computer forensic
KW  - digital investigations
KW  - logging mechanism
KW  - multilevel overwriting data
KW  - time bounding event reasoning
KW  - time offset mechanism
KW  - timestamps
KW  - Algorithm design and analysis
KW  - Clocks
KW  - Computational intelligence
KW  - Computer security
KW  - Forensics
KW  - Hard disks
KW  - Information security
KW  - Information technology
KW  - Web pages
KW  - Web server
VL  - 
JA  - Computational Intelligence and Security Workshops, 2007. CISW 2007. International Conference on
DO  - 10.1109/CISW.2007.4425652
AB  - Timestamps are widely used in computing and offer an easy way to determine the time of events in digital investigations. Unfortunately, the ability of users to change clock settings, the difficult to recover the multi-level overwriting data in a disk, etc. can not provide the efficient timestamp for event reasoning. In this paper, we present techniques to use lay technique to deal with the time of a file on local machine, even its data block of a file had been re-written many times or deleted long ago, and adopt the time offset mechanism to deal with the deviation time of the file at time t. Use a logging mechanism to record the time of modifications to each disk block and its deviation time at time t to calculate the real time of a file for reasoning the order of the events and obtaining a timeline of activities on a file.
ER  - 

TY  - CONF
JO  - Fuzzy Systems Conference, 2007. FUZZ-IEEE 2007. IEEE International
TI  - Detecting Abnormal Changes in E-mail Traffic Using Hierarchical Fuzzy Systems
T2  - Fuzzy Systems Conference, 2007. FUZZ-IEEE 2007. IEEE International
IS  - 
SN  - 1098-7584
VO  - 
SP  - 1
EP  - 6
AU  - Lim, M.J.-H.
AU  - Negnevitsky, M.
AU  - Hartnett, J.
Y1  - 23-26 July 2007
PY  - 2007
KW  - electronic mail
KW  - information retrieval
KW  - law administration
KW  - security of data
KW  - terrorism
KW  - Enron e-mail corpus
KW  - e-mail traffic abnormal change detection
KW  - forensic tool
KW  - hierarchical fuzzy system architecture
KW  - information extraction
KW  - law enforcement
KW  - terrorist attack
KW  - Australia
KW  - Data analysis
KW  - Data mining
KW  - Digital forensics
KW  - Electronic mail
KW  - Fuzzy systems
KW  - Information analysis
KW  - Law enforcement
KW  - Mobile communication
KW  - Terrorism
VL  - 
JA  - Fuzzy Systems Conference, 2007. FUZZ-IEEE 2007. IEEE International
DO  - 10.1109/FUZZY.2007.4295556
AB  - E-mail traffic analysis is an area of work that focuses on extracting information about the behaviour of e-mail users based on the sender, receiver, and date/time information taken from the header section of e-mail messages. Such work has applications for law enforcement where investigators and analysts require techniques to assist them with finding unusual or suspicious patterns from large amounts of communication log data. This paper describes work using hierarchical fuzzy systems to detect abnormal changes in e-mail traffic behaviour, through the fusion of e-mail traffic behaviour measurements. The paper focuses on the use of three different hierarchical fuzzy system architectures, to determine the effect that input variable groupings have on the abnormality ratings given to the communication links of suspect e-mail accounts. The case study demonstrates the use of the three hierarchical fuzzy system architectures for analysing suspect e-mail accounts belonging to the Enron e-mail corpus.
ER  - 

TY  - CONF
JO  - Complex, Intelligent, and Software Intensive Systems (CISIS), 2013 Seventh International Conference on
TI  - An Integrated Distributed Log Management System with Metadata for Network Operation
T2  - Complex, Intelligent, and Software Intensive Systems (CISIS), 2013 Seventh International Conference on
IS  - 
SN  - 
VO  - 
SP  - 747
EP  - 750
AU  - Ikebe, M.
AU  - Yoshida, K.
Y1  - 3-5 July 2013
PY  - 2013
KW  - Internet
KW  - computer network management
KW  - computer network security
KW  - distributed sensors
KW  - meta data
KW  - system monitoring
KW  - campus networks
KW  - cross-processing system
KW  - integrated distributed log management system
KW  - log analysis
KW  - log collection
KW  - metadata
KW  - network administrators
KW  - network management tasks
KW  - network operation
KW  - sensor network
KW  - server administrators
KW  - server management tasks
KW  - Artificial intelligence
KW  - Distributed databases
KW  - Educational institutions
KW  - IP networks
KW  - Protocols
KW  - Prototypes
KW  - Servers
KW  - Distributed System
KW  - Metadata
KW  - Network Operation
KW  - Server Log
VL  - 
JA  - Complex, Intelligent, and Software Intensive Systems (CISIS), 2013 Seventh International Conference on
DO  - 10.1109/CISIS.2013.134
AB  - An enormous amount of log data is generated by servers and other devices on the network, and server/network administrators analyze the logs to investigate anomalous communications or troubleshoot. However, server/network management tasks increase in volume and complexity, resulting in greater burden on the administrator. In this paper, we propose a integrated management system for a sensor network where log data is output from many different kinds of sensors. We consider a server or network device as one of the sensors. We also propose a cross-processing system for several kinds of log data. In particular, we describe the management and collection of logs in our campus networks.
ER  - 


